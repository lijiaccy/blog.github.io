<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[spring源码分析之事务]]></title>
    <url>%2F2017%2F11%2F07%2Fspring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8B%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[什么是事务事务是作为一个逻辑单元执行的一系列操作。一个事务中的一系列的操作要么全部成功，要么一个都失败。事务应该具有4个属性：原子性、一致性、隔离性、持续性。这四个属性通常称为ACID特性。原子性（atomicity）：一个事务是一个不可分割的工作单位，事务中包括的诸操作要么都做，要么都不做。一致性（consistency）：事务必须是使数据库从一个一致性状态变到另一个一致性状态。一致性与原子性是密切相关的。隔离性（isolation）：一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。持久性（durability）：持续性也称永久性（permanence），指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响。 事务的流程对于纯JDBC操作数据库，想要用到事务，可以按照以下步骤进行： 获取连接 Connection con = DriverManager.getConnection() 开启事务con.setAutoCommit(true/false); 执行CRUD 提交事务/回滚事务 con.commit() 或 con.rollback(); 关闭连接 conn.close(); 使用Spring的事务管理功能后，我们可以不再写步骤 2 和 4 的代码，而是由Spirng 自动完成。Spring是如何在我们书写的 CRUD 之前和之后开启事务和关闭事务的呢？理解Spring的事务管理实现原理了。 配置文件开启注解驱动，在相关的类和方法上通过注解@Transactional标识。 spring 在启动的时候会去解析生成相关的bean，这时候会查看拥有相关注解的类和方法，并且为这些类和方法生成代理，并根据@Transaction的相关参数进行相关配置注入，这样就在代理中为我们把相关的事务处理掉了（开启正常提交事务，异常回滚事务）。 真正的数据库层的事务提交和回滚是通过binlog或者redo log实现的。Spring 事务的传播属性所谓spring事务的传播属性，就是定义在存在多个事务同时存在的时候，spring应该如何处理这些事务的行为。这些属性在TransactionDefinition中定义，具体常量的解释如下 常量名称 解释 PROPAGATION_REQUIRED 支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择，也是 Spring 默认的事务的传播 PROPAGATION_REQUIRES_NEW 新建事务，如果当前存在事务，把当前事务挂起。新建的事务将和被挂起的事务没有任何关系，是两个独立的事务，外层事务失败回滚之后，不能回滚内层事务执行的结果，内层事务失败抛出异常，外层事务捕获，也可以不处理回滚操作 PROPAGATION_SUPPORTS 支持当前事务，如果当前没有事务，就以非事务方式执行 PROPAGATION_MANDATORY 支持当前事务，如果当前没有事务，就抛出异常 PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起 PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常 PROPAGATION_NESTED 如果一个活动的事务存在，则运行在一个嵌套的事务中。如果没有活动事务，则按REQUIRED属性执行。它使用了一个单独的事务，这个事务拥有多个可以回滚的保存点。内部事务的回滚不会对外部事务造成影响。它只对DataSourceTransactionManager事务管理器起效 数据库隔离级别 隔离级别 隔离级别的值 导致的问题 Read-Uncommitted 0 导致脏读 Read-Committed 1 避免脏读，允许不可重复读和幻读 Repeatable-Read 2 避免脏读，不可重复读，允许幻读 Serializable 3 串行化读，事务只能一个一个执行，避免了脏读、不可重复读、幻读。执行效率慢，使用时慎重 脏读：一事务对数据进行了增删改，但未提交，另一事务可以读取到未提交的数据。如果第一个事务这时候回滚了，那么第二个事务就读到了脏数据。不可重复读：一个事务中发生了两次读操作，第一次读操作和第二次操作之间，另外一个事务对数据进行了修改，这时候两次读取的数据是不一致的。幻读：第一个事务对一定范围的数据进行批量修改，第二个事务在这个范围增加一条数据，这时候第一个事务就会丢失对新增数据的修改。总结：隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大。大多数的数据库默认隔离级别为 Read Commited，比如 SqlServer、Oracle少数数据库默认隔离级别为：Repeatable Read 比如： MySQL InnoDB Spring中的隔离级别 常量 解释 ISOLATION_DEFAULT 这是个 PlatfromTransactionManager 默认的隔离级别，使用数据库默认的事务隔离级别。另外四个与 JDBC 的隔离级别相对应 ISOLATION_READ_UNCOMMITTED 这是事务最低的隔离级别，它充许另外一个事务可以看到这个事务未提交的数据。这种隔离级别会产生脏读，不可重复读和幻像读 ISOLATION_READ_COMMITTED 保证一个事务修改的数据提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据 ISOLATION_REPEATABLE_READ 这种事务隔离级别可以防止脏读，不可重复读。但是可能出现幻像读 ISOLATION_SERIALIZABLE 这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行 Spring事务嵌套的问题声明式事务声明式事务有两种实现方式，一种xml的，如下 &lt;tx:advice id=&quot;advice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;tx:attributes&gt; &lt;!-- 拦截save开头的方法，事务传播行为为：REQUIRED：必须要有事务, 如果没有就在上下文创建一个 --&gt; &lt;tx:method name=&quot;save*&quot; propagation=&quot;REQUIRED&quot; isolation=&quot;READ_COMMITTED&quot; timeout=&quot;&quot; read-only=&quot;false&quot; no-rollback-for=&quot;&quot; rollback-for=&quot;&quot;/&gt; &lt;!-- 支持,如果有就有,没有就没有 --&gt; &lt;tx:method name=&quot;*&quot; propagation=&quot;SUPPORTS&quot;/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 定义切入点，expression为切人点表达式，如下是指定impl包下的所有方法，具体以自身实际要求自定义 --&gt; &lt;aop:config&gt; &lt;aop:pointcut expression=&quot;execution(* com.kaizhi.*.service.impl.*.*(..))&quot; id=&quot;pointcut&quot;/&gt; &lt;!--&lt;aop:advisor&gt;定义切入点，与通知，把tx与aop的配置关联,才是完整的声明事务配置 --&gt; &lt;aop:advisor advice-ref=&quot;advice&quot; pointcut-ref=&quot;pointcut&quot;/&gt; &lt;/aop:config&gt; 还有一种使用@Transactional @Transactional @Override public void insert(Test test) { //事物传播行为是PROPAGATION_NOT_SUPPORTED，以非事务方式运行，不会存入数据库 dao.insert(test); } 但是使用@Transactional，内部是利用环绕通知TransactionInterceptor实现事务的开启及关闭。需要注意的是： 默认情况下，只有来自外部的方法调用才会被AOP代理捕获，也就是，类内部方法调用本类内部的其他方法并不会引起事务行为，即使被调用方法使用@Transactional注解进行修饰。 如果在接口、实现类或方法上都指定了@Transactional 注解，则优先级顺序为方法&gt;实现类&gt;接口。 建议只在实现类或实现类的方法上使用@Transactional，而不要在接口上使用，这是因为如果使用JDK代理机制（基于接口的代理）是没问题；而使用使用CGLIB代理（继承）机制时就会遇到问题，因为其使用基于类的代理而不是接口，这是因为接口上的@Transactional注解是“不能继承的”。 @Transactional还有其他的一些用法noRollbackFor：执行事务，但是不会滚，出入数据库了 @Transactional(noRollbackFor=RuntimeException.class) @Override public void insert(Test test) { dao.insert(test); //抛出unchecked异常，触发事物，noRollbackFor=RuntimeException.class,不回滚 throw new RuntimeException(&quot;test&quot;); } NOT_SUPPORTED：以非事务方式运行，不会存入数据库 @Transactional(propagation=Propagation.NOT_SUPPORTED) @Override public void insert(Test test) { //事物传播行为是PROPAGATION_NOT_SUPPORTED，以非事务方式运行，不会存入数据库 dao.insert(test); } 实例为了方便，我用Springboot去实现 表 pom： &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-parent&lt;/artifactId&gt; &lt;version&gt;1.5.4.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;version.jackson&gt;2.8.5&lt;/version.jackson&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.26&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.40&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; Mapper： import org.apache.ibatis.annotations.*; @Mapper public interface HelloMapper { @Insert(&quot;insert into user(id,username,password) values(0,&apos;zhangsan&apos;,&apos;1234&apos;)&quot;) void addClientUser(); } Service： import com.fsy.mapper.HelloMapper; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; import org.springframework.transaction.annotation.EnableTransactionManagement; import org.springframework.transaction.annotation.Propagation; import org.springframework.transaction.annotation.Transactional; @Service @EnableTransactionManagement public class HelloServer { @Autowired private HelloMapper helloMapper; // @Transactional(propagation = Propagation.NOT_SUPPORTED) //插入数据库里面没有回滚 @Transactional(propagation = Propagation.REQUIRED,rollbackFor=Exception.class)//数据没有存到数据库，但是数据库的自增变量+1了，说明执行成功了，但是回滚了 public void insertHello() throws Exception { helloMapper.addClientUser(); Thread.sleep(8000); throw new RuntimeException(); } } Controller： import com.fsy.server.HelloServer; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.RequestMapping; @Controller @RequestMapping(&quot;/hello&quot;) public class HelloController { @Autowired private HelloServer helloServer; @RequestMapping(&quot;/insert&quot;) public void insert() throws Exception { System.out.println(&quot;1111111111&quot;); helloServer.insertHello(); } } 启动类： import org.mybatis.spring.annotation.MapperScan; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.context.annotation.Bean; import org.springframework.transaction.annotation.EnableTransactionManagement; @EnableTransactionManagement @SpringBootApplication @MapperScan(&quot;com.fsy.mapper&quot;) public class App { public static void main(String[] args) { SpringApplication.run(App.class,args); } } 运行结果自己去验证下，这个回滚我用的navicat，能看到，每次运行都+1，但是数据库没有。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring源码分析之AOP]]></title>
    <url>%2F2017%2F11%2F06%2Fspring%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BAOP%2F</url>
    <content type="text"><![CDATA[AOP核心概念横切关注点：对哪些方法进行拦截，拦截后怎么处理，这些关注点称之为横切关注点切面（aspect）：类是对物体特征的抽象，切面就是对横切关注点的抽象连接点（joinpoint）：被拦截到的点，因为Spring只支持方法类型的连接点，所以在Spring中连接点指的就是被拦截到的方法，实际上连接点还可以是字段或者构造器切入点（pointcut）：对连接点进行拦截的定义通知（advice）：所谓通知指的就是指拦截到连接点之后要执行的代码，通知分为前置、后置、异常、最终、环绕通知五类目标对象：代理的目标对象织入（weave）：将切面应用到目标对象并导致代理对象创建的过程引入（introduction）：在不修改代码的前提下，引入可以在运行期为类动态地添加一些方法或字段 Spring对AOP的支持Spring中AOP代理由Spring的IOC容器负责生成、管理，其依赖关系也由IOC容器负责管理。因此，AOP代理可以直接使用容器中的其它bean实例作为目标，这种关系可由IOC容器的依赖注入提供。Spring创建代理的规则为： 1、默认使用Java动态代理来创建AOP代理，这样就可以为任何接口实例创建代理了2、当需要代理的类不是代理接口的时候，Spring会切换为使用CGLIB代理，也可强制使用CGLIB JDK动态代理首先直接调用就可以了，为什么还需要代理。采用代理模式可以有效的将具体的实现与调用方进行解耦，通过面向接口进行编码完全将具体的实现隐藏在内部。 静态代理先看看什么是静态代理。由程序员创建或工具生成代理类的源码，再编译代理类。所谓静态也就是在程序运行前就已经存在代理类的字节码文件，代理类和委托类的关系在运行前就确定了。首先创建一个接口和一个实现类。JDK代理都是基于接口的 public interface ISub { public void hello(String name); } public class SubImpl implements ISub { @Override public void hello(String name) { System.out.println(&quot;My name is &quot;+name); } } 然后写个代理类，也是实现了ISub public class SubProxy implements ISub{ ISub sub = new SubImpl(); @Override public void hello(String name) { System.out.println(&quot;====之前====&quot;); sub.hello(name); System.out.println(&quot;====之后====&quot;); } } 最后写客户端。这个Client只于Proxy交互，不需要去了解ISub和SubImpl里面的东西了。实现了解耦。 public class Client{ public static void main(String[] args) { SubProxy subProxy = new SubProxy(); subProxy.hello(&quot;lijia&quot;); } } 那么静态代理有什么缺点呢。 代理对象的一个接口只服务一种类型的对象，如果要代理的方法很多，那么必须要为每一种方法都进行代理，静态代理在程序规模稍大就无法胜任了。 如果接口增加一个方法，那么所有实现类和代理类都要增加这个方法。增加系统维护复杂度。 动态代理动态代理的思维模式与之前的一般模式是一样的，也是面向接口进行编码，创建代理类将具体类隐藏解耦，不同之处在于代理类的创建时机不同，动态代理需要在运行时因需实时创建。接口和实现类还是上面的。主要是代理类。代理类实现了InvocationHandler。 import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; public class DynamicSubProxy implements InvocationHandler { private Object object; public DynamicSubProxy(Object o){ this.object = o; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(&quot;====之前====&quot;); method.invoke(object,args); System.out.println(&quot;====之后====&quot;); return null; } }测试类 import java.lang.reflect.InvocationHandler; import java.lang.reflect.Proxy; public class DynamicTest { public static void main(String[] args) { ISub sub = new SubImpl(); InvocationHandler ih = new DynamicSubProxy(sub); ISub o = (ISub) Proxy.newProxyInstance(ISub.class.getClassLoader(),new Class[]{ISub.class},ih); o.hello(&quot;lijia&quot;); } } 总结： 首先JDK的动态代理是基本接口实现的。因为通过使用接口指向实现类的实例的多态实现方式，可以有效的将具体实现类的细节向调用方完全隐藏（调用方调用的是代理类中的方法，而不是实现类中的方法）。面向接口编程，利用java的多态特性，实现程序代码的解耦 创建代理类的过程。静态代理和动态代理都需要创建代理类。但是创建的方式不一样。静态代理创建的代理类需要知道对哪个接口，哪个实现类来创建代理。而动态代理只需要实现一个固定的接口InvocationHandler 。 主要通过反射在运行期间创建。而静态代理之前就需要创建好。CGLIB代理JDK实现动态代理需要实现类通过接口定义业务方法，对于没有接口的类，如何实现动态代理呢，这就需要CGLIB代理 还是用上面的实现类，没有接口了 public class SubImpl1{ public void hello(String name) { System.out.println(&quot;My name is &quot;+name); } } cglib代理类 import org.springframework.cglib.proxy.Enhancer; import org.springframework.cglib.proxy.MethodInterceptor; import org.springframework.cglib.proxy.MethodProxy; import java.lang.reflect.Method; public class CglibProxy implements MethodInterceptor { private Enhancer enhancer = new Enhancer(); public Object getProxy(Class clazz){ //设置需要创建子类的类 enhancer.setSuperclass(clazz); enhancer.setCallback(this); //通过字节码技术动态创建子类实例 return enhancer.create(); } //实现MethodInterceptor接口方法 @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable { System.out.println(&quot;====之前====&quot;); //通过代理类调用父类中的方法 Object result = proxy.invokeSuper(obj, args); System.out.println(&quot;====之后====&quot;); return result; } } 客户端 public class CglibTest { public static void main(String[] args) { CglibProxy proxy = new CglibProxy(); SubImpl1 sub = (SubImpl1) proxy.getProxy(SubImpl1.class); sub.hello(&quot;lijia&quot;); } } 总结：CGLib创建的动态代理对象性能比JDK创建的动态代理对象的性能高不少，但是CGLib在创建代理对象时所花费的时间却比JDK多得多，所以对于单例的对象，因为无需频繁创建对象，用CGLib合适，反之，使用JDK方式要更为合适一些。同时，由于CGLib由于是采用动态创建子类的方法，对于final方法，无法进行代理。 AOP代码分析首先还是通过一个例子来看看。创建一个切面类 package aop.aspects; import java.util.Arrays; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.After; import org.aspectj.lang.annotation.Around; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Before; import org.springframework.stereotype.Component; @Component @Aspect public class MyAspect1 { public MyAspect1() { System.out.println(&quot;MyAspect1 created &quot;); } @Before(&quot;execution(* spring.services.*.*(..))&quot;) public void traceBusiness() { System.out.println( &quot;in spring advice &quot;); } @Before(&quot;execution(* spring.services.*.*(..))&quot;) public void traceBusiness(JoinPoint jp) { System.out.println(&quot;joinpoint [ &quot;+jp.getKind() + &quot; ,declaringTypeName &quot; + jp.getSignature().getDeclaringTypeName()+&quot;\r\n this &quot;+jp.getThis().getClass().getName() + &quot;\r\n,target:&quot; + jp.getTarget() + &quot; , method &quot; + jp.getSignature().getName() + &quot;,args:&quot; + Arrays.toString(jp.getArgs())); } @After(&quot;execution(* spring.services.*.*(..))&quot;) public void afterBusiness() { System.out.println( &quot;after aop&quot;); } @Around(&quot;execution(* spring.services.*.*(..))&quot;) public void traceBusiness(ProceedingJoinPoint jp) throws Throwable { System.out.println(&quot;before enter method &quot;+jp.getSignature().getName()); jp.proceed(jp.getArgs()); System.out.println(&quot;after enter method &quot;+jp.getSignature().getName()); } } 创建接口： package spring.services; public interface MyDemoServiceIntf { public void doBusinessBBB(boolean suc); } 创建MyDemoServiceIntf 实现类 package spring.services; import org.springframework.stereotype.Component; @Component(&quot;myTestService2&quot;) public class MyTestService2 { public MyTestService2() { System.out.println(&quot;MyTestService2 craeated &quot;+this); } public void doBusinessAAA(String[] args,boolean suc) { } public void doBusinessBBB(boolean suc) { System.out.println(&quot;=====进入了BBBBB&quot;); doBusinessCCC(); } public void doBusinessCCC() { System.out.println(&quot;=====CCCCCC&quot;); } } 配置类 import org.springframework.beans.factory.annotation.Configurable; import org.springframework.context.annotation.ComponentScan; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.EnableAspectJAutoProxy; @Configuration @ComponentScan(&quot;spring.services,aop.aspects&quot;) @EnableAspectJAutoProxy(proxyTargetClass=true,exposeProxy=true) //@EnableAspectJAutoProxy(proxyTargetClass=true) @Configurable public class MySpringConfig { public MySpringConfig() { System.out.println(&quot;MySpringConfig create d &quot;); } } 测试类 import org.springframework.context.annotation.AnnotationConfigApplicationContext; import spring.services.MyTestService2; public class Test4 { public static void main(String[] args) { AnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext(MySpringConfig.class); MyTestService2 mybean = (MyTestService2) ctx.getBean(&quot;myTestService2&quot;); mybean.doBusinessBBB(true); ctx.close(); } } 运行结果： 看结果顺序，首先是几个构造函数初始化。然后是进入@Around的System.out.println(“before enter method “+jp.getSignature().getName());再走了@Before，走完了之后执行业务代码，最后@After，然后走@Around的System.out.println(“after enter method “+jp.getSignature().getName()); 注解 arg() 限制连接点匹配参数为指定类型的执行方法； @args() 限制连接点匹配参数由指定注解标注的执行方法； execution() 用于匹配是连接点的执行方法； this() 限制连接点匹配AOP代理的bean引用为指定类型的类 target 限制连接点匹配目标对象为指定类型的类 @target() 限制连接点匹配特定的执行对象，这些对象对应的类要具有指定类型的注解 within() 限制连接点匹配指定的类型 @within() 限制连接点匹配特定注解所标注的类型 @annotation 限定匹配带有指定注解的连接点 总结Spring AOP使用的动态代理，所谓的动态代理就是说AOP框架不会去修改字节码，而是在内存中临时为方法生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。 Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。JDK动态代理的核心是InvocationHandler接口和Proxy类。 如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意，CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring源码分析IOC和DI]]></title>
    <url>%2F2017%2F11%2F02%2Fspring%E6%BA%90%E7%A0%81%E4%B9%8BIOC%E5%92%8CDI%2F</url>
    <content type="text"><![CDATA[看到一篇好文章http://www.jianshu.com/p/524748c83dde，所以自己也跟着走了一遍。 实例首先创建一个maven项目，引入spring的几个jar包 application.xml HelloWorld 测试类 IOC容器初始化过程根据上面的例子去理解IoC容器初始化过程： 初始化总过程： 资源定位（确定工厂创建和bean的配置文件） 资源装载（在文件系统路径上对IOC配置文件、bean配置进行加载） 资源解析（解析bean配置，解析xml元素） 生成bean（根据DOM资源解析成bean） 在IoC容器中注册（交给IoC容器管理，还有依赖注入的权限） 资源定位ApplicationContext ac = new ClassPathXmlApplicationContext(&quot;application.xml&quot;); 首先跟进去看看这段代码 继续走 public void refresh() throws BeansException, IllegalStateException { Object var1 = this.startupShutdownMonitor; synchronized(this.startupShutdownMonitor) { //调用容器准备刷新的方法，获取 容器的当时时间，同时给容器设置同步标识 this.prepareRefresh(); //告诉子类启动refreshBeanFactory()方法，Bean定义资源文件的载入从子类的refreshBeanFactory()方法启动 //并获取beanFactory ConfigurableListableBeanFactory beanFactory = this.obtainFreshBeanFactory(); //为BeanFactory配置容器特性，例如类加载器、事件处理器等 this.prepareBeanFactory(beanFactory); try { //为容器的某些子类指定特殊的BeanPost事件处理器 this.postProcessBeanFactory(beanFactory); //调用所有注册的BeanFactoryPostProcessor的Bean this.invokeBeanFactoryPostProcessors(beanFactory); //为BeanFactory注册BeanPost事件处理器. //BeanPostProcessor是Bean后置处理器，用于监听容器触发的事件 this.registerBeanPostProcessors(beanFactory); //初始化信息源，和国际化相关. this.initMessageSource(); //初始化容器事件传播器. this.initApplicationEventMulticaster(); //调用子类的某些特殊Bean初始化方法 this.onRefresh(); //为事件传播器注册事件监听器. this.registerListeners(); //初始化所有剩余的单态Bean. this.finishBeanFactoryInitialization(beanFactory); //初始化容器的生命周期事件处理器，并发布容器的生命周期事件 this.finishRefresh(); } catch (BeansException var9) { if(this.logger.isWarnEnabled()) { this.logger.warn(&quot;Exception encountered during context initialization - cancelling refresh attempt: &quot; + var9); } //销毁以创建的单态Bean this.destroyBeans(); //取消refresh操作，重置容器的同步标识. this.cancelRefresh(var9); throw var9; } finally { this.resetCommonCaches(); } } } 看 this.obtainFreshBeanFactory(); //关闭前面所有 bean 工厂，为新的上下文环境初始化一个新的 bean 工厂。 //这里需要子类(这里是AbstractRefreshableApplicationContext)来 协助完成资源位置定义 ,bean 载入和向 IOC 容器注册的过程 容器真正调用的是其子类AbstractRefreshableApplicationContext实现的 refreshBeanFactory()方法 protected ConfigurableListableBeanFactory obtainFreshBeanFactory() { this.refreshBeanFactory();//子类实现，调用子类的实现 ConfigurableListableBeanFactory beanFactory = this.getBeanFactory(); if(this.logger.isDebugEnabled()) { this.logger.debug(&quot;Bean factory for &quot; + this.getDisplayName() + &quot;: &quot; + beanFactory); } return beanFactory; } 继续看this.refreshBeanFactory(); //交给子类AbstractRefreshableApplicationContext //在这个方法中，先判断BeanFactory是否存在，如果存在则先销毁beans并关闭beanFactory， //接着创建DefaultListableBeanFactory，并调用loadBeanDefinitions(beanFactory)装载bean protected final void refreshBeanFactory() throws BeansException { if(this.hasBeanFactory()) { this.destroyBeans(); this.closeBeanFactory(); } try { //创建IoC容器 DefaultListableBeanFactory ex = this.createBeanFactory(); ex.setSerializationId(this.getId()); //对IoC容器进行定制化，如设置启动参数，开启注解的自动装配等 this.customizeBeanFactory(ex); //调用载入Bean定义的方法，主要这里使用了一个委派模式， //在当前类中只定义了抽象的loadBeanDefinitions方法，具体的实现调用子类容器 this.loadBeanDefinitions(ex); Object var2 = this.beanFactoryMonitor; synchronized(this.beanFactoryMonitor) { this.beanFactory = ex; } } catch (IOException var5) { throw new ApplicationContextException(&quot;I/O error parsing bean definition source for &quot; + this.getDisplayName(), var5); } } 总结：资源定位做的就是：确定工厂位置，执行工厂初始化并刷新，建立好bean资源加载路径。等待bean资源装载。 资源装载设置工厂配置，刷新容器之后，还要把bean配置给资源加载器。用this.loadBeanDefinitions(beanFactory);去解析。而解析交给子类去实现了。有下面几种情况进入AbstractXmlApplicationContext protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException { //从beanfactory拿到reader // 这里使用XMLBeanDefinitionReader来载入bean定义信息的XML文件 XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); //这里配置reader的环境，其中ResourceLoader是我们用来定位bean定义信息资源位置的 ///因为上下文本身实现了ResourceLoader接口，所以可以直接把上下文作为ResourceLoader传递给XmlBeanDefinitionReader。容器本身也是一个资源加载器 beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); //当Bean读取器读取Bean定义的Xml资源文件时，启用Xml的校验机制 this.initBeanDefinitionReader(beanDefinitionReader); //这里转到定义好的XmlBeanDefinitionReader中对载入bean信息进行处理 this.loadBeanDefinitions(beanDefinitionReader); } AbstractXmlApplicationContext职责为：对applicationContext.xml的解析操作，就是解析工厂的那个xmlAbstractBeanDefinitionReader职责为：从指定的资源加载bean定义，真正实现在其子类，这里是做了些兼容性错误处理。XmlBeanDefinitionReader是AbstractBeanDefinitionReader的子类，而且是一个真正的实现类 ，是实现BeanDefinitionReader接口的loadBeanDefinitions(Resource var1) 等方法的关键解析类。职责为：读取并真正解析 xml 文件。AbstractRefreshableApplicationContext中只定义了抽象的loadBeanDefinitions方法，容器真正调用的是其子类AbstractXmlApplicationContext对该方法的实现。（全局搜索SHIFT）进去this.loadBeanDefinitions(beanDefinitionReader);由于我们用的是application.xml方式，configResource是null，所以走了getConfigLocation() 走下去进入了AbstractBeanDefinitionReader public int loadBeanDefinitions(String location, Set&lt;Resource&gt; actualResources) throws BeanDefinitionStoreException { ResourceLoader resourceLoader = this.getResourceLoader(); if (resourceLoader == null) {//如果没有找到我们需要的ResourceLoader，直接抛出异常 throw new BeanDefinitionStoreException(&quot;Cannot import bean definitions from location [&quot; + location + &quot;]: no ResourceLoader available&quot;); } else { int loadCount; if (!(resourceLoader instanceof ResourcePatternResolver)) { // 这里处理我们在定义位置时使用的各种pattern,需要ResourcePatternResolver来完成 Resource resource = resourceLoader.getResource(location); loadCount = this.loadBeanDefinitions((Resource)resource); if (actualResources != null) { actualResources.add(resource); } if (this.logger.isDebugEnabled()) { this.logger.debug(&quot;Loaded &quot; + loadCount + &quot; bean definitions from location [&quot; + location + &quot;]&quot;); } return loadCount; } else { try { // 这里通过ResourceLoader来完成位置定位 Resource[] resources = ((ResourcePatternResolver)resourceLoader).getResources(location); // 这里已经把一个位置定义转化为Resource接口，可以供XmlBeanDefinitionReader来使用了 loadCount = this.loadBeanDefinitions(resources); if (actualResources != null) { Resource[] var6 = resources; int var7 = resources.length; for(int var8 = 0; var8 &lt; var7; ++var8) { Resource resource = var6[var8]; actualResources.add(resource); } } if (this.logger.isDebugEnabled()) { this.logger.debug(&quot;Loaded &quot; + loadCount + &quot; bean definitions from location pattern [&quot; + location + &quot;]&quot;); } return loadCount; } catch (IOException var10) { throw new BeanDefinitionStoreException(&quot;Could not resolve bean definition resource pattern [&quot; + location + &quot;]&quot;, var10); } } } } AbstractBeanDefinitionReader的loadBeanDefinitions方法源码分析可以看出该方法做了以下两件事：（1）首先，调用资源加载器的获取资源方法resourceLoader.getResource(location)，获取到要加载的资源。（2）其次，真正执行加载功能是其子类XmlBeanDefinitionReader实现的loadBeanDefinitions方法。此时调用的是DefaultResourceLoader中的getSource()方法定位Resource。然后我们再仔细看下各个类想拿到资源加载器就是通过getResourceLoader，拿到AbstractBeanDefinitionReader类定义的resourceLoader。这样的话，我们可通过此方式在工程spring下的任何地方拿到资源加载器，“随处加载”了。 public interface ResourceLoader { String CLASSPATH_URL_PREFIX = &quot;classpath:&quot;; Resource getResource(String var1); ClassLoader getClassLoader(); } 总结：资源加载就是根据之前确定好的bean资源配置路径，拿到资源、拿到加载器，并把bean配置丢进XmlBeanDefinitionReader。等待Bean资源解析。 Bean资源解析刚刚提到的XmlBeanDefinitionReader就是真正解析xml的类。 //这里是载入XML形式Bean定义资源文件方法 public int loadBeanDefinitions(EncodedResource encodedResource) throws BeanDefinitionStoreException { Assert.notNull(encodedResource, &quot;EncodedResource must not be null&quot;); if(this.logger.isInfoEnabled()) { this.logger.info(&quot;Loading XML bean definitions from &quot; + encodedResource.getResource()); } //获取当前的线程变量，它是用于保存处理的resource的 Set&lt;EncodedResource&gt; currentResources = (Set)this.resourcesCurrentlyBeingLoaded.get(); if(currentResources == null) { currentResources = new HashSet(4); this.resourcesCurrentlyBeingLoaded.set(currentResources);//保存当前的resource } if(!((Set)currentResources).add(encodedResource)) { throw new BeanDefinitionStoreException(&quot;Detected cyclic loading of &quot; + encodedResource + &quot; - check your import definitions!&quot;); } else { int var5; try { //将资源文件转为InputStream的IO流 InputStream inputStream = encodedResource.getResource().getInputStream(); try { //从InputStream中得到XML的解析源 InputSource inputSource = new InputSource(inputStream); if(encodedResource.getEncoding() != null) { inputSource.setEncoding(encodedResource.getEncoding()); } //这里是具体的读取过程 var5 = this.doLoadBeanDefinitions(inputSource, encodedResource.getResource()); } finally { //关闭从Resource中得到的IO流 inputStream.close(); } } catch (IOException var15) { throw new BeanDefinitionStoreException(&quot;IOException parsing XML document from &quot; + encodedResource.getResource(), var15); } finally { ((Set)currentResources).remove(encodedResource); if(((Set)currentResources).isEmpty()) { this.resourcesCurrentlyBeingLoaded.remove(); } } return var5; } } //从特定XML文件中实际载入Bean定义资源的方法 ，就是转成dom对象后交给这里去进一步处理从而转换出bean protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException { try { //将XML文件转换为DOM对象，解析过程由documentLoader实现 Document doc = this.doLoadDocument(inputSource, resource); //这里是启动对Bean定义解析的详细过程，该解析过程会用到Spring的Bean配置规则 return this.registerBeanDefinitions(doc, resource); } catch (BeanDefinitionStoreException var4) { throw var4; }。。。 } } 进入 this.doLoadDocument(inputSource, resource);走下去有个DocumentLoader接口，进入它的实现类DefaultDocumentLoader public Document loadDocument(InputSource inputSource, EntityResolver entityResolver, ErrorHandler errorHandler, int validationMode, boolean namespaceAware) throws Exception { //创建文件解析器工厂 DocumentBuilderFactory factory = this.createDocumentBuilderFactory(validationMode, namespaceAware); if (logger.isDebugEnabled()) { logger.debug(&quot;Using JAXP provider [&quot; + factory.getClass().getName() + &quot;]&quot;); } //创建文档解析器 DocumentBuilder builder = this.createDocumentBuilder(factory, entityResolver, errorHandler); //解析Spring的Bean定义资源 return builder.parse(inputSource); } //调用了Javaee的JAXP标准，根据定位的Bean定义资源文件，加载读入并转换成为Document对象过程完成 protected DocumentBuilderFactory createDocumentBuilderFactory(int validationMode, boolean namespaceAware) throws ParserConfigurationException { DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); factory.setNamespaceAware(namespaceAware); if (validationMode != 0) { factory.setValidating(true); if (validationMode == 3) { factory.setNamespaceAware(true); try { factory.setAttribute(&quot;http://java.sun.com/xml/jaxp/properties/schemaLanguage&quot;, &quot;http://www.w3.org/2001/XMLSchema&quot;); } catch (IllegalArgumentException var6) { 。。。 pcex.initCause(var6); throw pcex; } } } return factory; } 总结：Bean资源解析就是，先通过 XML解析器讲Bean定义资源文件转换得到Document对象，但是这堆Document对象没有按照spring的Bean规则的，所以不可直接转换成bean对象。然后完成XML解析变成Document对象后，就调用spring的解析方法按照Spring的Bean规则去对Document进行解析，生成Bean对象。 生成bean在XmlBeanDefinitionReader中有一个oLoadBeanDefinitions方法里面的return this.registerBeanDefinitions(doc, resource);进去 //按照Spring的Bean语义要求 将Bean 定 义 资源解析并转换为容器内部数据结构 public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException { //得到BeanDefinitionDocumentReader来对xml格式的BeanDefinition解析 BeanDefinitionDocumentReader documentReader = this.createBeanDefinitionDocumentReader(); //读取环境的配置设置 documentReader.setEnvironment(this.getEnvironment()); //获得容器中注册的Bean数量 int countBefore = this.getRegistry().getBeanDefinitionCount(); //解析过程入口，这里使用了委派模式，BeanDefinitionDocumentReader只是个接口，//具体的解析实现过程有实现类DefaultBeanDefinitionDocumentReader完成 documentReader.registerBeanDefinitions(doc, this.createReaderContext(resource)); //统计解析的Bean数量 return this.getRegistry().getBeanDefinitionCount() - countBefore; } //在此方法真正去转化document对象成为bean protected BeanDefinitionDocumentReader createBeanDefinitionDocumentReader() { return (BeanDefinitionDocumentReader)BeanDefinitionDocumentReader.class.cast(BeanUtils.instantiateClass(this.documentReaderClass)); } 跟着documentReader.registerBeanDefinitions(doc, this.createReaderContext(resource));进去是一个BeanDefinitionDocumentReader接口，然后去它的实现类DefaultBeanDefinitionDocumentReader public void registerBeanDefinitions(Document doc, XmlReaderContext readerContext) { this.readerContext = readerContext; this.logger.debug(&quot;Loading bean definitions&quot;); Element root = doc.getDocumentElement(); this.doRegisterBeanDefinitions(root); } 在这个类进行详细的document元素解析成我们平常工程用的bean。 在IoC容器中注册在类DefaultBeanDefinitionDocumentReader生成bean后必然会丢给IoC容器去注册，交给它管理。根据标签去选择bean元素生成法 private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) { if (delegate.nodeNameEquals(ele, &quot;import&quot;)) { this.importBeanDefinitionResource(ele); } else if (delegate.nodeNameEquals(ele, &quot;alias&quot;)) { this.processAliasRegistration(ele); //走这里 } else if (delegate.nodeNameEquals(ele, &quot;bean&quot;)) { this.processBeanDefinition(ele, delegate); } else if (delegate.nodeNameEquals(ele, &quot;beans&quot;)) { this.doRegisterBeanDefinitions(ele); } } //进入解析和注册分发啦 protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) { BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if(bdHolder != null) { bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try { //注册分发： 继续追踪 BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, this.getReaderContext().getRegistry()); } catch (BeanDefinitionStoreException var5) { this.getReaderContext().error(&quot;Failed to register bean definition with name &apos;&quot; + bdHolder.getBeanName() + &quot;&apos;&quot;, ele, var5); } this.getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); } } 跟着走进入BeanDefinitionReaderUtils public static void registerBeanDefinition(BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException { //得到需要 注册 的 bean名字 String beanName = definitionHolder.getBeanName(); //开始注册。锁定registerBeanDefinition方法 registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); // 别名也是可以 通过IOC容器和bean联系起来的进行注册 String[] aliases = definitionHolder.getAliases(); if(aliases != null) { String[] var4 = aliases; int var5 = aliases.length; for(int var6 = 0; var6 &lt; var5; ++var6) { String alias = var4[var6]; registry.registerAlias(beanName, alias); } } } 然后根据registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition());点进接口BeanDefinitionRegistry。找到BeanDefinitionRegistry的实现类DefaultListableBeanFactory。 public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException { //一堆验证beanDefinition的正确性 。。。 //先看看在容器里是不是已经有了同名的bean,如果有抛出异常。 BeanDefinition oldBeanDefinition = (BeanDefinition)this.beanDefinitionMap.get(beanName); if (oldBeanDefinition != null) { if (!this.isAllowBeanDefinitionOverriding()) { throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, &quot;Cannot register bean definition [&quot; + beanDefinition + &quot;] for bean &apos;&quot; + beanName + &quot;&apos;: There is already [&quot; + oldBeanDefinition + &quot;] bound.&quot;); } if (oldBeanDefinition.getRole() &lt; beanDefinition.getRole()) { if (this.logger.isWarnEnabled()) { this.logger.warn(&quot;Overriding user-defined bean definition for bean &apos;&quot; + beanName + &quot;&apos; with a framework-generated bean definition: replacing [&quot; + oldBeanDefinition + &quot;] with [&quot; + beanDefinition + &quot;]&quot;); } } else if (!beanDefinition.equals(oldBeanDefinition)) { if (this.logger.isInfoEnabled()) { this.logger.info(&quot;Overriding bean definition for bean &apos;&quot; + beanName + &quot;&apos; with a different definition: replacing [&quot; + oldBeanDefinition + &quot;] with [&quot; + beanDefinition + &quot;]&quot;); } } else if (this.logger.isDebugEnabled()) { this.logger.debug(&quot;Overriding bean definition for bean &apos;&quot; + beanName + &quot;&apos; with an equivalent definition: replacing [&quot; + oldBeanDefinition + &quot;] with [&quot; + beanDefinition + &quot;]&quot;); } this.beanDefinitionMap.put(beanName, beanDefinition); } else { if (this.hasBeanCreationStarted()) { Map var4 = this.beanDefinitionMap; synchronized(this.beanDefinitionMap) { this.beanDefinitionMap.put(beanName, beanDefinition); List&lt;String&gt; updatedDefinitions = new ArrayList(this.beanDefinitionNames.size() + 1); updatedDefinitions.addAll(this.beanDefinitionNames); updatedDefinitions.add(beanName); this.beanDefinitionNames = updatedDefinitions; if (this.manualSingletonNames.contains(beanName)) { Set&lt;String&gt; updatedSingletons = new LinkedHashSet(this.manualSingletonNames); updatedSingletons.remove(beanName); this.manualSingletonNames = updatedSingletons; } } } else { //这里把bean的名字和Bean定义联系起来放到一个HashMap中去,IOC容器通过这个Map来维护容器里的Bean定义信息。 this.beanDefinitionMap.put(beanName, beanDefinition); //没重复就把bean的名字加到IOC容器中去 this.beanDefinitionNames.add(beanName); this.manualSingletonNames.remove(beanName); } this.frozenBeanDefinitionNames = null; } if (oldBeanDefinition != null || this.containsSingleton(beanName)) { this.resetBeanDefinition(beanName); } } 总结：在IoC容器中注册就是把beandefinition丢给工厂用hashmap存好 总结IOC容器初始化流程 通过setConfigLocations载入spring配置文件。 初始化容器入口通过refresh方法，进入AbstractApplicationContext实现的refresh方法 然后通过obtainFreshBeanFactory方法进入子类AbstractRefreshableApplicationContext实现的refreshBeanFactory刷新一个容器工厂 在此创建了DefaultListableBeanFactory类，并调用loadBeanDefinitions(beanFactory)装载bean定义 接着以AbstractRefreshableApplicationContext为中心回到此类，进入其子类AbstractXmlApplicationContext实现的loadBeanDefinitions方法。对applicationContext.xml的解析操作，就是解析工厂的那个xml 再接着通过AbstractXmlApplicationContext的loadBeanDefinitions进入到AbstractBeanDefinitionReader类的loadBeanDefinitions。通过获取资源方法resourceLoader.getResource(location)，获取到要加载的资源。再真正执行加载功能是其子类XmlBeanDefinitionReader实现的loadBeanDefinitions方法 接着进入XmlBeanDefinitionReader中的loadBeanDefinitions。（XmlBeanDefinitionReader通过调用其父类中调用的DefaultResourceLoader的getResource方法获取要加载的资源）DocumentLoader将Bean定义资源转换成Document对象 doLoadBeanDefinitions中进入DefaultBeanDefinitionDocumentReader类的registerBeanDefinitions 解析 Document对象 解析完后，调用DefaultListableBeanFactory类中使用一个HashMap的集合对象存放IoC容器中注册解析的BeanDefinition IoC容器依赖注入过程Spring把loadBean和依赖注入分成两个基本的过程，一个是在启动容器的时候完成，建立起一系列 BeanDefinition,这些定义里面同时都包含了对bean依赖关系的描述，不过这里并没有对bean进行实例化，真正实例化的时候是在客户通过容器使用这些bean的时候 - 也就是getbean的时候。这个时候IOC容器根据需要会建立起一系列bean的实例和完成依赖注入。 BeanFactory接口定义了Spring IoC容器的基本功能规范，是Spring IoC容器所应遵守的最底层和最基本的编程规范。BeanFactory接口中定义了几个getBean方法，就是用户向IoC容器索取管理的Bean的方法， 从实例代码的getBean进入，到最后是上图的BeanFactory，然后进入它的实现类AbstractBeanFactory protected &lt;T&gt; T doGetBean(String name, Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException { //根据指定的名称获取被管理Bean的名称，剥离指定名称中对容器的相关依赖 //如果指定的是别名，将别名转换为规范的Bean名称 final String beanName = this.transformedBeanName(name); //先从缓存中取是否已经有被创建过的单态类型的Bean，对于单态模式的Bean整 //个IoC容器中只创建一次，不需要重复创建 Object sharedInstance = this.getSingleton(beanName); Object bean; if (sharedInstance != null &amp;&amp; args == null) { if (this.logger.isDebugEnabled()) { //如果指定名称的Bean在容器中已有单态模式的Bean被创建，直接返回 //已经创建的Bean if (this.isSingletonCurrentlyInCreation(beanName)) { this.logger.debug(&quot;Returning eagerly cached instance of singleton bean &apos;&quot; + beanName + &quot;&apos; that is not fully initialized yet - a consequence of a circular reference&quot;); } else { this.logger.debug(&quot;Returning cached instance of singleton bean &apos;&quot; + beanName + &quot;&apos;&quot;); } } //获取给定Bean的实例对象，主要是完成FactoryBean的相关处理 //注意：BeanFactory是管理容器中Bean的工厂，而FactoryBean是创建创建对象的工厂Bean，两者之间有区别 bean = this.getObjectForBeanInstance(sharedInstance, name, beanName, (RootBeanDefinition)null); } else { //缓存没有正在创建的单态模式Bean //缓存中已经有已经创建的原型模式Bean，但是由于循环引用的问题导致实 //例化对象失败 if (this.isPrototypeCurrentlyInCreation(beanName)) { throw new BeanCurrentlyInCreationException(beanName); } //对IoC容器中是否存在指定名称的BeanDefinition进行检查，首先检查是否 //能在当前的BeanFactory中获取的所需要的Bean，如果不能则委托当前容器 //的父级容器去查找，如果还是找不到则沿着容器的继承体系向父级容器查找 BeanFactory parentBeanFactory = this.getParentBeanFactory(); //当前容器的父级容器存在，且当前容器中不存在指定名称的Bean if (parentBeanFactory != null &amp;&amp; !this.containsBeanDefinition(beanName)) { String nameToLookup = this.originalBeanName(name); if (args != null) { //解析指定Bean名称的原始名称 return parentBeanFactory.getBean(nameToLookup, args); } //委派父级容器根据指定名称和类型查找 return parentBeanFactory.getBean(nameToLookup, requiredType); } //创建的Bean是否需要进行类型验证，一般不需要 if (!typeCheckOnly) { //向容器标记指定的Bean已经被创建 this.markBeanAsCreated(beanName); } try { //根据指定Bean名称获取其父级的Bean定义，主要解决Bean继承时子类 //合并父类公共属性问题 final RootBeanDefinition mbd = this.getMergedLocalBeanDefinition(beanName); this.checkMergedBeanDefinition(mbd, beanName, args); //获取当前Bean所有依赖Bean的名称 String[] dependsOn = mbd.getDependsOn(); String[] var11; //如果当前Bean有依赖Bean if (dependsOn != null) { var11 = dependsOn; int var12 = dependsOn.length; for(int var13 = 0; var13 &lt; var12; ++var13) { String dep = var11[var13]; if (this.isDependent(beanName, dep)) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Circular depends-on relationship between &apos;&quot; + beanName + &quot;&apos; and &apos;&quot; + dep + &quot;&apos;&quot;); } //把被依赖Bean注册给当前依赖的Bean this.registerDependentBean(dep, beanName); //递归调用getBean方法，获取当前Bean的依赖Bean this.getBean(dep); } } //创建单态模式Bean的实例对象 if (mbd.isSingleton()) { //这里使用了一个匿名内部类，创建Bean实例对象，并且注册给所依赖的对象 sharedInstance = this.getSingleton(beanName, new ObjectFactory&lt;Object&gt;() { public Object getObject() throws BeansException { try { //创建一个指定Bean实例对象，如果有父级继承，则合并子//类和父类的定义 return AbstractBeanFactory.this.createBean(beanName, mbd, args); } catch (BeansException var2) { //显式地从容器单态模式Bean缓存中清除实例对象 AbstractBeanFactory.this.destroySingleton(beanName); throw var2; } } }); //获取给定Bean的实例对象 bean = this.getObjectForBeanInstance(sharedInstance, name, beanName, mbd); //IoC容器创建原型模式Bean实例对象 } else if (mbd.isPrototype()) { var11 = null; //原型模式(Prototype)是每次都会创建一个新的对象 Object prototypeInstance; try { //回调beforePrototypeCreation方法，默认的功能是注册当前创//建的原型对象 this.beforePrototypeCreation(beanName); //创建指定Bean对象实例 prototypeInstance = this.createBean(beanName, mbd, args); } finally { //回调afterPrototypeCreation方法，默认的功能告诉IoC容器指//定Bean的原型对象不再创建了 this.afterPrototypeCreation(beanName); } //获取给定Bean的实例对象 bean = this.getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); } else { //要创建的Bean既不是单态模式，也不是原型模式，则根据Bean定义资源中 //配置的生命周期范围，选择实例化Bean的合适方法，这种在Web应用程序中 //比较常用，如：request、session、application等生命周期 String scopeName = mbd.getScope(); Scope scope = (Scope)this.scopes.get(scopeName); //Bean定义资源中没有配置生命周期范围，则Bean定义不合法 if (scope == null) { throw new IllegalStateException(&quot;No Scope registered for scope name &apos;&quot; + scopeName + &quot;&apos;&quot;); } try { //这里又使用了一个匿名内部类，获取一个指定生命周期范围的实例 Object scopedInstance = scope.get(beanName, new ObjectFactory&lt;Object&gt;() { public Object getObject() throws BeansException { AbstractBeanFactory.this.beforePrototypeCreation(beanName); Object var1; try { var1 = AbstractBeanFactory.this.createBean(beanName, mbd, args); } finally { AbstractBeanFactory.this.afterPrototypeCreation(beanName); } return var1; } }); //获取给定Bean的实例对象 bean = this.getObjectForBeanInstance(scopedInstance, name, beanName, mbd); } catch (IllegalStateException var21) { throw new BeanCreationException(beanName, &quot;Scope &apos;&quot; + scopeName + &quot;&apos; is not active for the current thread; consider defining a scoped proxy for this bean if you intend to refer to it from a singleton&quot;, var21); } } } catch (BeansException var23) { this.cleanupAfterBeanCreationFailure(beanName); throw var23; } } //对创建的Bean实例对象进行类型检查 if (requiredType != null &amp;&amp; bean != null &amp;&amp; !requiredType.isAssignableFrom(bean.getClass())) { try { return this.getTypeConverter().convertIfNecessary(bean, requiredType); } catch (TypeMismatchException var22) { if (this.logger.isDebugEnabled()) { this.logger.debug(&quot;Failed to convert bean &apos;&quot; + name + &quot;&apos; to required type &apos;&quot; + ClassUtils.getQualifiedName(requiredType) + &quot;&apos;&quot;, var22); } throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); } } else { return bean; } } 上面，我们可以清楚的看见在创建实例是做了判断 如果Bean定义的单态模式(Singleton)，则容器在创建之前先从缓存中查找，以确保整个容器中只存在一个实例对象 如果Bean定义的是原型模式(Prototype)，则容器每次都会创建一个新的实例对象。 两者都不是，则根据Bean定义资源中配置的生命周期范围，选择实例化Bean的合适方法，这种在Web应用程序中 比较常用，如：request、session、application等生命周期 上面的源码只是定义了根据Bean定义的模式，采取的不同创建Bean实例对象的策略，具体的Bean实例对象的创建过程由实现了ObejctFactory接口的匿名内部类的createBean方法完成，ObejctFactory使用委派模式，具体的Bean实例创建过程交由其实现类AbstractAutowireCapableBeanFactory完成，我们继续分析AbstractAutowireCapableBeanFactory的createBean方法的源码，理解其创建Bean实例的具体实现过程。 //创建Bean实 例对象 protected Object createBean(String beanName, RootBeanDefinition mbd, Object[] args) throws BeanCreationException { if (this.logger.isDebugEnabled()) { this.logger.debug(&quot;Creating instance of bean &apos;&quot; + beanName + &quot;&apos;&quot;); } RootBeanDefinition mbdToUse = mbd; //判断需要创建的Bean是否可以实例化，即是否可以通过当前的类加载器加载 Class&lt;?&gt; resolvedClass = this.resolveBeanClass(mbd, beanName, new Class[0]); //校验和准备Bean中的方法覆盖 if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) { mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); } try { mbdToUse.prepareMethodOverrides(); } catch (BeanDefinitionValidationException var7) { throw new BeanDefinitionStoreException(mbdToUse.getResourceDescription(), beanName, &quot;Validation of method overrides failed&quot;, var7); } Object beanInstance; try { //如果Bean配置了初始化前和初始化后的处理器，则试图返回一个需要创建Bean的代理对象 beanInstance = this.resolveBeforeInstantiation(beanName, mbdToUse); if (beanInstance != null) { return beanInstance; } } catch (Throwable var8) { throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, &quot;BeanPostProcessor before instantiation of bean failed&quot;, var8); } //真正创建Bean的入口 beanInstance = this.doCreateBean(beanName, mbdToUse, args); if (this.logger.isDebugEnabled()) { this.logger.debug(&quot;Finished creating instance of bean &apos;&quot; + beanName + &quot;&apos;&quot;); } return beanInstance; } 进入doCreateBean //真正创建bean的方法 protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, Object[] args) { //封装被创建的Bean对象 BeanWrapper instanceWrapper = null; if(mbd.isSingleton()) {//单态模式的Bean，先从容器中缓存中获取同名Bean instanceWrapper = (BeanWrapper)this.factoryBeanInstanceCache.remove(beanName); } //容器没有的话 if(instanceWrapper == null) { //创建实例对象 instanceWrapper = this.createBeanInstance(beanName, mbd, args); } final Object bean = instanceWrapper != null?instanceWrapper.getWrappedInstance():null; //获取实例化对象的类型 Class&lt;?&gt; beanType = instanceWrapper != null?instanceWrapper.getWrappedClass():null; Object var7 = mbd.postProcessingLock; //调用PostProcessor后置处理器 synchronized(mbd.postProcessingLock) { if(!mbd.postProcessed) { this.applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); mbd.postProcessed = true; } } //向容器中缓存单态模式的Bean对象，以防循环引用 boolean earlySingletonExposure = mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; this.isSingletonCurrentlyInCreation(beanName); if(earlySingletonExposure) { if(this.logger.isDebugEnabled()) { this.logger.debug(&quot;Eagerly caching bean &apos;&quot; + beanName + &quot;&apos; to allow for resolving potential circular references&quot;); } //这里是一个匿名内部类，为了防止循环引用，尽早持有对象的引用 this.addSingletonFactory(beanName, new ObjectFactory&lt;Object&gt;() { public Object getObject() throws BeansException { return AbstractAutowireCapableBeanFactory.this.getEarlyBeanReference(beanName, mbd, bean); } }); } //Bean对象的初始化，依赖注入在此触发 //这个exposedObject在初始化完成之后返回作为依赖注入完成后的Bean Object exposedObject = bean; try { //将Bean实例对象封装，并且Bean定义中配置的属性值赋值给实例对象 this.populateBean(beanName, mbd, instanceWrapper); if(exposedObject != null) { //初始化Bean对象 exposedObject = this.initializeBean(beanName, exposedObject, mbd); } } catch (Throwable var17) { 。。。 } if(earlySingletonExposure) { //获取指定名称的已注册的单态模式Bean对象 Object earlySingletonReference = this.getSingleton(beanName, false); if(earlySingletonReference != null) { //根据名称获取的以注册的Bean和正在实例化的Bean是同一个 if(exposedObject == bean) { //当前实例化的Bean初始化完成 exposedObject = earlySingletonReference; } else if(!this.allowRawInjectionDespiteWrapping &amp;&amp; this.hasDependentBean(beanName)) {//当前Bean依赖其他Bean，并且当发生循环引用时不允许新创建实例对象 String[] dependentBeans = this.getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet(dependentBeans.length); String[] var12 = dependentBeans;//用来暂存当前bean int var13 = dependentBeans.length; //获取当前Bean所依赖的其他Bean for(int var14 = 0; var14 &lt; var13; ++var14) { String dependentBean = var12[var14]; //对依赖Bean进行类型检查 if(!this.removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) { actualDependentBeans.add(dependentBean); } } if(!actualDependentBeans.isEmpty()) { 。。。 } } } } //注册完成依赖注入的Bean try { this.registerDisposableBeanIfNecessary(beanName, bean, mbd); return exposedObject; } catch (BeanDefinitionValidationException var16) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Invalid destruction signature&quot;, var16); } } 除了判断和校验之外，真正实现的是createBeanInstance：生成Bean所包含的Java对象实例。populateBean ：对Bean属性的依赖注入进行处理。进入createBeanInstance方法 //创建Bean的实例对象 protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) { //检查确认Bean是可实例化的 Class&lt;?&gt; beanClass = this.resolveBeanClass(mbd, beanName, new Class[0]); //使用工厂方法对Bean进行实例化 if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Bean class isn&apos;t public, and non-public access not allowed: &quot; + beanClass.getName()); } else if (mbd.getFactoryMethodName() != null) { //调用工厂方法实例化 return this.instantiateUsingFactoryMethod(beanName, mbd, args); } else {//使用容器的自动装配方法进行实例化 boolean resolved = false; boolean autowireNecessary = false; if (args == null) { Object var7 = mbd.constructorArgumentLock; synchronized(mbd.constructorArgumentLock) { if (mbd.resolvedConstructorOrFactoryMethod != null) { resolved = true; //决定是否使用自动装配的构造器 autowireNecessary = mbd.constructorArgumentsResolved; } } } //autowireConstructor构造器方法配置了自动装配属性，使用容器的自动装配实例化，容器的自动装配是根据参数类型匹配Bean的构造方法 if (resolved) { //根据标记位autowireNecessary而决定采用无参构造器还是自动装配构造器 return autowireNecessary ? this.autowireConstructor(beanName, mbd, (Constructor[])null, (Object[])null) : this.instantiateBean(beanName, mbd); } else { //使用Bean的构造方法进行实例化 Constructor&lt;?&gt;[] ctors = this.determineConstructorsFromBeanPostProcessors(beanClass, beanName); //根据是否有参数还是已经配置了自动装配模式，去选择构造器，无参构造器还是自动装配构造器。 return ctors == null &amp;&amp; mbd.getResolvedAutowireMode() != 3 &amp;&amp; !mbd.hasConstructorArgumentValues() &amp;&amp; ObjectUtils.isEmpty(args) ? this.instantiateBean(beanName, mbd) : this.autowireConstructor(beanName, mbd, ctors, args); } } } 进入无参构造器instantiateBean //使用默认的无参构造方法实例化Bean对象 protected BeanWrapper instantiateBean(final String beanName, final RootBeanDefinition mbd) { try { Object beanInstance; //获取系统的安全管理接口，JDK标准的安全管理API if(System.getSecurityManager() != null) { //这里是一个匿名内置类，根据实例化策略创建实例对象 beanInstance = AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() { public Object run() { return AbstractAutowireCapableBeanFactory.this.getInstantiationStrategy().instantiate(mbd, beanName, AbstractAutowireCapableBeanFactory.this); } }, this.getAccessControlContext()); } else { //将实例化的对象封装起来 beanInstance = this.getInstantiationStrategy().instantiate(mbd, beanName, this); } BeanWrapper bw = new BeanWrapperImpl(beanInstance); this.initBeanWrapper(bw); return bw; } catch (Throwable var6) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Instantiation of bean failed&quot;, var6); } } 我们都看到了，无论什么调用什么构造器，返回的都是统一的BeanWrapper。BeanWrapper相当于一个代理器，Spring通过BeanWrapper完成Bean属性的填充工作。在Bean实例被InstantiationStrategy创建出来之后，容器主控程序将Bean实例通过BeanWrapper包装起来。 BeanWrapper还有两个顶级类接口，分别是PropertyAccessor和PropertyEditorRegistry。PropertyAccessor接口定义了各种访问Bean属性的方法，如setPropertyValue(String,Object)，setPropertyValues(PropertyValues pvs)等，而PropertyEditorRegistry是属性编辑器的注册表。所以BeanWrapper实现类BeanWrapperImpl具有了三重身份： 1）Bean包裹器； 2）属性访问器； 3）属性编辑器注册表。 在注入过程中： createBean开始调用populateBean方法.首先进行自动装配模式的处理,也就是说对BeanDefiniton中定义自动装配模式的属性进行调整.比如定义了AUTOWIRE_BY_NAME的属性会相应找到匹配该命名的bean.并且将该被检索到的bean实例值给property,当然这里也肯定通过getBean方法来获取这个需要自动装配的bean实例,并且在BeanWrapper中包装 再看看populateBean：对Bean的属性依赖注入的处理，分为两个部分属性值解析和注入。 //将Bean属性设置到生成的实例对象上 protected void populateBean(String beanName, RootBeanDefinition mbd, BeanWrapper bw) { //获取容器在解析Bean定义资源时为BeanDefiniton中设置的属性值 PropertyValues pvs = mbd.getPropertyValues(); //实例对象为null if(bw == null) { //属性值不为空 if(!((PropertyValues)pvs).isEmpty()) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Cannot apply property values to null instance&quot;); } } else { //在设置属性之前调用Bean的PostProcessor后置处理器 boolean continueWithPropertyPopulation = true; if(!mbd.isSynthetic() &amp;&amp; this.hasInstantiationAwareBeanPostProcessors()) { Iterator var6 = this.getBeanPostProcessors().iterator(); while(var6.hasNext()) { BeanPostProcessor bp = (BeanPostProcessor)var6.next(); if(bp instanceof InstantiationAwareBeanPostProcessor) { InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor)bp; if(!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) { continueWithPropertyPopulation = false; break; } } } } //依赖注入开始，首先处理autowire自动装配的注入 if(continueWithPropertyPopulation) { if(mbd.getResolvedAutowireMode() == 1 || mbd.getResolvedAutowireMode() == 2) { MutablePropertyValues newPvs = new MutablePropertyValues((PropertyValues)pvs); //对autowire自动装配的处理，根据Bean名称自动装配注入 if(mbd.getResolvedAutowireMode() == 1) { this.autowireByName(beanName, mbd, bw, newPvs); } //根据Bean类型自动装配注入 if(mbd.getResolvedAutowireMode() == 2) { this.autowireByType(beanName, mbd, bw, newPvs); } pvs = newPvs; } //检查容器是否持有用于处理单态模式Bean关闭时的后置处理器 boolean hasInstAwareBpps = this.hasInstantiationAwareBeanPostProcessors(); //Bean实例对象没有依赖，即没有继承基类 boolean needsDepCheck = mbd.getDependencyCheck() != 0; if(hasInstAwareBpps || needsDepCheck) { //从实例对象中提取属性描述符 PropertyDescriptor[] filteredPds = this.filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if(hasInstAwareBpps) { Iterator var9 = this.getBeanPostProcessors().iterator(); while(var9.hasNext()) { BeanPostProcessor bp = (BeanPostProcessor)var9.next(); if(bp instanceof InstantiationAwareBeanPostProcessor) { InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor)bp; //使用BeanPostProcessor处理器处理属性值 pvs = ibp.postProcessPropertyValues((PropertyValues)pvs, filteredPds, bw.getWrappedInstance(), beanName); if(pvs == null) { return; } } } } if(needsDepCheck) { //为要设置的属性进行依赖检查 this.checkDependencies(beanName, mbd, filteredPds, (PropertyValues)pvs); } } //对属性进行注入 ，解析并注入依赖属性的过程 就在这个方法里面 /* 属性转换也有两情况： 1.属性值类型不需要转换时，不需要解析属性值，直接准备进行依赖注入。 2.属性值需要进行类型转换时，如对其他对象的引用等，首先需要解析属性值，然后对解析后的属性值进行依赖注入。 */ this.applyPropertyValues(beanName, mbd, bw, (PropertyValues)pvs); } } } 然后进入applyPropertyValues //解析并注入依赖属性的过程 protected void applyPropertyValues(String beanName, BeanDefinition mbd, BeanWrapper bw, PropertyValues pvs) { if(pvs != null &amp;&amp; !pvs.isEmpty()) { //封装属性值 MutablePropertyValues mpvs = null; if(System.getSecurityManager() != null &amp;&amp; bw instanceof BeanWrapperImpl) { //设置安全上下文，JDK安全机制 ((BeanWrapperImpl)bw).setSecurityContext(this.getAccessControlContext()); } List original; if(pvs instanceof MutablePropertyValues) { mpvs = (MutablePropertyValues)pvs; //属性值已经转换 if(mpvs.isConverted()) { try { //为实例化对象设置属性值 ，依赖注入真真正正地实现在此！！！！！ bw.setPropertyValues(mpvs); return; } catch (BeansException var18) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Error setting property values&quot;, var18); } } //获取属性值对象的原始类型值 original = mpvs.getPropertyValueList(); } else { original = Arrays.asList(pvs.getPropertyValues()); } //获取用户自定义的类型转换 TypeConverter converter = this.getCustomTypeConverter(); if(converter == null) { converter = bw; } //创建一个Bean定义属性值解析器，将Bean定义中的属性值解析为Bean实例对象 //的实际值 BeanDefinitionValueResolver valueResolver = new BeanDefinitionValueResolver(this, beanName, mbd, (TypeConverter)converter); //为属性的解析值创建一个拷贝，将拷贝的数据注入到实例对象中 List&lt;PropertyValue&gt; deepCopy = new ArrayList(original.size()); boolean resolveNecessary = false; Iterator var11 = original.iterator();//用迭代器去遍历 while(true) { while(var11.hasNext()) { PropertyValue pv = (PropertyValue)var11.next(); //属性值不需要转换 if(pv.isConverted()) { deepCopy.add(pv); } else {//属性值需要转换 String propertyName = pv.getName(); //原始的属性值，即转换之前的属性值 Object originalValue = pv.getValue(); //转换属性值，例如将引用转换为IoC容器中实例化对象引用 ！！！！！ 对属性值的解析！！ Object resolvedValue = valueResolver.resolveValueIfNecessary(pv, originalValue); //转换之后的属性值 Object convertedValue = resolvedValue; //属性值是否可以转换 boolean convertible = bw.isWritableProperty(propertyName) &amp;&amp; !PropertyAccessorUtils.isNestedOrIndexedProperty(propertyName); if(convertible) { //使用用户自定义的类型转换器转换属性值 convertedValue = this.convertForProperty(resolvedValue, propertyName, bw, (TypeConverter)converter); } //存储转换后的属性值，避免每次属性注入时的转换工作 if(resolvedValue == originalValue) { if(convertible) { //设置属性转换之后的值 pv.setConvertedValue(convertedValue); } deepCopy.add(pv); } //属性是可转换的，且属性原始值是字符串类型，且属性的原始类型值不是 //动态生成的字符串，且属性的原始值不是集合或者数组类型 else if(convertible &amp;&amp; originalValue instanceof TypedStringValue &amp;&amp; !((TypedStringValue)originalValue).isDynamic() &amp;&amp; !(convertedValue instanceof Collection) &amp;&amp; !ObjectUtils.isArray(convertedValue)) { pv.setConvertedValue(convertedValue); deepCopy.add(pv); } else { resolveNecessary = true; //重新封装属性的值 deepCopy.add(new PropertyValue(pv, convertedValue)); } } } if(mpvs != null &amp;&amp; !resolveNecessary) { //标记属性值已经转换过 mpvs.setConverted(); } //进行属性依赖注入 ，依赖注入的真真正正实现依赖的注入方法在此！！！ try { bw.setPropertyValues(new MutablePropertyValues(deepCopy)); return; } catch (BeansException var19) { throw new BeanCreationException(mbd.getResourceDescription(), beanName, &quot;Error setting property values&quot;, var19); } } } } 总结applyPropertyValues方法（完成属性转换）：属性值类型不需要转换时，不需要解析属性值，直接准备进行依赖注入。属性值需要进行类型转换时，如对其他对象的引用等，首先需要解析属性值，然后对解析后的属性值进行依赖注入。当容器在对属性进行依赖注入时，如果发现属性值需要进行类型转换，如属性值是容器中另一个Bean实例对象的引用，则容器首先需要根据属性值解析出所引用的对象，然后才能将该引用对象注入到目标实例对象的属性上去，对属性进行解析的由resolveValueIfNecessary方法实现。可知：创建与注入是个递归的过程空间限制，都简写了进入BeanDefinitionValueResolver类的resolveValueIfNecessary方法。解析引用类型是BeanDefinitionValueResolver类的resolveReference方法刚刚的AbstractAutowireCapableBeanFactory类中applyPropertyValues方法分发了一个方法实现对属性值的依赖注入setPropertyValues。找到AbstractPropertyAccessor类中的抽象方法setPropertyValue 很复杂的一个解析方法：将属性的值注入到Bean实例对象中情况如下： 对于集合类型的属性，将其属性值解析为目标类型的集合后直接赋值给属性 对于非集合类型的属性，大量使用了JDK的反射和内省机制，通过属性的getter方法(reader method)获取指定属性注入以前的值，同时调用属性的setter方法(writer method)为属性设置注入后的值。 DI总结： DefaultListableBeanFactory父类AbstractBeanFactory根据Bean的状态定义（单例、存在、原型）进行构造方法分发。分发到AbstractAutowireCapableBeanFactory类的createBean方法 createBean方法负责Bean实例要求状态判断以及再度分发到doCreateBean实现创建实例（再次配置判断）。并在doCreateBean再度分发去createBeanInstance去Bean所包含的Java对象实例以及去populateBean 方法对Bean属性的依赖注入进行处理（以此为责任分发中心）。 在createBeanInstance方法中真正地根据之前的配置判断设置选择真正合适的构造器（自动装配、无参构造器）； 在populateBean 方法中真正地将Bean属性设置到生成的实例对象上 ，但在过程中注入依赖属性的是在applyPropertyValues方法（完成属性转换），调用BeanDefinitionValueResolver类调用resolveValueIfNecessary方法对属性值的解析，属性的真正注入实现在BeanWrapperImpl类。 这还是站在巨人的肩膀上写的，自己都跟不下去。]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty之ChannelPipeline]]></title>
    <url>%2F2017%2F11%2F01%2FNetty%E4%B9%8BChannelPipeline%2F</url>
    <content type="text"><![CDATA[Netty的ChannelPipeline和ChannelHandler机制类似于Servlet和Filter过滤器，这类拦截器实际上是职责链模式的一种变形。 ChannelPipeline的事件处理功能说明ChannelPipeline是ChannelHandler的容器，负责ChannelHandler的管理和事件拦截与调度。一个消息被ChannelPipeline的ChannelHandler拦截的处理流程如下： 1、底层的SocketChannel.read()方法读取ByteBuf，触发ChannelRead事件，由I/O线程NioEventLoop调用ChannelPipeline的fireChannelRead(Object msg),将消息（ByteBuf）传输到ChannelPipeline中。2、消息依次被HeadHandler，ChannelHandler1，ChannelHandler2。。。TailHandler拦截和处理，这个过程中，热河ChannelHandler都可以中断当前流程，结束消息传递。3、调用ChannelHandlerContext.write()发送消息，消息从TailHandler开始，然后进过ChannelHandlerN。。。ChannelHandler2，ChannelHandler1，HeadHandler最终被添加到消息发送缓冲区中等待刷新和发送，在此过程中也可以中断消息的传递，例如当编码失败时，就需要中断流程，构造异常的Future返回。 Netty中的事件分为inbound事件和outbound事件。inbound事件通常由I/O线程触发，例如TCP链路建立事件、链路关闭事件、读事件、异常通知事件等。 触发inbound事件的方法如下。 （1）ChannelHandlerContext.fireChannelRegistered()：Channel注册事件； （2）ChannelHandlerContext.fireChannelActive()：TCP链路建立成功，Channel激活事件； （3）ChannelHandlerContext.fireChannelRead(Object)：读事件； （4）ChannelHandlerContext.fireChannelReadComplete()：读操作完成通知事件； （5）ChannelHandlerContext.fireExceptionCaught(Throwable)：异常通知事件； （6）ChannelHandlerContext.fireUserEventTriggered(Object)：用户自定义事件； （7）ChannelHandlerContext.fireChannelWritabilityChanged()：Channel的可写状态变化通知事件； （8）ChannelHandlerContext.fireChannelInactive()：TCP连接关闭，链路不可用通知事件。 Outbound事件通常是由用户主动发起的网络I/O操作，例如用户发起的连接操作、绑定操作、消息发送等操作，它对应图17-1的右半部分。 触发outbound事件的方法如下： （1）ChannelHandlerContext.bind(SocketAddress, ChannelPromise)：绑定本地地址事件； （2）ChannelHandlerContext.connect(SocketAddress, SocketAddress, ChannelPromise)：连接服务端事件； （3）ChannelHandlerContext.write(Object, ChannelPromise)：发送事件； （4）ChannelHandlerContext.flush()：刷新事件； （5）ChannelHandlerContext.read()：读事件； （6）ChannelHandlerContext.disconnect(ChannelPromise)：断开连接事件； （7）ChannelHandlerContext.close(ChannelPromise)：关闭当前Channel事件。 自定义拦截器ChannelPipeline通过ChannelHandler接口来实现事件的拦截和处理，由于ChannelHandler中的事件种类繁多，不同的ChannelHandler可能只需要关心其中的某一个或者几个事件，所以，通常ChannelHandler只需要继承ChannelHandlerAdapter类覆盖自己关心的方法即可。 public class MyInboundHandler extends ChannelHandlerAdapter { @Override //拦截channelActive方法 public void channelActive(ChannelHandlerContext ctx) { System.out.println(&quot;TCP connected!&quot;); ctx.fireChannelActive(); } } 构建pipeline事实上，用户不需要自己创建pipeline，因为使用ServerBootstrap或者Bootstrap启动服务端或者客户端时，Netty会为每个Channel连接创建一个独立的pipeline。对于使用者而言，只需要将自定义的拦截器加入到pipeline中即可。 pipeline = ch.pipeline(); pipeline.addLast(&quot;decoder&quot;, new MyProtocolDecoder()); pipeline.addLast(&quot;encoder&quot;, new MyProtocolEncoder()); 对于类似编解码这样的ChannelHandler，它存在先后顺序，例如MessageToMessageEncoder，在它之前往往需要有ByteToMessageDecoder将ByteBuf解码为对象，然后对对象做二次解码得到最终的POJO对象。 ChannelPipeline的主要特性ChannelPipeline支持运行态动态的添加或者删除ChannelHandler，在某些场景下这个特性非常实用。例如当业务高峰期需要对系统做拥塞保护时，就可以根据当前的系统时间进行判断，如果处于业务高峰期，则动态地将系统拥塞保护ChannelHandler添加到当前的ChannelPipeline中，当高峰期过去之后，就可以动态删除拥塞保护ChannelHandler了。 ChannelPipeline是线程安全的，这意味着N个业务线程可以并发地操作ChannelPipeline而不存在多线程并发问题。但是，ChannelHandler却不是线程安全的，这意味着尽管ChannelPipeline是线程安全的，但是用户仍然需要自己保证ChannelHandler的线程安全。 ChannelPipeline源码分析ChannelPipeline的代码相对比较简单，它实际上是一个ChannelHandler的容器，内部维护了一个ChannelHandler的链表和迭代器，可以方便地实现ChannelHandler查找、添加、替换和删除。ChannelPipeline对ChannelHandler的管理 ChannelPipeline是ChannelHandler的管理容器，负责ChannelHandler的查询、添加、替换和删除，它与Map等容器的实现非常类似。 由于ChannelPipeline支持运行期动态修改，在调用类似addBefore（ChannelHandlerInvoker invoker, String baseName, final String name, ChannelHandler handler）方法时，存在两种潜在的多线程并发访问场景。 I/O线程和用户业务线程的并发访问； 用户多个线程之间的并发访问。 为了保证ChannelPipeline的线程安全性，需要通过线程安全容器或者锁来保证并发访问的安全，此处Netty直接使用了synchronized关键字，保证同步块内的所有操作的原子性。 public ChannelPipeline addLast(ChannelHandlerInvoker invoker, String name, ChannelHandler handler) { synchronized(this) { name = this.filterName(name, handler); this.addLast0(name, new DefaultChannelHandlerContext(this, invoker, name, handler)); return this; } } 首先根据baseName获取它对应的DefaultChannelHandlerContext，ChannelPipeline维护了ChannelHandler名和ChannelHandlerContext实例的映射关系。 新增的ChannelHandler名进行重复性校验，如果已经有同名的ChanneHandler存在，则不允许覆盖，抛出IllegalArgumentException(“Duplicate handler name: “ + name)异常。校验通过之后，使用新增的ChannelHandler等参数构造一个新的DefaultChannelHandlerContext实例。将新创建的DefaultChannelHandlerContext添加到当前的pipeline中(首先需要对添加的ChannelHandlerContext做重复性校验,如果ChannelHandler不是可以在多个ChannelPipeline中共享的，且已经被添加到ChannelPipeline中，则抛出ChannelPipelineException异常。)。加入成功之后，缓存ChannelHandlerContext，发送新增ChannelHandlerContext通知消息。 ChannelPipeline的inbound事件当发生某个I/O事件的时候，例如链路建立、链路关闭、读取操作完成等，都会产生一个事件，事件在pipeline中得到传播和处理，它是事件处理的总入口。由于网络I/O相关的事件有限，因此Netty对这些事件进行了统一抽象，Netty自身和用户的ChannelHandler会对感兴趣的事件进行拦截和处理。 pipeline中以fireXXX命名的方法都是从IO线程流向用户业务Handler的inbound事件，它们的实现因功能而异，但是处理步骤类似，总结如下。 （1）调用HeadHandler对应的fireXXX方法；（2）执行事件相关的逻辑操作。 以fireChannelActive方法为例，调用head.fireChannelActive()之后，判断当前的Channel配置是否自动读取，如果为真则调用Channel的read方法 DefaultChannelPipeline @Override public ChannelPipeline fireChannelActive() { head.fireChannelActive(); if (channel.config().isAutoRead()) { channel.read(); } return this; } ChannelPipeline的outbound事件 由用户线程或者代码发起的I/O操作被称为outbound事件，事实上inbound和outbound是Netty自身根据事件在pipeline中的流向抽象出来的术语，在其他NIO框架中并没有这个概念。 Pipeline本身并不直接进行I/O操作，最终都是由Unsafe和Channel来实现真正的I/O操作的。Pipeline负责将I/O事件通过HeadHandler进行调度和传播，最终调用Unsafe的I/O方法进行I/O操作。最终由TailHandler调用Unsafe的connect方法发起真正的连接，pipeline仅仅负责事件的调度。 总结ChannelPipeline是ChannelHandler的容器，负责ChannelHandler的管理和事件拦截与调度。并且支持运行态动态的添加或者删除ChannelHandler。]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty之Channel源码]]></title>
    <url>%2F2017%2F10%2F31%2FNetty%E4%B9%8BChannel%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[和ByteBuf一样，先了解NIO的Channel。http://www.jianshu.com/p/d8c779cdda41 Netty的Channel的API读写相关的API列表。 （1）Channel read()：从当前的Channel中读取数据到第一个inbound缓冲区中，如果数据被成功读取，触发ChannelHandler.channelRead(ChannelHandlerContext, Object)事件，读取操作API调用完成之后，紧接着会触发ChannelHandler.channelReadComplete (Channel HandlerContext)事件，这样业务的ChannelHandler可以决定是否需要继续读取数据。如果已经有读操作请求被挂起，则后续的读操作会被忽略。 （2）ChannelFuture write(Object msg)：请求将当前的msg通过ChannelPipeline写入到目标Channel中。注意，write操作只是将消息存入到消息发送环形数组中，并没有真正被发送，只有调用flush操作才会被写入到Channel中，发送给对方。 （3）ChannelFuture write(Object msg, ChannelPromise promise)：功能与write(Object msg)相同，但是携带了ChannelPromise参数负责设置写入操作的结果。 （4）ChannelFuture writeAndFlush(Object msg, ChannelPromise promise)：与方法（3）功能类似，不同之处在于它会将消息写入到Channel中发送，等价于单独调用write和flush操作的组合。 （5）ChannelFuture writeAndFlush(Object msg)：功能等同于方法（4），但是没有携带writeAndFlush(Object msg)参数。 （6）Channel flush()：将之前写入到发送环形数组中的消息全部写入到目标Chanel中，发送给通信对方。 （7）ChannelFuture close(ChannelPromise promise)：主动关闭当前连接，通过ChannelPromise设置操作结果并进行结果通知，无论操作是否成功，都可以通过ChannelPromise获取操作结果。该操作会级联触发ChannelPipeline中所有ChannelHandler的ChannelHandler.close(ChannelHandlerContext, ChannelPromise)事件。 （8）ChannelFuture disconnect(ChannelPromise promise)：请求断开与远程通信对端的连接并使用ChannelPromise来获取操作结果的通知消息。该方法会级联触发ChannelHandler.disconnect(ChannelHandlerContext, ChannelPromise)事件。 （9）ChannelFuture connect(SocketAddress remoteAddress)：客户端使用指定的服务端地址remoteAddress发起连接请求，如果连接因为应答超时而失败，ChannelFuture中的操作结果就是ConnectTimeoutException异常，如果连接被拒绝，操作结果为ConnectException。该方法会级联触发ChannelHandler.connect(ChannelHandlerContext, SocketAddress, SocketAddress, ChannelPromise)事件。 （10）ChannelFuture connect(SocketAddress remoteAddress, SocketAddress localAddress)：与方法9）功能类似，唯一不同的就是先绑定指定的本地地址localAddress，然后再连接服务端。 （11）ChannelFuture connect(SocketAddress remoteAddress, ChannelPromise promise)：与方法9）功能类似，唯一不同的是携带了ChannelPromise参数用于写入操作结果。 （12）connect(SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise)：与方法（11）功能类似，唯一不同的就是绑定了本地地址。 （13）ChannelFuture bind(SocketAddress localAddress)：绑定指定的本地Socket地址localAddress，该方法会级联触发ChannelHandler.bind(ChannelHandlerContext, SocketAddress, ChannelPromise)事件。 （14）ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise)：与方法13）功能类似，多携带了了一个ChannelPromise用于写入操作结果。 （15）ChannelConfig config()：获取当前Channel的配置信息，例如CONNECT_ TIMEOUT_MILLIS。 （16）boolean isOpen()：判断当前Channel是否已经打开。 （17）boolean isRegistered()：判断当前Channel是否已经注册到EventLoop上。 （18）boolean isActive()：判断当前Channel是否已经处于激活状态。 （19）ChannelMetadata metadata()：获取当前Channel的元数据描述信息，包括TCP参数配置等。 （20）SocketAddress localAddress()：获取当前Channel的本地绑定地址。 （21）SocketAddress remoteAddress()：获取当前Channel通信的远程Socket地址。 AbstractChannel我们通过Channel的实现类AbstractChannel来看Channel的方法。 protected AbstractChannel(Channel parent) { this.parent = parent; this.id = DefaultChannelId.newInstance(); this.unsafe = this.newUnsafe(); this.pipeline = new DefaultChannelPipeline(this); } protected AbstractChannel(Channel parent, ChannelId id) { this.parent = parent; this.id = id; this.unsafe = this.newUnsafe(); this.pipeline = new DefaultChannelPipeline(this); } newUnsafe()和newChannelPipeline()可由子类覆盖实现。在Netty的实现中每一个Channel都有一个对应的Unsafe内部类：AbstractChannel–AbstractUnsafe，AbstractNioChannel–AbstractNioUnsafe等等，newUnsafe()方法正好用来生成这样的对应关系。ChannelPipeline的功能：作为用户处理器Handler的容器为用户提供自定义处理I/O事件的能力即为用户提供业务逻辑处理。AbstractChannel中对I/O事件的处理，都委托给ChannelPipeline处理。Netty是基于事件驱动，我们也可以理解为当Channel进行I/O操作时会产生对应的I/O事件，然后驱动事件在ChannelPipeline中传播，由对应的ChannelHandler对事件定义来划分事件拦截切面，方面业务的定制和功能扩展。类似于AOP，但是性能更高。网络I/O操作直接调用DefaultChannelPipeline的相关方法，由DefaultChannelPipeline中对应的ChannelHandler进行具体的逻辑处理。 public ChannelFuture bind(SocketAddress localAddress) { return pipeline.bind(localAddress); } public ChannelFuture connect(SocketAddress remoteAddress, ChannelPromise promise) { return this.pipeline.connect(remoteAddress, promise); } AbstractUnsafe实际网络I/O的操作基本都是由Unsafe功能类负责实现的，看看里面重要的API register方法register方法主要用于将当前Unsafe对应的Channel注册到EventLoop的多路复用器上，然后调用DefaultChannelPipeline的fireChannelRegistered方法。如果Channel被激活，调用DefaultChannelPipeline的fireChannelActive方法。 public final void register(EventLoop eventLoop, final ChannelPromise promise) { if (eventLoop == null) { throw new NullPointerException(&quot;eventLoop&quot;); } else if (promise == null) { throw new NullPointerException(&quot;promise&quot;); } else if (AbstractChannel.this.isRegistered()) {//已经被注册 promise.setFailure(new IllegalStateException(&quot;registered to an event loop already&quot;)); } else if (!AbstractChannel.this.isCompatible(eventLoop)) {//类型不兼容 promise.setFailure(new IllegalStateException(&quot;incompatible event loop type: &quot; + eventLoop.getClass().getName())); } else { if (AbstractChannel.this.eventLoop == null) { AbstractChannel.this.eventLoop = AbstractChannel.this.new PausableChannelEventLoop(eventLoop); } else { AbstractChannel.this.eventLoop.unwrapped = eventLoop; } if (eventLoop.inEventLoop()) {//当前线程为EventLoop线程直接执行；否则提交任务给EventLoop线程 this.register0(promise); } else { try { eventLoop.execute(new OneTimeTask() { public void run() { AbstractUnsafe.this.register0(promise); } }); } catch (Throwable var4) { AbstractChannel.logger.warn(&quot;Force-closing a channel whose registration task was not accepted by an event loop: {}&quot;, AbstractChannel.this, var4); this.closeForcibly(); AbstractChannel.this.closeFuture.setClosed(); this.safeSetFailure(promise, var4); } } } } private void register0(ChannelPromise promise) { try { // 确保Channel没有关闭 if (!promise.setUncancellable() || !this.ensureOpen(promise)) { return; } boolean firstRegistration = this.neverRegistered; // 模板方法，细节由子类完成 AbstractChannel.this.doRegister(); this.neverRegistered = false; AbstractChannel.this.registered = true; AbstractChannel.this.eventLoop.acceptNewTasks(); this.safeSetSuccess(promise); AbstractChannel.this.pipeline.fireChannelRegistered(); if (firstRegistration &amp;&amp; AbstractChannel.this.isActive()) { AbstractChannel.this.pipeline.fireChannelActive(); } } catch (Throwable var3) { this.closeForcibly(); AbstractChannel.this.closeFuture.setClosed(); this.safeSetFailure(promise, var3); } } 如果没有抛出异常，则注册成功。 bind()bind()主要用于绑定指定的端口，对于服务器，用于绑定监听端口，可以设置backlog参数，对于客户端，主要用于指定客户端Channel的本地绑定Socket地址。 public final void bind(SocketAddress localAddress, ChannelPromise promise) { if (promise.setUncancellable() &amp;&amp; this.ensureOpen(promise)) { if (Boolean.TRUE.equals(AbstractChannel.this.config().getOption(ChannelOption.SO_BROADCAST)) &amp;&amp; localAddress instanceof InetSocketAddress &amp;&amp; !((InetSocketAddress)localAddress).getAddress().isAnyLocalAddress() &amp;&amp; !PlatformDependent.isWindows() &amp;&amp; !PlatformDependent.isRoot()) { AbstractChannel.logger.warn(&quot;A non-root user can&apos;t receive a broadcast packet if the socket is not bound to a wildcard address; binding to a non-wildcard address (&quot; + localAddress + &quot;) anyway as requested.&quot;); } boolean wasActive = AbstractChannel.this.isActive(); try { AbstractChannel.this.doBind(localAddress); } catch (Throwable var5) { this.safeSetFailure(promise, var5); this.closeIfClosed(); return; } if (!wasActive &amp;&amp; AbstractChannel.this.isActive()) { //invokeLater()方法向Channel注册到的EventLoop提交一个任务 this.invokeLater(new OneTimeTask() { public void run() { AbstractChannel.this.pipeline.fireChannelActive(); } }); } this.safeSetSuccess(promise); } } 调用doBind()，对于NioSocketChannel和NioServerSocketChannel有不同的实现。对于NioServerSocketChannel，用于绑定监听端口，可以设置backlog参数；对于NioSocketChannel，主要用于指定客户端Channel的本地绑定Socket地址。如果绑定本地端口发生异常，则将异常设置到ChannelPromise中用于通知ChannelFuture，随后调用closeIfClosed方法来关闭Channel。 disconnect()disconnect用于客户端或者服务端主动关闭连接， public final void disconnect(ChannelPromise promise) { boolean wasActive = AbstractChannel.this.isActive(); try { AbstractChannel.this.doDisconnect(); } catch (Throwable var4) { promise.setFailure(var4); this.closeIfClosed(); return; } if(wasActive &amp;&amp; !AbstractChannel.this.isActive()) { this.invokeLater(new Runnable() { public void run() { AbstractChannel.this.pipeline.fireChannelInactive(); } }); } promise.setSuccess(); this.closeIfClosed(); } close()在链路关闭之前需要首先判断是否处于刷新状态，如果处于刷新状态说明还有消息尚未发送出去，需要等到所有消息发送完成再关闭链路，因此，将关闭操作封装成Runnable稍后再执行。如果链路没有处于刷新状态，需要从closeFuture中判断关闭操作是否完成，如果已经完成，不需要重复关闭链路，设置ChannelPromise的操作结果为成功并返回。执行关闭操作，将消息发送缓冲数组设置为空，通知JVM进行内存回收。调用抽象方法doClose关闭链路。如果关闭操作成功，设置ChannelPromise结果为成功。如果操作失败，则设置异常对象到ChannelPromise中。调用ChannelOutboundBuffer的close方法释放缓冲区的消息，随后构造链路关闭通知Runnable放到NioEventLoop中执行。最后，调用deregister方法，将Channel从多路复用器上取消注册。NioEventLoop的cancel方法实际将selectionKey对应的Channel从多路复用器上去注册。 public final void close(final ChannelPromise promise) { if(this.inFlush0) { this.invokeLater(new Runnable() { public void run() { AbstractUnsafe.this.close(promise); } }); } else if(AbstractChannel.this.closeFuture.isDone()) { promise.setSuccess(); } else { boolean wasActive = AbstractChannel.this.isActive(); ChannelOutboundBuffer outboundBuffer = this.outboundBuffer; this.outboundBuffer = null; try { AbstractChannel.this.doClose(); AbstractChannel.this.closeFuture.setClosed(); promise.setSuccess(); } catch (Throwable var8) { AbstractChannel.this.closeFuture.setClosed(); promise.setFailure(var8); } try { outboundBuffer.failFlushed(AbstractChannel.CLOSED_CHANNEL_EXCEPTION); outboundBuffer.close(AbstractChannel.CLOSED_CHANNEL_EXCEPTION); } finally { if(wasActive &amp;&amp; !AbstractChannel.this.isActive()) { this.invokeLater(new Runnable() { public void run() { AbstractChannel.this.pipeline.fireChannelInactive(); } }); } this.deregister(); } } } write方法write方法实际上将消息添加到环形发送数组中，并不是真正的写Channel，如果Channel没有处于激活状态，说明TCP链路还没有真正建立成功，当前Channel存在以下两种状态。（1）Channel打开，但是TCP链路尚未建立成功：NOT_YET_CONNECTED_EXCEPTION；（2）Channel已经关闭：CLOSED_CHANNEL_EXCEPTION。对链路状态进行判断，给ChannelPromise设置对应的异常，然后调用ReferenceCountUtil的release方法释放发送的msg对象。如果链路状态正常，则将需要发送的msg和promise放入发送缓冲区中（环形数组）。 public void write(Object msg, ChannelPromise promise) { if(!AbstractChannel.this.isActive()) { if(AbstractChannel.this.isOpen()) { promise.tryFailure(AbstractChannel.NOT_YET_CONNECTED_EXCEPTION); } else { promise.tryFailure(AbstractChannel.CLOSED_CHANNEL_EXCEPTION); } ReferenceCountUtil.release(msg); } else { this.outboundBuffer.addMessage(msg, promise); } } flush方法flush方法负责将发送缓冲区中待发送的消息全部写入到Channel中，并发送给通信对方。 重点分析 doWrite方法，首先计算需要发送的消息个数（unflushed - flush），如果只有 一个消息需要发送，则调用父类的写操作，我们分析AbstractNioByteChannel的doWrite()方法，因为只有一条消息需要发送，所以直接从ChannelOutboundBuffer中获取当前需要发送的消息，首先，获取需要发送的消息，如果消息为ByteBuf且它分配的是JDK的非堆内存，则直接返回。对返回的消息进行判断，如果为空，说明该消息已经发送完成并被回收，然后执行清空OP_WRITE操作位的clearOpWrite方法，如果需要发送的ByteBuf已经没有可写的字节了，则说明已经发送完成，将该消息从环形队列中删除，然后继续循环，分析下ChannelOutboundBuffer的remove方法，首先判断环形队列中是否还有需要发送的消息，如果没有，则直接返回。如果非空，则首先获取Entry，然后对其进行资源释放，同时对需要发送的索引flushed进行更新。所有操作执行完之后，调用decrementPendingOutboundBytes减去已经发送的字节数，该方法跟incrementPendingOutboundBytes类似，会进行发送低水位的判断和事件通知。继续对消息的发送进行分析，首先将半包标识设置为false，从DefaultSocketChannelConfig中获取循环发送的次数，进行循环发送，对发送方法doWriteBytes展开分析，ByteBuf的readBytes()方法的功能是将当前ByteBuf中的可写字节数组写入到指定的Channel中。方法的第一个参数是Channel，此处就是SocketChannel，第二个参数是写入的字节数组长度，它等于ByteBuf的可读字节数，返回值是写入的字节个数。由于我们将SocketChannel设置为异步非阻塞模式，所以写操作不会阻塞。从写操作中返回，需要对写入的字节数进行判断，如果为0，说明TCP发送缓冲区已满，不能继续再向里面写入消息，因此，将写半包标识设置为true，然后退出循环，执行后续排队的其他任务或者读操作，等待下一次selector的轮询继续触发写操作。对写入的字节数进行累加，判断当前的ByteBuf中是否还有没有发送的字节，如果没有可发送的字节，则将done设置为true，退出循环。从循环发送状态退出后，首先根据实际发送的字节数更新发送进度，实际就是发送的字节数和需要发送的字节数的一个比值。执行完进度更新后，判断本轮循环是否将需要发送的消息全部发送完成，如果发送完成则将该消息从循环队列中删除；否则，设置多路复用器的OP_WRITE操作位，用于通知Reactor线程还有半包消息需要继续发送。 public void flush() { ChannelOutboundBuffer outboundBuffer = this.outboundBuffer; if(outboundBuffer != null) { //首先将发送环形数组的unflushed指针修改为tail，标识本次要发送消息的缓冲区范围。然后调用flush0进行发送。 outboundBuffer.addFlush(); this.flush0(); } } protected void flush0() { if(!this.inFlush0) { ChannelOutboundBuffer outboundBuffer = this.outboundBuffer; if(outboundBuffer != null &amp;&amp; !outboundBuffer.isEmpty()) { this.inFlush0 = true; if(!AbstractChannel.this.isActive()) { try { if(AbstractChannel.this.isOpen()) { outboundBuffer.failFlushed(AbstractChannel.NOT_YET_CONNECTED_EXCEPTION); } else { outboundBuffer.failFlushed(AbstractChannel.CLOSED_CHANNEL_EXCEPTION); } } finally { this.inFlush0 = false; } } else { try { AbstractChannel.this.doWrite(outboundBuffer); } catch (Throwable var11) { outboundBuffer.failFlushed(var11); } finally { this.inFlush0 = false; } } } } } AbstractNioUnsafeAbstractNioUnsafe是AbstractUnsafe类的NIO实现，它主要实现了connect、finishConnect等方法。 connect()首先获取当前的连接状态进行缓存，然后发起连接操作，需要指出的是，SocketChannel执行connect()操作有三种可能的结果。 （1）连接成功，返回true；（2）暂时没有连接上，服务端没有返回ACK应答，连接结果不确定，返回false；（3）连接失败，直接抛出I/O异常。 如果是第（2）种结果，需要将NioSocketChannel中的selectionKey设置为OP_ CONNECT，监听连接应答消息。 异步连接返回之后，需要判断连接结果，如果连接成功，则触发ChannelActive事件，它最终会将NioSocketChannel中的 selectionKey设置为SelectionKey.OP_READ，用于监听网络读操作位。如果没有立即连接上服务端，则执行其他分支的操作，有两个目的。 （1）根据连接超时时间设置定时任务，超时时间到之后触发校验，如果发现连接并没有完成，则关闭连接句柄，释放资源，设置异常堆栈并发起去注册。 （2）设置连接结果监听器，如果接收到连接完成通知则判断连接是否被取消，如果被取消则关闭连接句柄，释放资源，发起取消注册操作。 public void connect(final SocketAddress remoteAddress, SocketAddress localAddress, ChannelPromise promise) { if(this.ensureOpen(promise)) { try { if(AbstractNioChannel.this.connectPromise != null) { throw new IllegalStateException(&quot;connection attempt already made&quot;); } boolean t1 = AbstractNioChannel.this.isActive(); if(AbstractNioChannel.this.doConnect(remoteAddress, localAddress)) { this.fulfillConnectPromise(promise, t1); } else { AbstractNioChannel.this.connectPromise = promise; AbstractNioChannel.this.requestedRemoteAddress = remoteAddress; int newT1 = AbstractNioChannel.this.config().getConnectTimeoutMillis(); if(newT1 &gt; 0) { AbstractNioChannel.this.connectTimeoutFuture = AbstractNioChannel.this.eventLoop().schedule(new Runnable() { public void run() { ChannelPromise connectPromise = AbstractNioChannel.this.connectPromise; ConnectTimeoutException cause = new ConnectTimeoutException(&quot;connection timed out: &quot; + remoteAddress); if(connectPromise != null &amp;&amp; connectPromise.tryFailure(cause)) { AbstractNioUnsafe.this.close(AbstractNioUnsafe.this.voidPromise()); } } }, (long)newT1, TimeUnit.MILLISECONDS); } promise.addListener(new ChannelFutureListener() { public void operationComplete(ChannelFuture future) throws Exception { if(future.isCancelled()) { if(AbstractNioChannel.this.connectTimeoutFuture != null) { AbstractNioChannel.this.connectTimeoutFuture.cancel(false); } AbstractNioChannel.this.connectPromise = null; AbstractNioUnsafe.this.close(AbstractNioUnsafe.this.voidPromise()); } } }); } } catch (Throwable var6) { Object t = var6; if(var6 instanceof ConnectException) { ConnectException newT = new ConnectException(var6.getMessage() + &quot;: &quot; + remoteAddress); newT.setStackTrace(var6.getStackTrace()); t = newT; } promise.tryFailure((Throwable)t); this.closeIfClosed(); } } } finishConnect()客户端接收到服务端的TCP握手应答消息，通过SocketChannel的finishConnect方法对连接结果进行判断，首先缓存连接状态，当前返回false，然后执行doFinishConnect方法判断连接结果，通过 SocketChannel的finishConnect 方法判断连接结果，执行该方法返回三种可能结果。 （1）连接成功返回true； （2）连接失败返回 false； （3）发生链路被关闭、链路中断等异常，连接失败。 只要连接失败，就抛出 Error()，由调用方执行句柄关闭等资源释放操作，如果返回成功，则执行fulfillConnectPromise 方法，它负责将SocketChannel修改为监听读操作位，用来监听网络的读事件，最后对连接超时进行判断：如果连接超时时仍然没有接收到服务端的 ACK 应答消息，则由定时任务关闭客户端连接，将SocketChannel从Reactor线程的多路复用器上摘除，释放资源。 public void finishConnect() { assert AbstractNioChannel.this.eventLoop().inEventLoop(); assert AbstractNioChannel.this.connectPromise != null; try { boolean t1 = AbstractNioChannel.this.isActive(); AbstractNioChannel.this.doFinishConnect(); this.fulfillConnectPromise(AbstractNioChannel.this.connectPromise, t1); } catch (Throwable var6) { Object t = var6; if(var6 instanceof ConnectException) { ConnectException newT = new ConnectException(var6.getMessage() + &quot;: &quot; + AbstractNioChannel.this.requestedRemoteAddress); newT.setStackTrace(var6.getStackTrace()); t = newT; } AbstractNioChannel.this.connectPromise.tryFailure((Throwable)t); this.closeIfClosed(); } finally { if(AbstractNioChannel.this.connectTimeoutFuture != null) { AbstractNioChannel.this.connectTimeoutFuture.cancel(false); } AbstractNioChannel.this.connectPromise = null; } }]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty之ByteBuf源码(二)]]></title>
    <url>%2F2017%2F10%2F30%2FNetty%E4%B9%8BByteBuf%E6%BA%90%E7%A0%81-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[UnpooledHeapByteBufUnpooledHeapByteBuf是一个非线程池实现的在堆内存进行内存分配的字节缓冲区，在每次IO操作的都会去创建一个UnpooledHeapByteBuf对象，如果频繁地对内存进行分配或者释放会对性能造成影响。 成员变量 ByteBufAllocator 用于内存分配 array 字节数组作为缓冲区，用于存储字节数据 ByteBuffer 用来实现Netty ByteBuf 到Nio ByteBuffer的变换动态扩展缓冲区调用capacity方法动态扩展缓冲区，首先要对扩展容量进行校验，如果新容量的大小小于0或者大于最大可扩展容量maxCapacity的话，抛出IllegalArgumentException异常。通过校验之后，如果新扩展容量比原来大的话，则创建一个新的容量为新扩展容量的字节数组缓冲区，然后调用System.arraycopy进行内存复制，将旧的数据复制到新数组中去，然后用setArray进行数组替换。动态扩展之后需要原来的视图tmpNioBuffer设置为控。如果新的容量小于当前缓冲区容量的话，不需要进行动态扩展，但是需要截取部分数据作为子缓冲区。 首先对当前的readerIndex是否小于newCapacity，如果小于的话继续对writerIndex跟newCapacity进行比较，如果writerIndex大于newCapacity的话，就将writerIndex设置为newCapacity，更新完索引之后就通过System.arrayCopy内存复制将当前可读的数据复制到新的缓冲区字节数组中。 如果newCapacity小于readerIndex的话，说明没有新的可读数据要复制到新的字节数组缓冲区中，只需要把writerIndex跟readerIndex都更新为newCapacity既可，最后调用setArray更换字节数组。 public ByteBuf capacity(int newCapacity) { ensureAccessible(); if (newCapacity &lt; 0 || newCapacity &gt; maxCapacity()) { throw new IllegalArgumentException(&quot;newCapacity: &quot; + newCapacity); } int oldCapacity = array.length; if (newCapacity &gt; oldCapacity) { byte[] newArray = new byte[newCapacity]; System.arraycopy(array, 0, newArray, 0, array.length); setArray(newArray); } else if (newCapacity &lt; oldCapacity) { byte[] newArray = new byte[newCapacity]; int readerIndex = readerIndex(); if (readerIndex &lt; newCapacity) { int writerIndex = writerIndex(); if (writerIndex &gt; newCapacity) { writerIndex(writerIndex = newCapacity); } System.arraycopy(array, readerIndex, newArray, readerIndex, writerIndex - readerIndex); } else { setIndex(newCapacity, newCapacity); } setArray(newArray); } return this; } setBytes字节数组复制，首先对数据进行合法性检验，如果srcIndex或者index的值小于0，就会抛出IllegalArgumentException，如果index+length的值大于capacity的值或者srcIndex+length的值大于src.length的话，就会抛出IndexOutOfBoundsException异常。通过校验之后，就调用System.arraycopy进行字节数组复制。 public ByteBuf setBytes(int index, byte[] src, int srcIndex, int length) { checkSrcIndex(index, length, srcIndex, src.length); System.arraycopy(src, srcIndex, array, index, length); return this; } protected final void checkSrcIndex(int index, int length, int srcIndex, int srcCapacity) { checkIndex(index, length); if (srcIndex &lt; 0 || srcIndex &gt; srcCapacity - length) { throw new IndexOutOfBoundsException(String.format( &quot;srcIndex: %d, length: %d (expected: range(0, %d))&quot;, srcIndex, length, srcCapacity)); } } Netty ByteBuf与Nio ByteBuffer转换要将Netty的ByteBuf转化为Nio ByteBuffer，在ByteBuffer中有wrap静态方法，只需要传入对应的字节数组即可创建转化为ByteBuffer，在nioBuffer方法还调用了slice方法，它可以创建一个从原ByteBuffer的position开始缓冲区，与原缓冲区共享同一段数据元素。nioBuffer方法不会重用缓冲区，只能保证writerIndex跟readerIndex的独立性。 public ByteBuffer nioBuffer(int index, int length) { ensureAccessible(); return ByteBuffer.wrap(array, index, length).slice(); } PooledByteBuf在Netty4之后加入内存池管理，通过内存池管理比之前ByteBuf的创建性能得到了极大提高。 PoolChunk Page 可以用来分配的最小内存块单位 Chunk page的集合 PoolChunk主要负责内存块的分配及释放，chunk中的page会构建成一颗二叉树，默认情况下page的大小是8K,chunk的大小是2^11 page，即16M，构成了11层的二叉树，最下面一层的叶子节点有8192个，与page的数目一样，每一次内存的分配必须保证连续性，方便内存操作。每个节点会记录自己在Memory Area的偏移地址，当一个节点表示的内存区域被分配之后，那么该节点会被标志为已分配，该节点的所有子节点的内存请求都会忽略。每次内存分配的都是8k(2^n)大小的内存块，当需要分配大小为chunkSize/(2^k)的内存端时，为了找到可用的内存段，会从第K层左边开始寻找可用节点。 PoolArena在内存分配中，为了能够集中管理内存的分配及释放，同时提供分配和释放内存的性能，一般都是会先预先分配一大块连续的内存，不需要重复频繁地进行内存操作，那一大块连续的内存就叫做memory Arena，而PoolArena是Netty的内存池实现类。在Netty中，PoolArena是由多个Chunk组成的，而每个Chunk则由多个Page组成。PoolArena是由Chunk和Page共同组织和管理的。 PoolSubpage当对于小于一个Page的内存分配的时候，每个Page会被划分为大小相等的内存块，它的大小是根据第一次申请内存分配的内存块大小来决定的。一个Page只能分配与第一次内存内存的内存块的大小相等的内存块，如果想要想要申请大小不想等的内存块，只能在新的Page上申请内存分配了。Page中的存储区域的使用情况是通过一个long数组bitmap来维护的,每一位表示一个区域的占用情况。 PooledDirectByteBuf创建字节缓冲区由于内存池实现，每次创建字节缓冲区的时候，不是直接new，而是从内存池中去获取，然后设置引用计数器跟读写Index，跟缓冲区最大容量返回。 static PooledHeapByteBuf newInstance(int maxCapacity) { PooledHeapByteBuf buf = RECYCLER.get(); buf.reuse(maxCapacity); return buf; } final void reuse(int maxCapacity) { maxCapacity(maxCapacity); setRefCnt(1); setIndex0(0, 0); discardMarks(); } 复制字节缓冲区实例copy方法可以复制一个字节缓冲区实例，与原缓冲区独立。首先要对index和length进行合法性判断，然后调用PooledByteBufAllocator的directBuffer方法分配一个新的缓冲区。newDirectBuffer方法是一个抽象方法，对于不同的子类有不同的实现。如果是unpooled的话，会直接创建一个新的缓冲区，如果是pooled的话，它会从内存池中获取一个可用的缓冲区。 public ByteBuf copy(int index, int length) { checkIndex(index, length); ByteBuf copy = alloc().directBuffer(length, maxCapacity()); copy.writeBytes(this, index, length); return copy; } public ByteBuf directBuffer(int initialCapacity, int maxCapacity) { if (initialCapacity == 0 &amp;&amp; maxCapacity == 0) { return emptyBuf; } validate(initialCapacity, maxCapacity); return newDirectBuffer(initialCapacity, maxCapacity); } // PooledByteBufAllocator protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) { PoolThreadCache cache = threadCache.get(); PoolArena&lt;ByteBuffer&gt; directArena = cache.directArena; ByteBuf buf; if (directArena != null) { buf = directArena.allocate(cache, initialCapacity, maxCapacity); } else { if (PlatformDependent.hasUnsafe()) { buf = new UnpooledUnsafeDirectByteBuf(this, initialCapacity, maxCapacity); } else { buf = new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity); } } return toLeakAwareBuffer(buf); } //UnpooledByteBufAllocator protected ByteBuf newDirectBuffer(int initialCapacity, int maxCapacity) { ByteBuf buf; if (PlatformDependent.hasUnsafe()) { buf = new UnpooledUnsafeDirectByteBuf(this, initialCapacity, maxCapacity); } else { buf = new UnpooledDirectByteBuf(this, initialCapacity, maxCapacity); } return toLeakAwareBuffer(buf); } ByteBuf辅助类ByteBufHolderByteBufHolder是ByteBuf的一个容器，它可以更方便地访问ByteBuf中的数据，在使用不同的协议进行数据传输的时候，不同的协议消息体包含的数据格式和字段不一样，所以抽象一个ByteBufHolder对ByteBuf进行包装，不同的子类有不同的实现，使用者可以根据自己的需要进行实现。Netty提供了一个默认实现DefaultByteBufHolder。 ByteBufAllocatorByteBufAllocator是字节缓冲区分配器，根据Netty字节缓冲区的实现不同，分为两种不同的分配器PooledByteBufAllocator和UnpooledByteBufAllocator。他们提供了不同ByteBuf的分配方法。 CompositeByteBufCompositeByteBuf是一个虚拟的Buffer，它可以将多个ByteBuf组装为一个ByteBuf视图。 ByteBufUtilByteBufUtil是ByteBuf的工具类，它提供了一系列的静态方法来操作ByteBuf。]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty之ByteBuf源码(一)]]></title>
    <url>%2F2017%2F10%2F27%2FNetty%E4%B9%8BByteBuf%E6%BA%90%E7%A0%81-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[了解ByteBuf之前应先了解Java NIO的Buffer。而且主要使用的是Buffer的实现类ByteBuffer。这里主要以ByteBuffer。 NIO的ByteBuffer参考 http://www.jianshu.com/p/d67129097a88里面的四个属性 容量（Capacity）：缓冲区能够容纳的数据元素的最大数量。这一容量在缓冲区创建时被设定，并且永远不能被改变。 上界（Limit）：缓冲区的第一个不能被读或写的元素。或者说，缓冲区中现存元素的计数。 位置（Position）：下一个要被读或写的元素的索引。位置会自动由相应的 get( )和 put( )函数更新。 标记（Mark）：一个备忘位置。调用 mark( )来设定 mark = postion。调用 reset( )设定 position = mark。标记在设定前是未定义的( undefined) 。由于NIO复杂性，Buffer的实现类ByteBuffer也有其局限性，（1）、ByteBuffer长度固定，一旦分配完成，它的容量不能动态扩展和收缩，当需要编码的POJO对象大于ByteBuffer的容量时，会报索引越界异常。（2）、ByteBuffer只有一个标识位置的指针position，读写的时候需要手工调用flip()和rewind()，使用者必须小心谨慎的处理这些API，否则会导致程序处理失败。（3）、ByteBuffer的API功能有限，一个高级和实用的特性它不支持，需要自己去实现。 Netty的ByteBufNetty的ByteBuf在ByteBuffer上做了修改，区分了读写，引入了两个位置属性，readIndex和writeIndex来取代position。这样就可以不用切换flip了。a、首先初始化一个ByteBuf，b、开始的时候readIndex=writeIndex=0，c、写数据，writeIndex向后移动d、读数据，readIndex向后移，但是不能超过writeIndexe、从0-readIndex这部分叫做discard，调用discardReadBytes方法，可以释放这部分空间。类似于ByteBuffer的compact方法。回收之后，0 = readIndex，writeIndex= writeIndex-discard。可写的区域变大了。从readIndex到writeIndex这之间的数据可读，从writeIndex到capacity这之间的数据可写。 ByteBuf的继承关系 从内存分配角度看：（1）堆内存（HeapByteBuf）字节缓冲区：特点是内存的分配和回收速度快，可以被JVM自动回收；缺点是如果进行Socket的I/O读写，需要额外做一次内存复制，将堆内存对应的缓冲区复制到内核Channel中，性能有一定的下降（2）直接内存（DirectByteBuf）字节缓冲区：非堆内存，它在堆外进行内存分配，相比于堆内存，它的分配和回收会慢一点，但是将它写入和从SocketChannel中读取时，相当于少一次内存复制，速度比对内存快。**经验表明：ByteBuf最佳实践是在I/O通信线程读写缓冲区使用DirectByteBuf，后端业务消息的编解码模块使用HeapByteBuf，这样组合可以达到性能最优。 从内存回收角度看对象池的ByteBuf和普通ByteBuf。两者的主要区别是就是基于对象池的ByteBuf可以重用ByteBuf对象，它自己维护一个内存池，可以循环利用创建的ByteBuf，提升内存使用效率，降低由于高负载导致的频繁GC。测试标明使用内存池后的Netty在高负载，大并发的冲击下内存和GC更加平稳。尽管推荐使用基于内存池的ByteBuf，但是内存池的管理和维护更加复杂，使用起来更加谨慎。 ByteBuf的动态扩展正常情况下，NIO对ByteBuffer进行put操作时，如果缓冲区剩余可写空间不够，会发生BufferOverflowException。为了避免这个问题，通常在put时会对剩余可用空间进行校验，如果剩余空间不足，需要重新创建一个新的ByteBuffer，并将之前的ByteBuffer复制到新创建的ByteBuffer中，最后释放老的ByteBuffer。而由ByteBuf的write操作负责剩余的可用空间检验，如果可用缓冲区不足，ByteBuf会自动扩容。对于使用者而言，不需要关系底层的校验和扩展。代码如下。三个参数，src写的数据，srcIndex就是writeIndex，长度。 public ByteBuf writeBytes(byte[] src, int srcIndex, int length) { this.ensureAccessible(); this.ensureWritable(length); this.setBytes(this.writerIndex, src, srcIndex, length); this.writerIndex += length; return this; } public ByteBuf ensureWritable(int minWritableBytes) { if (minWritableBytes &lt; 0) { throw new IllegalArgumentException(String.format(&quot;minWritableBytes: %d (expected: &gt;= 0)&quot;, minWritableBytes)); } else if (minWritableBytes &lt;= this.writableBytes()) { return this; } else if (minWritableBytes &gt; this.maxCapacity - this.writerIndex) { throw new IndexOutOfBoundsException(String.format(&quot;writerIndex(%d) + minWritableBytes(%d) exceeds maxCapacity(%d): %s&quot;, this.writerIndex, minWritableBytes, this.maxCapacity, this)); } else { int newCapacity = this.alloc().calculateNewCapacity(this.writerIndex + minWritableBytes, this.maxCapacity); this.capacity(newCapacity); return this; } } ByteBuf的主要API以AbstractByteBuf为例来看，除了上面的write方法之外，还有readBytes：缓冲区的内容 public ByteBuf readBytes(byte[] dst, int dstIndex, int length) { //对缓冲区的可用空间进行校验 this.checkReadableBytes(length); this.getBytes(this.readerIndex, dst, dstIndex, length); this.readerIndex += length; return this; } slice：获取调用者的子缓冲区，且与原缓冲区共享缓冲区 public ByteBuf slice() { return this.slice(this.readerIndex, this.readableBytes()); } public SlicedByteBuf(ByteBuf buffer, int index, int length) { super(length); if (index &gt;= 0 &amp;&amp; index &lt;= buffer.capacity() - length) { if (buffer instanceof SlicedByteBuf) { this.buffer = ((SlicedByteBuf)buffer).buffer; this.adjustment = ((SlicedByteBuf)buffer).adjustment + index; } else if (buffer instanceof DuplicatedByteBuf) { this.buffer = buffer.unwrap(); this.adjustment = index; } else { this.buffer = buffer; this.adjustment = index; } this.length = length; this.writerIndex(length); } else { throw new IndexOutOfBoundsException(buffer + &quot;.slice(&quot; + index + &quot;, &quot; + length + &apos;)&apos;); } } copy：复制一份全新的对象，内容和缓冲区都不是共享的 public ByteBuf copy(int index, int length) { this.checkIndex(index, length); return this.buffer.copy(index + this.adjustment, length); } duplicate：复制当前对象，复制后的对象与前对象共享缓冲区，且维护自己的独立索引 public ByteBuf duplicate() { return new DuplicatedByteBuf(this); } public DuplicatedByteBuf(ByteBuf buffer) { super(buffer.maxCapacity()); if (buffer instanceof DuplicatedByteBuf) { this.buffer = ((DuplicatedByteBuf)buffer).buffer; } else { this.buffer = buffer; } this.setIndex(buffer.readerIndex(), buffer.writerIndex()); } discardReadBytes和discardSomeReadBytes：重用缓冲区设置读写索引的同时需要调用adjustMarkers()调整markedReaderIndex和markedWriterIndex public ByteBuf discardReadBytes() { this.ensureAccessible(); if (this.readerIndex == 0) { return this; } else { if (this.readerIndex != this.writerIndex) { this.setBytes(0, this, this.readerIndex, this.writerIndex - this.readerIndex); this.writerIndex -= this.readerIndex; this.adjustMarkers(this.readerIndex); this.readerIndex = 0; } else { this.adjustMarkers(this.readerIndex); this.writerIndex = this.readerIndex = 0; } return this; } } public ByteBuf discardSomeReadBytes() { this.ensureAccessible(); if (this.readerIndex == 0) { return this; } else if (this.readerIndex == this.writerIndex) { this.adjustMarkers(this.readerIndex); this.writerIndex = this.readerIndex = 0; return this; } else { if (this.readerIndex &gt;= this.capacity() &gt;&gt;&gt; 1) { this.setBytes(0, this, this.readerIndex, this.writerIndex - this.readerIndex); this.writerIndex -= this.readerIndex; this.adjustMarkers(this.readerIndex); this.readerIndex = 0; } return this; } } protected final void adjustMarkers(int decrement) { int markedReaderIndex = this.markedReaderIndex; if (markedReaderIndex &lt;= decrement) { this.markedReaderIndex = 0; int markedWriterIndex = this.markedWriterIndex; if (markedWriterIndex &lt;= decrement) { this.markedWriterIndex = 0; } else { this.markedWriterIndex = markedWriterIndex - decrement; } } else { this.markedReaderIndex = markedReaderIndex - decrement; this.markedWriterIndex -= decrement; } } skipBytes：丢弃非法的数据报 public ByteBuf skipBytes(int length) { this.checkReadableBytes(length); this.readerIndex += length; return this; } 代码示例import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; public class Test { public static void main(String[] args) { ByteBuf byteBuf = Unpooled.buffer(4); //ByteBuf byteBuf = Unpooled.directBuffer(4); byteBuf.writeByte(1); byteBuf.writeByte(2); //结果为1 System.out.println(byteBuf.readByte()); //结果为2 System.out.println(byteBuf.readByte()); byteBuf.writeByte(3); //结果为2 System.out.println(byteBuf.readerIndex()); //结果为3 System.out.println(byteBuf.writerIndex()); byteBuf.discardReadBytes(); //结果为0 System.out.println(byteBuf.readerIndex()); //结果为1 System.out.println(byteBuf.writerIndex()); byteBuf.writeByte(3); byteBuf.writeByte(3); byteBuf.writeByte(3); byteBuf.writeByte(3); byteBuf.writeByte(3); byteBuf.writeByte(3); //结果为0 System.out.println(byteBuf.readerIndex()); //结果为7 System.out.println(byteBuf.writerIndex()); //结果为64 System.out.println(byteBuf.capacity()); //slice是重新复制了一个对象 ByteBuf slice = byteBuf.slice(); //结果为7 System.out.println(slice.writerIndex()); //UnpooledHeapByteBuf(ridx: 0, widx: 7, cap: 64) System.out.println(byteBuf.markReaderIndex()); //SlicedByteBuf(ridx: 0, widx: 7, cap: 7/7, unwrapped: UnpooledHeapByteBuf(ridx: 0, widx: 7, cap: 64)) System.out.println(slice.markReaderIndex()); ByteBuf copy = byteBuf.copy(); //copy是复制了byteBuf //结果是UnpooledHeapByteBuf(ridx: 0, widx: 7, cap: 7) System.out.println(copy.markReaderIndex()); } } 其他的以后再慢慢熟悉吧。]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty之客户端创建]]></title>
    <url>%2F2017%2F10%2F25%2Fnetty%E4%B9%8B%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%88%9B%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[其实客户端创建和服务端流程差不多，但是更加复杂，有线程模型，异步连接，客户端连接超时，各种异常处理。 客户端的实例代码如下：import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; import io.netty.handler.codec.string.StringDecoder; public class TimeClient { public void connect(int port, String host) throws Exception { // 配置客户端NIO线程组 EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new StringDecoder()); ch.pipeline().addLast(new TimeClientHandler()); } }); // 发起异步连接操作 ChannelFuture f = b.connect(host, port).sync(); // 当代客户端链路关闭 f.channel().closeFuture().sync(); } finally { // 优雅退出，释放NIO线程组 group.shutdownGracefully(); } } public static void main(String[] args) throws Exception { int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { // 采用默认值 } } new TimeClient().connect(port, &quot;127.0.0.1&quot;); } } 客户端创建步骤根据上面的代码：1、用户线程创建Bootstrap实例，通过API设置创建客户端相关的参数，异步发起客户端连接。 Bootstrap b = new Bootstrap(); 源码是： private static final NameResolverGroup&lt;?&gt; DEFAULT_RESOLVER; public Bootstrap() { this.resolver = DEFAULT_RESOLVER; } 2、创建处理客户端连接，I/O读写的Reactor线程组NioEventLoopGroup。可以通过构造行数指定I/O的个数，默认是CPU内核数的2倍。 EventLoopGroup group = new NioEventLoopGroup(); 3、通过Bootstrap的ChannelFactory和用户指定的Channel类型创建用于客户端连接的NioSocketChannel，它的功能类似于Jdk的SocketChannel b.group(group).channel(NioSocketChannel.class) 源码如下： private volatile EventLoopGroup group; public B group(EventLoopGroup group) { if (group == null) { throw new NullPointerException(&quot;group&quot;); } else if (this.group != null) { throw new IllegalStateException(&quot;group set already&quot;); } else { this.group = group; return this; } } public B channel(Class&lt;? extends C&gt; channelClass) { if (channelClass == null) { throw new NullPointerException(&quot;channelClass&quot;); } else { //用反射创建一个ChannelFactory对象 return this.channelFactory((io.netty.channel.ChannelFactory)(new ReflectiveChannelFactory(channelClass))); } } 4、创建默认的ChannelHandler Pipeline。用于调度和执行网络事件 5、异步发起TCP连接，判断连接是否成功如果成功，则直接将NioSocketChannel注册到多路复用器上，监听读操作位，用于数据报读取和消息发送。如果没有立即连接成功，则注册到连接监听位到多路复用器，等待连接结果。Channel配置参数: //ByteBuf的分配器，默认值为ByteBufAllocator.DEFAULT，4.0版本为UnpooledByteBufAllocator，4.1版本为PooledByteBufAllocator。该值也可以使用系统参数io.netty.allocator.type配置，使用字符串值：&quot;unpooled&quot;，&quot;pooled&quot; public static final ChannelOption&lt;ByteBufAllocator&gt; ALLOCATOR = valueOf(&quot;ALLOCATOR&quot;); //用于Channel分配接受Buffer的分配器，默认值为AdaptiveRecvByteBufAllocator.DEFAULT，是一个自适应的接受缓冲区分配器，能根据接受到的数据自动调节大小。可选值为FixedRecvByteBufAllocator，固定大小的接受缓冲区分配器。 public static final ChannelOption&lt;RecvByteBufAllocator&gt; RCVBUF_ALLOCATOR = valueOf(&quot;RCVBUF_ALLOCATOR&quot;); //消息大小估算器，默认为DefaultMessageSizeEstimator.DEFAULT。估算ByteBuf、ByteBufHolder和FileRegion的大小，其中ByteBuf和ByteBufHolder为实际大小，FileRegion估算值为0。该值估算的字节数在计算水位时使用，FileRegion为0可知FileRegion不影响高低水位。 public static final ChannelOption&lt;MessageSizeEstimator&gt; MESSAGE_SIZE_ESTIMATOR = valueOf(&quot;MESSAGE_SIZE_ESTIMATOR&quot;); //客户端连接超时时间,默认值30000毫秒即30秒。 public static final ChannelOption&lt;Integer&gt; CONNECT_TIMEOUT_MILLIS = valueOf(&quot;CONNECT_TIMEOUT_MILLIS&quot;); public static final ChannelOption&lt;Integer&gt; MAX_MESSAGES_PER_READ = valueOf(&quot;MAX_MESSAGES_PER_READ&quot;); //一次Loop读取的最大消息数，对于ServerChannel或者NioByteChannel，默认值为16，其他Channel默认值为1。默认值这样设置，是因为：ServerChannel需要接受足够多的连接，保证大吞吐量，NioByteChannel可以减少不必要的系统调用select。 public static final ChannelOption&lt;Integer&gt; WRITE_SPIN_COUNT = valueOf(&quot;WRITE_SPIN_COUNT&quot;); //写高水位标记，默认值64KB。如果Netty的写缓冲区中的字节超过该值，Channel的isWritable()返回False。 public static final ChannelOption&lt;Integer&gt; WRITE_BUFFER_HIGH_WATER_MARK = valueOf(&quot;WRITE_BUFFER_HIGH_WATER_MARK&quot;); //写低水位标记，默认值32KB。当Netty的写缓冲区中的字节超过高水位之后若下降到低水位，则Channel的isWritable()返回True。写高低水位标记使用户可以控制写入数据速度，从而实现流量控制 public static final ChannelOption&lt;Integer&gt; WRITE_BUFFER_LOW_WATER_MARK = valueOf(&quot;WRITE_BUFFER_LOW_WATER_MARK&quot;); //一个连接的远端关闭时本地端是否关闭，默认值为False。值为False时，连接自动关闭；为True时，触发ChannelInboundHandler的userEventTriggered()方法，事件为ChannelInputShutdownEvent。 public static final ChannelOption&lt;Boolean&gt; ALLOW_HALF_CLOSURE = valueOf(&quot;ALLOW_HALF_CLOSURE&quot;); //自动读取，默认值为True。Netty只在必要的时候才设置关心相应的I/O事件。 public static final ChannelOption&lt;Boolean&gt; AUTO_READ = valueOf(&quot;AUTO_READ&quot;); //Socket参数，设置广播模式。 public static final ChannelOption&lt;Boolean&gt; SO_BROADCAST = valueOf(&quot;SO_BROADCAST&quot;); //Socket参数，连接保活，默认值为False。启用该功能时，TCP会主动探测空闲连接的有效性。可以将此功能视为TCP的心跳机制，需要注意的是：默认的心跳间隔是7200s即2小时。Netty默认关闭该功能。 public static final ChannelOption&lt;Boolean&gt; SO_KEEPALIVE = valueOf(&quot;SO_KEEPALIVE&quot;); //套接字使用的发送缓存区大小 public static final ChannelOption&lt;Integer&gt; SO_SNDBUF = valueOf(&quot;SO_SNDBUF&quot;); //套接字使用的接收缓存区大小 public static final ChannelOption&lt;Integer&gt; SO_RCVBUF = valueOf(&quot;SO_RCVBUF&quot;); //用于决定如果网络上仍然有数据向旧的ServerSocket传输数据，是否允许新的ServerSocket绑定到旧的ServerSocket通用的端口上 public static final ChannelOption&lt;Boolean&gt; SO_REUSEADDR = valueOf(&quot;SO_REUSEADDR&quot;); //Netty对底层Socket参数的简单封装，关闭Socket的延迟时间，默认值为-1，表示禁用该功能。-1以及所有&lt;0的数表示socket.close()方法立即返回，但OS底层会将发送缓冲区全部发送到对端。0表示socket.close()方法立即返回，OS放弃发送缓冲区的数据直接向对端发送RST包，对端收到复位错误。非0整数值表示调用socket.close()方法的线程被阻塞直到延迟时间到或发送缓冲区中的数据发送完毕，若超时，则对端会收到复位错误。 public static final ChannelOption&lt;Integer&gt; SO_LINGER = valueOf(&quot;SO_LINGER&quot;); //Socket参数，服务端接受连接的队列长度，如果队列已满，客户端连接将被拒绝。默认值，Windows为200，其他为128。 public static final ChannelOption&lt;Integer&gt; SO_BACKLOG = valueOf(&quot;SO_BACKLOG&quot;); //控制读取操作将阻塞多少毫秒，如果返回0，计时器就禁止了，改线程无限期阻塞 public static final ChannelOption&lt;Integer&gt; SO_TIMEOUT = valueOf(&quot;SO_TIMEOUT&quot;); //IP参数，设置IP头部的Type-of-Service字段，用于描述IP包的优先级和QoS选项。 public static final ChannelOption&lt;Integer&gt; IP_TOS = valueOf(&quot;IP_TOS&quot;); //对应IP参数IP_MULTICAST_IF，设置对应地址的网卡为多播模式。 public static final ChannelOption&lt;InetAddress&gt; IP_MULTICAST_ADDR = valueOf(&quot;IP_MULTICAST_ADDR&quot;); //对应IP参数IP_MULTICAST_IF2，同上但支持IPV6。 public static final ChannelOption&lt;NetworkInterface&gt; IP_MULTICAST_IF = valueOf(&quot;IP_MULTICAST_IF&quot;); //IP参数，多播数据报的time-to-live即存活跳数。 public static final ChannelOption&lt;Integer&gt; IP_MULTICAST_TTL = valueOf(&quot;IP_MULTICAST_TTL&quot;); //对应IP参数IP_MULTICAST_LOOP，设置本地回环接口的多播功能。由于IP_MULTICAST_LOOP返回True表示关闭，所以Netty加上后缀_DISABLED防止歧义。 public static final ChannelOption&lt;Boolean&gt; IP_MULTICAST_LOOP_DISABLED = valueOf(&quot;IP_MULTICAST_LOOP_DISABLED&quot;); //激活或者禁止TCP_NODELAY 套接字选项，决定是否使用Nagle算法 public static final ChannelOption&lt;Boolean&gt; TCP_NODELAY = valueOf(&quot;TCP_NODELAY&quot;); 6、注册对应的网络监听状态位到多路复用器 ChannelFuture f = b.connect(host, port).sync(); 7、由多路复用器在I/O现场中轮询各Channel，处理连接结果8、如果连接成功，设置Future结果，发送连接成功实践，触发ChannelPipeline执行9、由ChannelPipeline调度执行系统和用户的ChannelHandler，执行业务逻辑。其实，这个大体和服务端一致，只是有些细微的区别。]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java面试之垃圾回收机制]]></title>
    <url>%2F2017%2F10%2F25%2Fjava%E9%9D%A2%E8%AF%95%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[垃圾回收机制请先去看 http://www.jianshu.com/p/b3eff15b3f72 四种引用状态在JDK1.2之前，Java中引用的定义很传统：如果引用类型的数据中存储的数值代表的是另一块内存的起始地址，就称这块内存代表着一个引用。这种定义很纯粹，但是太过于狭隘，一个对象只有被引用或者没被引用两种状态。我们希望描述这样一类对象：当内存空间还足够时，则能保留在内存中；如果内存空间在进行垃圾收集后还是非常紧张，则可以抛弃这些对象。很多系统的缓存功能都符合这样的应用场景。在JDK1.2之后，Java对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用4种，这4种引用强度依次减弱。1、强引用代码中普遍存在的类似”Object obj = new Object()”这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。2、软引用描述有些还有用但并非必需的对象。在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围进行二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。Java中的类SoftReference表示软引用。3、弱引用描述非必需对象。被弱引用关联的对象只能生存到下一次垃圾回收之前，垃圾收集器工作之后，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。Java中的类WeakReference表示弱引用。4、虚引用这个引用存在的唯一目的就是在这个对象被收集器回收时收到一个系统通知，被虚引用关联的对象，和其生存时间完全没关系。Java中的类PhantomReference表示虚引用。 垃圾回收算法标记-清除（Mark-Sweep）算法这是最基础的算法，标记-清除算法就如同它的名字样，分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，标记完成后统一回收所有被标记的对象。这种算法的不足主要体现在效率和空间，从效率的角度讲，标记和清除两个过程的效率都不高；从空间的角度讲，标记清除后会产生大量不连续的内存碎片， 内存碎片太多可能会导致以后程序运行过程中在需要分配较大对象时，无法找到足够的连续内存而不得不提前触发一次垃圾收集动作。标记-清除算法执行过程如图： 复制（Copying）算法复制算法是为了解决效率问题而出现的，它将可用的内存分为两块，每次只用其中一块，当这一块内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已经使用过的内存空间一次性清理掉。这样每次只需要对整个半区进行内存回收，内存分配时也不需要考虑内存碎片等复杂情况，只需要移动指针，按照顺序分配即可。复制算法的执行过程如图：不过这种算法有个缺点，内存缩小为了原来的一半，这样代价太高了。现在的商用虚拟机都采用这种算法来回收新生代，不过研究表明1:1的比例非常不科学，因此新生代的内存被划分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。每次回收时，将Eden和Survivor中还存活着的对象一次性复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。HotSpot虚拟机默认Eden区和Survivor区的比例为8:1，意思是每次新生代中可用内存空间为整个新生代容量的90%。当然，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖老年代进行分配担保（Handle Promotion）。 标记-整理（Mark-Compact）算法复制算法在对象存活率较高的场景下要进行大量的复制操作，效率很低。万一对象100%存活，那么需要有额外的空间进行分配担保。老年代都是不易被回收的对象，对象存活率高，因此一般不能直接选用复制算法。根据老年代的特点，有人提出了另外一种标记-整理算法，过程与标记-清除算法一样，不过不是直接对可回收对象进行清理，而是让所有存活对象都向一端移动，然后直接清理掉边界以外的内存。标记-整理算法的工作过程如图： 分代收集算法根据上面的内容，用一张图概括一下堆内存的布局 现代商用虚拟机基本都采用分代收集算法来进行垃圾回收。这种算法没什么特别的，无非是上面内容的结合罢了，根据对象的生命周期的不同将内存划分为几块，然后根据各块的特点采用最适当的收集算法。大批对象死去、少量对象存活的（新生代），使用复制算法，复制成本低；对象存活率高、没有额外空间进行分配担保的（老年代），采用标记-清理算法或者标记-整理算法。 垃圾收集器垃圾收集器就是上面讲的理论知识的具体实现了。不同虚拟机所提供的垃圾收集器可能会有很大差别，我们使用的是HotSpot，HotSpot这个虚拟机所包含的所有收集器如图：上图展示了7种作用于不同分代的收集器，如果两个收集器之间存在连线，那说明它们可以搭配使用。虚拟机所处的区域说明它是属于新生代收集器还是老年代收集器。多说一句，我们必须明确一个观点：没有最好的垃圾收集器，更加没有万能的收集器，只能选择对具体应用最合适的收集器。这也是HotSpot为什么要实现这么多收集器的原因。 1、Serial收集器最基本、发展历史最久的收集器，这个收集器是一个采用复制算法的单线程的收集器，单线程一方面意味着它只会使用一个CPU或一条线程去完成垃圾收集工作，另一方面也意味着它进行垃圾收集时必须暂停其他线程的所有工作，直到它收集结束为止。后者意味着，在用户不可见的情况下要把用户正常工作的线程全部停掉，这对很多应用是难以接受的。不过实际上到目前为止，Serial收集器依然是虚拟机运行在Client模式下的默认新生代收集器，因为它简单而高效。用户桌面应用场景中，分配给虚拟机管理的内存一般来说不会很大，收集几十兆甚至一两百兆的新生代停顿时间在几十毫秒最多一百毫秒，只要不是频繁发生，这点停顿是完全可以接受的。Serial收集器运行过程如下图所示： 说明：1. 需要STW（Stop The World），停顿时间长。2. 简单高效，对于单个CPU环境而言，Serial收集器由于没有线程交互开销，可以获取最高的单线程收集效率。 2、ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本，除了使用多条线程进行垃圾收集外，其余行为和Serial收集器完全一样，包括使用的也是复制算法。ParNew收集器除了多线程以外和Serial收集器并没有太多创新的地方，但是它却是Server模式下的虚拟机首选的新生代收集器，其中有一个很重要的和性能无关的原因是，除了Serial收集器外，目前只有它能与CMS收集器配合工作（看图）。CMS收集器是一款几乎可以认为有划时代意义的垃圾收集器，因为它第一次实现了让垃圾收集线程与用户线程基本上同时工作。ParNew收集器在单CPU的环境中绝对不会有比Serial收集器更好的效果，甚至由于线程交互的开销，该收集器在两个CPU的环境中都不能百分之百保证可以超越Serial收集器。当然，随着可用CPU数量的增加，它对于GC时系统资源的有效利用还是很有好处的。它默认开启的收集线程数与CPU数量相同，在CPU数量非常多的情况下，可以使用-XX:ParallelGCThreads参数来限制垃圾收集的线程数。ParNew收集器运行过程如下图所示： 3、Parallel Scavenge收集器Parallel Scavenge收集器也是一个新生代收集器，也是用复制算法的收集器，也是并行的多线程收集器，但是它的特点是它的关注点和其他收集器不同。介绍这个收集器主要还是介绍吞吐量的概念。CMS等收集器的关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目标则是打到一个可控制的吞吐量。所谓吞吐量的意思就是CPU用于运行用户代码时间与CPU总消耗时间的比值，即吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间），虚拟机总运行100分钟，垃圾收集1分钟，那吞吐量就是99%。另外，Parallel Scavenge收集器是虚拟机运行在Server模式下的默认垃圾收集器。 停顿时间短适合需要与用户交互的程序，良好的响应速度能提升用户体验；高吞吐量则可以高效率利用CPU时间，尽快完成运算任务，主要适合在后台运算而不需要太多交互的任务。 虚拟机提供了-XX:MaxGCPauseMillis和-XX:GCTimeRatio两个参数来精确控制最大垃圾收集停顿时间和吞吐量大小。不过不要以为前者越小越好，GC停顿时间的缩短是以牺牲吞吐量和新生代空间换取的。由于与吞吐量关系密切，Parallel Scavenge收集器也被称为“吞吐量优先收集器”。Parallel Scavenge收集器有一个-XX:+UseAdaptiveSizePolicy参数，这是一个开关参数，这个参数打开之后，就不需要手动指定新生代大小、Eden区和Survivor参数等细节参数了，虚拟机会根据当前系统的运行情况手机性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。如果对于垃圾收集器运作原理不太了解，以至于在优化比较困难的时候，使用Parallel Scavenge收集器配合自适应调节策略，把内存管理的调优任务交给虚拟机去完成将是一个不错的选择**。 4、Serial Old收集器Serial收集器的老年代版本，同样是一个单线程收集器，使用“标记-整理算法”，这个收集器的主要意义也是在于给Client模式下的虚拟机使用。 5、Parallel Old收集器Parallel Scavenge收集器的老年代版本，使用多线程和“标记-整理”算法。这个收集器在JDK 1.6之后的出现，“吞吐量优先收集器”终于有了比较名副其实的应用组合，在注重吞吐量以及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge收集器+Parallel Old收集器的组合。运行过程如下图所示： 6、CMS收集器CMS（Conrrurent Mark Sweep）收集器是以获取最短回收停顿时间为目标的收集器。使用标记 - 清除算法，收集过程分为如下四步：(1). 初始标记，标记GCRoots能直接关联到的对象，时间很短。(2). 并发标记，进行GCRoots Tracing（可达性分析）过程，时间很长。(3). 重新标记，修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，时间较长。(4). 并发清除，回收内存空间，时间很长。其中，并发标记与并发清除两个阶段耗时最长，但是可以与用户线程并发执行。运行过程如下图所示:说明：1. 对CPU资源非常敏感，可能会导致应用程序变慢，吞吐率下降。2. 无法处理浮动垃圾，因为在并发清理阶段用户线程还在运行，自然就会产生新的垃圾，而在此次收集中无法收集他们，只能留到下次收集，这部分垃圾为浮动垃圾，同时，由于用户线程并发执行，所以需要预留一部分老年代空间提供并发收集时程序运行使用。3. 由于采用的标记 - 清除算法，会产生大量的内存碎片，不利于大对象的分配，可能会提前触发一次Full GC。虚拟机提供了-XX:+UseCMSCompactAtFullCollection参数来进行碎片的合并整理过程，这样会使得停顿时间变长，虚拟机还提供了一个参数配置，-XX:+CMSFullGCsBeforeCompaction，用于设置执行多少次不压缩的Full GC后，接着来一次带压缩的GC。 7、G1收集器G1是目前技术发展的最前沿成果之一，HotSpot开发团队赋予它的使命是未来可以替换掉JDK1.5中发布的CMS收集器。与其他GC收集器相比，G1收集器有以下特点：(1). 并行和并发。使用多个CPU来缩短Stop The World停顿时间，与用户线程并发执行。(2). 分代收集。独立管理整个堆，但是能够采用不同的方式去处理新创建对象和已经存活了一段时间、熬过多次GC的旧对象，以获取更好的收集效果。(3). 空间整合。基于标记 - 整理算法，无内存碎片产生。(4). 可预测的停顿。能简历可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。 在G1之前的垃圾收集器，收集的范围都是整个新生代或者老年代，而G1不再是这样。使用G1收集器时，Java堆的内存布局与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分（可以不连续）Region的集合。 GC日志的理解GC LOG 及Collector行为分析LOG分析包含前面文章所介绍的各个GC collector的行为分析。通过加入 -XX:+PrintGCDetails 参数则可以打印详细GC信息至控制台。参数-verbose:gc也是可以，但不够详细。通过加入-XX:+PrintGCDateStamps则可以记录GC发生的详细时间。通过加入 -Xloggc:/home/XX/gc/app_gc.log 可以把GC输出至文件，这对长时间服务器GC监控很有帮助。以下列出一些参数大致打印的信息如下： -verbose:gc： [GC 72104K-&gt;9650K(317952K), 0.0130635 secs] -XX:+PrintGCDetails: [GC [PSYoungGen: 142826K-&gt;10751K(274944K)] 162800K-&gt;54759K(450048K), 0.0609952 secs] [Times: user=0.13 sys=0.02, real=0.06 secs] -XX:+PrintGCDetails 加上-XX:+PrintGCDateStamps 参数则打印如下：2015-12-06T12:32:02.890+0800: [GC [PSYoungGen: 142833K-&gt;10728K(142848K)] 166113K-&gt;59145K(317952K), 0.0792023 secs] [Times: user=0.22 sys=0.00, real=0.08 secs] 可以看出，如果是想监控详细信息与GC发生时间，加上-XX:+PrintGCDateStamps -XX:+PrintGCDetails 参数会是一个比较好的选择。 首先来说明一段在各个GC中通用的字段含义说明：1、142826K-&gt;10751K(274944K) 分别代表回收前、回收后以及总内存大小。2、Times: user=0.46 sys=0.05, real=0.07 secs： user代表GC 需要的各个CPU总时间(各个CPU时间相加)，sys代表回收器自身的行为所占用CPU时间，real则代表本次GC所耗费的真正耗时(在多核CPU中并行回收，它通常小于user) 。 Serial GC (-XX:+UseSerialGC) 下面是一段的Serial GC日志含义依次分解： [GC[DefNew: 78656K-&gt;8704K(78656K), 0.0487492 secs] 135584K-&gt;80553K(253440K), 0.0488309 secs] [Times: user=0.05 sys=0.00, real=0.05 secs] [Full GC[Tenured: 62546K-&gt;60809K(174784K), 0.1600120 secs] 85931K-&gt;60809K(253440K), [Perm : 38404K-&gt;38404K(65536K)], 0.1600814 secs] [Times: user=0.16 sys=0.00, real=0.16 secs] 其中的DefNew代表单线程回收yong generation。 紧跟后面的 78656K-&gt;8704K(78656K) 中的 78656K 代表young generation 回收前大小，8704K 代表回收后大小，括号中的78656K 代表young generation总大小(包含2个survivor)。 135584K-&gt;80553K(253440K) 则代表整个Heap(young+old)的变化与总量，含义参照前面所述(Perm也一样)。 Full GC 即代表 major GC, Tenured: 62546K-&gt;60809K(174784K)则表示 old generation变化及总量 ParallelGC-XX:-UseParallelGC：Use parallel garbage collection for scavenges. (Introduced in 1.4.1)-XX:-UseParallelOldGC：Use parallel garbage collection for the full collections. Enabling this option automatically sets -XX:+UseParallelGC. (Introduced in 5.0 update 6.)[GC [PSYoungGen: 88524K-&gt;10728K(274944K)] 133505K-&gt;61187K(450048K), 0.0374438 secs] [Times: user=0.08 sys=0.00, real=0.04 secs][Full GC [PSYoungGen: 10728K-&gt;0K(274944K)] [ParOldGen: 50459K-&gt;50210K(175104K)] 61187K-&gt;50210K(450048K) [PSPermGen: 38656K-&gt;38643K(77312K)], 0.3787131 secs] [Times: user=0.98 sys=0.02, real=0.38 secs] PSYoungGen 代表并行回收 young generation ParOldGen 代表并行回收 old generation. PSPermGen 代表并行回收 Permanent generation. 其他的参数与前面解释的类似。 CMS GCCMS GC相对来说比较复杂，通过使用 -XX:+UseConcMarkSweepGC 参数在指定，但是一般情况需要更多的其他参数来保证它能比较好地达到我们的低延时目的，下面就部分常用参数做介绍： -XX:+CMSIncrementalMode 采用增量式的标记方式，减少标记时应用停顿时间-XX:+CMSParallelRemarkEnabled 启用并行标记-XX:CMSInitiatingOccupancyFraction=70 Old generation消耗比例达到多少时进行回收，通常配置60-80之间-XX:CMSFullGCsBeforeCompaction=1 多少次Full GC 后压缩old generation一次-XX:+UseCMSInitiatingOccupancyOnly-XX:+ScavengeBeforeFullGC Old generation GC前对young generation GC一次，默认开启。-XX:+CMSScavengeBeforeRemark CMS remark之前进行一次young generation GC GC监控工具1、jstack 可以定位到具体的线程堆栈，定位cpu冲高 结合top实例： j&apos;s 2、jmap查看堆内存使用情况 3、jstat统计堆的使用情况 jstat用于实时监测 GC情况，如PID为7880的应用监测，每 1000毫秒打印一次： jstat -gc 7880 1000S0C S1C S0U S1U EC EU OC OU PC PU YGC YGCT FGC FGCT GCT8704.0 8704.0 8704.0 0.0 69952.0 14761.0 277100.0 181950.8 65536.0 37705.5 60 2.946 35 1.285 4.2318704.0 8704.0 8704.0 0.0 69952.0 14763.0 277100.0 181950.8 65536.0 37705.5 60 2.946 35 1.285 4.231 4、vivalueVM MAT]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty之服务端创建]]></title>
    <url>%2F2017%2F10%2F24%2Fnetty%E4%B9%8B%E6%9C%8D%E5%8A%A1%E7%AB%AF%E5%88%9B%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[服务端创建的时序图用户可以通过ServerBootstrap可以方便的创建Netty的服务端。 1、创建ServerBootstrap实例ServerBootstrap是Netty服务端的起动辅助类，它提供了一系列方法用于设置服务端的启动相关参数。底层通过门面模式对各种能力进行抽象和封装，尽量不需要用户跟过多的底层API打交道，以降低用户的开发难度。 ServerBootstrap b = new ServerBootstrap(); 创建ServerBootstrap的实例只需要一个无参的构造函数。因为ServerBootstrap需要的参数太多了，这里用了Builder设计模式。（遇到多个构造器参数时要考虑用构建器） 2、设置绑定Reactor线程池。Netty的Reactor线程池是EventLoopGroup，它实际就是EventLoop的数组。EvnetLoop的职责是处理所有注册到本线程多路复用器Selector上的Channel，Selector的轮询操作由绑定的EventLoop线程run方法驱动，在一个循环体内循环执行。EventLoop的职责不仅仅是处理网络I/O事件，用户自定义的Task和定时任务Task也由EventLoop负责处理，这样线程模型就实现了统一。从调度层看，也不存在从EventLoop线程中再启动其他类型的线程用于异步执行另外的任务，这样避免了多线程并发操作和锁竞争，提升了I/O线程的处理和调度性能。 EventLoopGroup bossGruop=new NioEventLoopGroup();//用于服务器端接受客户端的连接 EventLoopGroup workGroup=new NioEventLoopGroup();//用于网络事件的处理 3、设置并绑定服务端Channel作为服务端，需要创建ServerSocketChannel。Netty对原生的NIO进行了封装，对应的实现类是NioServerSocketChannel。 b.group(bossGruop, workGroup).channel(NioServerSocketChannel.class) 4、TCP链路建立的时候创建并初始化ChannelPipelineb.group(bossGroup, workGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 1024) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;(){ @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); } } ChannelPipeline的本质是一个负责处理网络事件的职责链，负责管理和执行ChannelHandler。网络事件以事件流的形式在ChannelPipeline中流转，由ChannelPipeline根据Channel|Handler的执行策略调度ChannelHandler的执行。典型的网络事件有： 链路注册 链路激活 链路断开 接收到请求信息 请求信息接收并处理完毕 发送应答消息 链路发生异常 用户自定义事件 5、添加并设置ChannelHandlerChannelHandler是提供用户定制或扩展的关键接口。利用ChannelHandler可以完成大多数功能定制。比较常用的ChannelHandler有：（1）系统编解码框架—–ByteToMessageCodec（2）通用基于长度的半包解码器—–LengthFieldBasedFrameDecoder（3）码流日志打印—–LoggingHandler（4）SSL安全认证—–SslHander（5）链路空闲检测—–IdleStateHandler（6）流量整形—–ChannelTrafficShapingHandler（7）Base64编解码—–Base64Decoder和Base64Encoder @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); //Msgpack编解码 pipeline.addLast(new MsgpackEncoder()); pipeline.addLast(new MsgpackDecoder()); //自定义EchoServerHandler ch.pipeline().addLast(new EchoServerHandler()); } 6、绑定并启动监听窗口在绑定监听端口之前系统回去做一系列的初始化和检测工作，完成之后，会启动监听端口，并将ServerSocketChannel注册到Selector上监听客户端连接。 ChannelFuture f = b.bind(port).sync(); 7、Selector轮询由Reactor线程NioEventLoop负责调度和执行Selector轮询操作，选择准备就绪的Channel集合。 8、网络事件通知当轮询到准备就绪的Channel之后，就由Reactor线程NioEventLoop执行ChannelPipeline的相应方法，最终调度并执行ChannelHandler。 9、执行Netty系统和业务HandlerChannel()public class EchoServerHandler extends ChannelInboundHandlerAdapter{} 示例代码Netty服务器端HelloServer： import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; //Netty服务器端 public class HelloServer { private int port; public HelloServer(int port) { super(); this.port = port; } private void bind() throws InterruptedException { EventLoopGroup bossGruop=new NioEventLoopGroup();//用于服务器端接受客户端的连接 EventLoopGroup workGroup=new NioEventLoopGroup();//用于网络事件的处理 try { ServerBootstrap b=new ServerBootstrap(); b.group(bossGruop, workGroup).channel(NioServerSocketChannel.class).childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel arg0) throws Exception { arg0.pipeline().addLast(new HelloServerHandler()); } }).option(ChannelOption.SO_BACKLOG, 1024);//指定此套接口排队的最大连接个数 ChannelFuture f=b.bind(port).sync(); f.channel().closeFuture().sync(); } finally { bossGruop.shutdownGracefully(); workGroup.shutdownGracefully(); } } public static void main(String[] args) throws InterruptedException { new HelloServer(8080).bind(); } } 自定义的ChannelHandler： import io.netty.buffer.ByteBuf; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; //自定义的ChannelHandler public class HelloServerHandler extends ChannelHandlerAdapter { @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { System.out.println(&quot;客户端连上了...&quot;); } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf=(ByteBuf) msg; byte[] req=new byte[buf.readableBytes()]; buf.readBytes(req); System.out.println(&quot;服务器端接收的消息：&quot;+new String(req)); } @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { ctx.close(); } } 然后启动HelloServer。在telnet中连接localhost 8080输入字符串，会在控制台显示]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java面试之类加载机制和双亲委派]]></title>
    <url>%2F2017%2F10%2F24%2Fjava%E9%9D%A2%E8%AF%95%E4%B9%8B%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%E5%92%8C%E5%8F%8C%E4%BA%B2%E5%A7%94%E6%B4%BE%2F</url>
    <content type="text"><![CDATA[什么是类的加载类的加载指的是将类的.class文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区内的数据结构。类的加载的最终产品是位于堆区中的Class对象，Class对象封装了类在方法区内的数据结构，并且向Java程序员提供了访问方法区内的数据结构的接口。 类的生命周期其种类的加载过程包括加载，验证，准备，解析，初始化五个阶段。在这五个阶段中，加载，验证，准备，初始化的顺序是固定的，而解析阶段则不一定，它在某些情况下可以在初始化阶段之后工作，这是为了支持java的运行时绑定（动态绑定）。这里的几个阶段是按顺序开始的，而不是按顺序进行或者完成，因为这些阶段通常交叉进行的。 加载查找并加载类的二进制数据，在这个阶段，虚拟机需要完成以下三件事情： 通过一个类的全限定名来获取其定义的二进制字节流 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在Java堆中生成一个代表这个类的java.lang.Class对象作为对方法区中这些数据的访问入口相对于类加载的其他阶段而言，加载阶段是可控性最强的阶段，因为程序猿既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器加载。双亲委派机制①加载完成之后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区中，而在堆中也创建一个java.lang.Class对象，这样可以通过该对象访问方法区中的这些数据。验证验证是连接的第一步，这一阶段是为了确保Class文件的字节流包含的信息符合当前虚拟机的要求，冰球不会危害虚拟机自身的安全。验证阶段大致完成4个检验动作： 文件格式验证：验证字节流是否符合Class文件格式的规范。 元数据验证：对字节码描述的信息进行语义分析，以保证其描述的信息符合java语言规范的要求。 字节码验证：通过数据流和控制流的分析，确定程序语义是合法的、符合逻辑的。 符号引用验证：确保解析动作能正确执行。验证阶段非常重要，但不是必须的，这个对程序运行期没有影响。如果所应用的类经过反复验证，可以考虑采用-Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载时间。 准备准备阶段是正式为类变量分配内存并设置泪变量初始值的阶段，这些内存都将在方法区中分配。选哟注意以下几点：1、这个阶段的内存分配仅仅是static变量，而不是实例变量。实例变量会在对象实例化的时候随着对象一起分配在java队中。2、这里所设置的初始值通常情况下是数据默认值，而不是java代码中所显式设置的值。 int a = 1;//这个阶段a的初始值就是0，而不是1另外还需注意下面几点： 对基本数据类型来说，对于类变量（static）和全局变量，如果不显式地对其赋值而直接使用，则系统会为其赋予默认的零值，而对于局部变量来说，在使用前必须显式地为其赋值，否则编译时不通过。 对于同时被static和final修饰的常量，必须在声明的时候就为其显式地赋值，否则编译时不通过；而只被final修饰的常量则既可以在声明时显式地为其赋值，也可以在类初始化时显式地为其赋值，总之，在使用前必须为其显式地赋值，系统不会为其赋予默认零值。 对于引用数据类型reference来说，如数组引用、对象引用等，如果没有对其进行显式地赋值而直接使用，系统都会为其赋予默认的零值，即null。 如果在数组初始化时没有对数组中的各元素赋值，那么其中的元素将根据对应的数据类型而被赋予默认的值3、也就是第二点中，如果一个属性同时被final和static修饰，准备阶段就会初始化为指定的值并放入常量池。解析解析阶段是虚拟机将常量池中的符号引用转换为直接引用的过程，解析动作主要针对类或者接口、字段、类方法、接口方法、方法类型、方法句柄、调用点限定符7类符号引用进行。符号引用就是一组符号来描述目标，可以是任何字符。初始化为类的静态变量赋予正确的初始值，JVM负责对类进行初始化，主要对类变量进行初始化。在Java中对类变量进行初始值设定有两种方式：①声明类变量是指定初始值②使用静态代码块为类变量指定初始值JVM初始化步骤：1、假如这个类还没有被加载和连接，则程序先加载并连接该类2、假如该类的直接父类还没有被初始化，则先初始化其直接父类3、假如类中有初始化语句，则系统依次执行这些初始化语句类初始化时机：只有当对类的主动使用的时候才会导致类的初始化，类的主动使用包括以下六种： 创建类的实例，也就是new的方式 访问某个类或接口的静态变量，或者对该静态变量赋值 调用类的静态方法 反射（如Class.forName(“com.shengsiyuan.Test”)） 初始化某个类的子类，则其父类也会被初始化 Java虚拟机启动时被标明为启动类的类（Java Test），直接使用java.exe命令来运行某个主类结束生命周期在如下几种情况下，Java虚拟机将结束生命周期 执行了System.exit()方法 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Java虚拟机进程终止 类加载器 public class Test { public static void main(String[] args) { ClassLoader classLoader = Thread.currentThread().getContextClassLoader(); System.out.println(classLoader); System.out.println(classLoader.getParent()); System.out.println(classLoader.getParent().getParent()); } } 结果： sun.misc.Launcher$AppClassLoader@7d4991ad sun.misc.Launcher$ExtClassLoader@677327b6 null最后的null是由于Bootstrap Loader（引导类加载器）是用C语言实现的，找不到一个确定的返回父Loader的方式，于是就返回null。通过一个图看类加载器： 注意：这里父类加载器并不是通过继承关系来实现的，而是采用组合实现的。站在Java虚拟机的角度来讲，只存在两种不同的类加载器：启动类加载器：它使用C++实现（这里仅限于Hotspot，也就是JDK1.5之后默认的虚拟机，有很多其他的虚拟机是用Java语言实现的），是虚拟机自身的一部分；所有其他的类加载器：这些类加载器都由Java语言实现，独立于虚拟机之外，并且全部继承自抽象类java.lang.ClassLoader，这些类加载器需要由启动类加载器加载到内存中之后才能去加载其他的类。 站在Java开发人员的角度来看，类加载器可以大致划分为以下三类： 启动类加载器：Bootstrap ClassLoader，负责加载存放在JDK\jre\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库（如rt.jar，所有的java.开头的类均被Bootstrap ClassLoader加载）。启动类加载器是无法被Java程序直接引用的。扩展类加载器：Extension ClassLoader，该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载DK\jre\lib\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库（如javax.开头的类），开发者可以直接使用扩展类加载器。应用程序类加载器：Application ClassLoader，该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径（ClassPath）所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 应用程序都是由这三种类加载器互相配合进行加载的，如果有必要，我们还可以加入自定义的类加载器。因为JVM自带的ClassLoader只是懂得从本地文件系统加载标准的java class文件，因此如果编写了自己的ClassLoader，便可以做到如下几点： 1）在执行非置信代码之前，自动验证数字签名。2）动态地创建符合用户特定需要的定制化构建类。3）从特定的场所取得java class，例如数据库中和网络中。 JVM类加载机制全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入父类委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效 类加载有三种方式：1、命令行启动应用时候由JVM初始化加载2、通过Class.forName()方法动态加载3、通过ClassLoader.loadClass()方法动态加载 Class.forName()和ClassLoader.loadClass()区别Class.forName()：将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块；ClassLoader.loadClass()：只干一件事情，就是将.class文件加载到jvm中，不会执行static中的内容,只有在newInstance才会去执行static块。注：Class.forName(name, initialize, loader)带参函数也可控制是否加载static块。并且只有调用了newInstance()方法采用调用构造函数，创建类的对象 。 双亲委派模型双亲委派模型的工作流程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。双亲委派机制:1、当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。2、当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。3、如果BootStrapClassLoader加载失败（例如在$JAVA_HOME/jre/lib里未查找到该class），会使用ExtClassLoader来尝试加载；4、若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。ClassLoader源码分析： public Class&lt;?&gt; loadClass(String name)throws ClassNotFoundException { return loadClass(name, false); } protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve)throws ClassNotFoundException { // 首先判断该类型是否已经被加载 Class c = findLoadedClass(name); if (c == null) { //如果没有被加载，就委托给父类加载或者委派给启动类加载器加载 try { if (parent != null) { //如果存在父类加载器，就委派给父类加载器加载 c = parent.loadClass(name, false); } else { //如果不存在父类加载器，就检查是否是由启动类加载器加载的类，通过调用本地方法native Class findBootstrapClass(String name) c = findBootstrapClass0(name); } } catch (ClassNotFoundException e) { // 如果父类加载器和启动类加载器都不能完成加载任务，才调用自身的加载功能 c = findClass(name); } } if (resolve) { resolveClass(c); } return c; } 双亲委派模型意义： 系统类防止内存中出现多份同样的字节码 保证Java程序安全稳定运行]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty之私有栈]]></title>
    <url>%2F2017%2F10%2F23%2Fnetty%E4%B9%8B%E7%A7%81%E6%9C%89%E6%A0%88%2F</url>
    <content type="text"><![CDATA[协议栈功能设计Netty协议栈用于内部各模块间的通信，基于TCP/IP协议栈。 协议栈功能描述 基于Netty的NIO通信框架，提供高性能的异步通信能力 提供消息的编解码框架，可以实现POJO的序列化和反序列化 提供基于IP地址的白名单接入认证机制 链路的有效校验机制 链路的断连机制通信模型 （1） Netty协议栈客户端发送握手请求消息，携带节点ID等有效身份认证信息（2） Netty协议栈服务端对握手请求消息进行合法性验证。校验通过后，返回登陆成功的应答信息。（3） 链路建立成功之后，客户端发送业务消息。（4） 链路成功之后，服务端发送心跳消息。（5） 链路成功之后，客户端发送心跳消息。（6） 链路建立成功之后，服务端发送业务消息。（7） 服务端退出时，服务器关闭连接，客户端感知对方关闭，被动关闭客户端。注意：Netty协议通信双方链路建立成功之后，双发可以进行全双工通信，无论是客户端还是服务端，都可以主动发送消息给对方。双方之间的心跳采用Ping-Pong机制，当链路空闲时，客户端主动发送ping消息给服务端，服务端收到后发送Pong返回给客户端，如果客户端连续发送N条ping消息都没有收到服务端返回的pong消息，说明链路已经挂死或者对方处于异常，客户端应主动关闭连接，间隔周期T后发起重连操作，直到重连成功。 消息的定义Netty协议栈消息定义包含了两部分：消息头和消息体 Netty协议支持的字段类型java所有的基本类型还有String，map，set，array，list Netty协议的编解码使用同一的编解码类型 链路的建立Netty协议栈是支持服务端和客户端的，但是对于使用Netty协议栈的应用程序中，不需要刻意的去区别服务端和客户端。在分布式组网环境中，一个节点可能是服务端，也可能是客户端。Netty协议栈对客户端的说明如下，如果A节点需要调用B节点的服务，而A节点和B节点还没有建立物理链路，则由调用方主动发起连接。调用方称为客户端，被调用方称为服务端。注意链路建立的安全机制 链路的关闭由于采用长连接通信，在正常业务运行期间，双方通过心跳和业务消息维护链路，任何一方不需要主动关闭连接。在以下情况下，需要客户端和服务端关闭连接。 当双方关机或者重启时，会主动关闭链路，另一方读取到操作系统的通知信号，得知双方的REST链路，需要关闭连接，释放自身的 句柄等资源。由于采用TCP全双工通信，通信双方都需要关闭连接，释放资源。 消息读写过程中，发生了I/0异常，需要主动关闭连接 心跳超时，需要主动关闭连接 发生编码异常等不可恢复错误时，需要主动关闭连接可靠性设计1、心跳机制（1）当网络处于空闲状态达到T时，客户端主动发送Ping心跳消息给服务端。（2）如果在下一个周期T到来时客户端没有收到对方发送的Pong心跳应答消息或者读取到服务端发送的其他业务消息，则心跳失败计数器加1（3）每当客户端接收到服务的业务消息或者Pong应答消息，将心跳失败计数器清零；（4）服务端网络空闲状态时间达到T后，服务端将心跳失败计数器加1；只要连接到客户端发送的Ping消息或者其他业务消息，计数器清零；（5）服务端连续N次没有接收到客户端的Ping消息或者其他业务消息，则关闭链路，释放资源，等待客户端重连。2、重连机制要注意的只有一点，不是失败后立即重连，需要确保句柄资源释放，如果重连失败，必须打印异常堆栈信息。3、重复登录保护在缓存地址表中查看客户端死否已经登录，如果已经登录，则拒绝重复登录。如果客户有ID，看此客户ID是否登录。以上两个如果有一个验证未通过，返回-1安全设计IP白名单验证实例代码参考 http://www.cnblogs.com/carl10086/p/6195568.html]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty之WebSocket]]></title>
    <url>%2F2017%2F10%2F19%2Fnetty%E4%B9%8BWebSocket%2F</url>
    <content type="text"><![CDATA[Http的弊端HTTP的生命周期通过Request来界定，也就是一个Request 一个Response。那么在HTTP1.0中，这次HTTP请求就结束了。在HTTP1.1中进行了改进，使得有一个keep-alive，也就是说，在一个HTTP连接中，可以发送多个Request，接收多个Response。但是请记住 Request 和 Response ， 在HTTP中永远是这样，也就是说一个request只能有一个response。而且这个response也是被动的，不能主动发起。 ajax轮询其实ajax轮询就是在js上加上一个定时器 window.setInterval(function(){$.ajax(getting)},1000);//1秒执行一次 由于ajax轮询采用的是http协议，而http协议是无状态的，每次轮询都需要去建立连接，然后去判断。浪费带宽和服务器资源。 长连接获取资源，没有获取到资源就不断开。在无消息的情况下不会频繁的请求，耗费资源小。但是服务器hold连接会消耗资源，返回数据顺序无保证，难于管理维护。 Websocket传统HTTP客户端与服务器请求响应模式如下图所示： WebSocket模式客户端与服务器请求响应模式如下图： 上图对比可以看出，相对于传统HTTP每次请求-应答都需要客户端与服务端建立连接的模式，WebSocket是类似Socket的TCP长连接通讯模式。 一旦WebSocket连接建立后，后续数据都以帧序列的形式传输。在客户端断开WebSocket连接或Server端中断连接前，不需要客户端和服务端重新发起连接请求。在海量并发及客户端与服务器交互负载流量大的情况下，极大的节省了网络带宽资源的消耗，有明显的性能优势，且客户端发送和接受消息是在同一个持久连接上发起，实时性优势明显。 相比HTTP长连接，WebSocket有以下特点： 是真正的全双工方式，建立连接后客户端与服务器端是完全平等的，可以互相主动请求。而HTTP长连接基于HTTP，是传统的客户端对服务器发起请求的模式。 HTTP长连接中，每次数据交换除了真正的数据部分外，服务器和客户端还要大量交换HTTP header，信息交换效率很低。Websocket协议通过第一个request建立了TCP连接之后，之后交换的数据都不需要发送 HTTP header就能交换数据，这显然和原有的HTTP协议有区别所以它需要对服务器和客户端都进行升级才能实现（主流浏览器都已支持HTML5）。此外还有 multiplexing、不同的URL可以复用同一个WebSocket连接等功能。这些都是HTTP长连接不能做到的。 下面再通过客户端和服务端交互的报文对比WebSocket通讯与传统HTTP的不同点：在客户端，new WebSocket实例化一个新的WebSocket客户端对象，请求类似 ws://yourdomain:port/path 的服务端WebSocket URL，客户端WebSocket对象会自动解析并识别为WebSocket请求，并连接服务端端口，执行双方握手过程，客户端发送数据格式类似： GET /webfin/websocket/ HTTP/1.1 Host: localhost Upgrade: websocket Connection: Upgrade Sec-WebSocket-Key: xqBt3ImNzJbYqRINxEFlkg== Origin: http://localhost:8080 Sec-WebSocket-Version: 13 可以看到，客户端发起的WebSocket连接报文类似传统HTTP报文，Upgrade：websocket参数值表明这是WebSocket类型请求，Sec-WebSocket-Key是WebSocket客户端发送的一个 base64编码的密文，要求服务端必须返回一个对应加密的Sec-WebSocket-Accept应答，否则客户端会抛出Error during WebSocket handshake错误，并关闭连接。 服务端收到报文后返回的数据格式类似： HTTP/1.1 101 Switching ProtocolsUpgrade: websocketConnection: UpgradeSec-WebSocket-Accept: K7DJLdLooIwIG/MOpvWFB3y3FE8= Sec-WebSocket-Accept的值是服务端采用与客户端一致的密钥计算出来后返回客户端的，HTTP/1.1 101 Switching Protocols表示服务端接受WebSocket协议的客户端连接，经过这样的请求-响应处理后，两端的WebSocket连接握手成功, 后续就可以进行TCP通讯了。用户可以查阅WebSocket协议栈了解WebSocket客户端和服务端更详细的交互数据格式。在开发方面，WebSocket API 也十分简单：只需要实例化 WebSocket，创建连接，然后服务端和客户端就可以相互发送和响应消息。在WebSocket 实现及案例分析部分可以看到详细的 WebSocket API 及代码实现。 Websocket其实是一个新协议，跟HTTP协议基本没有关系，只是为了兼容现有浏览器的握手规范而已，也就是说它是HTTP协议上的一种补充可以通过这样一张图理解有交集，但是并不是全部。另外Html5是指的一系列新的API，或者说新规范，新技术。Http协议本身只有1.0和1.1，而且跟Html本身没有直接关系。 WebSocket特点总结 单一的TCP连接，采用全双工模式通信 对代理，防火墙和路由器透明 无头部信息，Cookie和身份验证 无安全开销 通过“ping/pong”帧保持链路激活 度武器可以主动传递消息给客户端用Netty实现WebSocketWebSocketServer import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.Channel; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.http.HttpObjectAggregator; import io.netty.handler.codec.http.HttpServerCodec; import io.netty.handler.stream.ChunkedWriteHandler; public class WebSocketServer { public void run(int port) throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(&quot;http-codec&quot;, new HttpServerCodec()); pipeline.addLast(&quot;aggregator&quot;, new HttpObjectAggregator(65536)); ch.pipeline().addLast(&quot;http-chunked&quot;, new ChunkedWriteHandler()); pipeline.addLast(&quot;handler&quot;, new WebSocketServerHandler()); } }); Channel ch = b.bind(port).sync().channel(); System.out.println(&quot;Web socket server started at port &quot; + port + &apos;.&apos;); System.out .println(&quot;Open your browser and navigate to http://localhost:&quot; + port + &apos;/&apos;); ch.closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) throws Exception { int port = 8080; if (args.length &gt; 0) { try { port = Integer.parseInt(args[0]); } catch (NumberFormatException e) { e.printStackTrace(); } } new WebSocketServer().run(port); } } WebSocketServerHandler import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelFutureListener; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import io.netty.handler.codec.http.DefaultFullHttpResponse; import io.netty.handler.codec.http.FullHttpRequest; import io.netty.handler.codec.http.FullHttpResponse; import io.netty.handler.codec.http.websocketx.*; import io.netty.util.CharsetUtil; import java.util.logging.Level; import java.util.logging.Logger; import static io.netty.handler.codec.http.HttpHeaderUtil.setContentLength; import static io.netty.handler.codec.http.HttpHeaderUtil.isKeepAlive; import static io.netty.handler.codec.http.HttpResponseStatus.BAD_REQUEST; import static io.netty.handler.codec.http.HttpVersion.HTTP_1_1; public class WebSocketServerHandler extends SimpleChannelInboundHandler&lt;Object&gt; { private static final Logger logger = Logger .getLogger(WebSocketServerHandler.class.getName()); private WebSocketServerHandshaker handshaker; @Override public void messageReceived(ChannelHandlerContext ctx, Object msg) throws Exception { // 传统的HTTP接入 if (msg instanceof FullHttpRequest) { handleHttpRequest(ctx, (FullHttpRequest) msg); } // WebSocket接入 else if (msg instanceof WebSocketFrame) { handleWebSocketFrame(ctx, (WebSocketFrame) msg); } } @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { ctx.flush(); } private void handleHttpRequest(ChannelHandlerContext ctx, FullHttpRequest req) throws Exception { // 如果HTTP解码失败，返回HHTP异常 if (!req.decoderResult().isSuccess() || (!&quot;websocket&quot;.equals(req.headers().get(&quot;Upgrade&quot;)))) { sendHttpResponse(ctx, req, new DefaultFullHttpResponse(HTTP_1_1, BAD_REQUEST)); return; } // 构造握手响应返回，本机测试 WebSocketServerHandshakerFactory wsFactory = new WebSocketServerHandshakerFactory( &quot;ws://localhost:8080/websocket&quot;, null, false); handshaker = wsFactory.newHandshaker(req); if (handshaker == null) { WebSocketServerHandshakerFactory.sendUnsupportedVersionResponse(ctx.channel()); } else { handshaker.handshake(ctx.channel(), req); } } private void handleWebSocketFrame(ChannelHandlerContext ctx, WebSocketFrame frame) { // 判断是否是关闭链路的指令 if (frame instanceof CloseWebSocketFrame) { handshaker.close(ctx.channel(), (CloseWebSocketFrame) frame.retain()); return; } // 判断是否是Ping消息 if (frame instanceof PingWebSocketFrame) { ctx.channel().write( new PongWebSocketFrame(frame.content().retain())); return; } // 本例程仅支持文本消息，不支持二进制消息 if (!(frame instanceof TextWebSocketFrame)) { throw new UnsupportedOperationException(String.format( &quot;%s frame types not supported&quot;, frame.getClass().getName())); } // 返回应答消息 String request = ((TextWebSocketFrame) frame).text(); if (logger.isLoggable(Level.FINE)) { logger.fine(String.format(&quot;%s received %s&quot;, ctx.channel(), request)); } ctx.channel().write( new TextWebSocketFrame(request + &quot; , 欢迎使用Netty WebSocket服务，现在时刻：&quot; + new java.util.Date().toString())); } private static void sendHttpResponse(ChannelHandlerContext ctx, FullHttpRequest req, FullHttpResponse res) { // 返回应答给客户端 if (res.status().code() != 200) { ByteBuf buf = Unpooled.copiedBuffer(res.status().toString(), CharsetUtil.UTF_8); res.content().writeBytes(buf); buf.release(); setContentLength(res, res.content().readableBytes()); } // 如果是非Keep-Alive，关闭连接 ChannelFuture f = ctx.channel().writeAndFlush(res); if (!isKeepAlive(req) || res.status().code() != 200) { f.addListener(ChannelFutureListener.CLOSE); } } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); } } 然后启动WebSocketServer，控制台会出现下面地址：但是这个地址是无效的 最后给个html显示 &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; Netty WebSocket 时间服务器 &lt;/head&gt; &lt;br&gt; &lt;body&gt; &lt;br&gt; &lt;script type=&quot;text/javascript&quot;&gt; var socket; if (!window.WebSocket) { window.WebSocket = window.MozWebSocket; } if (window.WebSocket) { socket = new WebSocket(&quot;ws://localhost:8080/websocket&quot;); socket.onmessage = function(event) { var ta = document.getElementById(&apos;responseText&apos;); ta.value=&quot;&quot;; ta.value = event.data }; socket.onopen = function(event) { var ta = document.getElementById(&apos;responseText&apos;); ta.value = &quot;打开WebSocket服务正常，浏览器支持WebSocket!&quot;; }; socket.onclose = function(event) { var ta = document.getElementById(&apos;responseText&apos;); ta.value = &quot;&quot;; ta.value = &quot;WebSocket 关闭!&quot;; }; } else { alert(&quot;抱歉，您的浏览器不支持WebSocket协议!&quot;); } function send(message) { if (!window.WebSocket) { return; } if (socket.readyState == WebSocket.OPEN) { socket.send(message); } else { alert(&quot;WebSocket连接没有建立成功!&quot;); } } &lt;/script&gt; &lt;form onsubmit=&quot;return false;&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;message&quot; value=&quot;Netty最佳实践&quot;/&gt; &lt;br&gt;&lt;br&gt; &lt;input type=&quot;button&quot; value=&quot;发送WebSocket请求消息&quot; onclick=&quot;send(this.form.message.value)&quot;/&gt; &lt;hr color=&quot;blue&quot;/&gt; &lt;h3&gt;服务端返回的应答消息&lt;/h3&gt; &lt;textarea id=&quot;responseText&quot; style=&quot;width:500px;height:300px;&quot;&gt;&lt;/textarea&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; 运行这个html，会显示 这个时间是后台返回回来的。到此这个WebSocket也搭建完成。]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty之Http协议]]></title>
    <url>%2F2017%2F10%2F18%2Fnetty%E4%B9%8BHttp%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[什么是HTTPHTTP是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。 HTTP协议的主要特点 支持客户/服务器模式。 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。 灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。HTTP的url组成HTTP使用统一资源标识符（Uniform Resource Identifiers, URI）来传输数据和建立连接。URL是一种特殊类型的URI，包含了用于查找某个资源的足够的信息 URL全称是UniformResourceLocator, 中文叫统一资源定位符,是互联网上用来标识某一处资源的地址。以下面这个URL为例，介绍下普通URL的各部分组成：http://www.aspxfans.com:8080/news/index.asp?boardID=5&amp;ID=24618&amp;page=1#name 从上面的URL可以看出，一个完整的URL包括以下几部分：1.协议部分：该URL的协议部分为“http：”，这代表网页使用的是HTTP协议。在Internet中可以使用多种协议，如HTTP，FTP等等本例中使用的是HTTP协议。在”HTTP”后面的“//”为分隔符2.域名部分：该URL的域名部分为“www.aspxfans.com”。一个URL中，也可以使用IP地址作为域名使用3.端口部分：跟在域名后面的是端口，域名和端口之间使用“:”作为分隔符。端口不是一个URL必须的部分，如果省略端口部分，将采用默认端口4.虚拟目录部分：从域名后的第一个“/”开始到最后一个“/”为止，是虚拟目录部分。虚拟目录也不是一个URL必须的部分。本例中的虚拟目录是“/news/”5.文件名部分：从域名后的最后一个“/”开始到“？”为止，是文件名部分，如果没有“?”,则是从域名后的最后一个“/”开始到“#”为止，是文件部分，如果没有“？”和“#”，那么从域名后的最后一个“/”开始到结束，都是文件名部分。本例中的文件名是“index.asp”。文件名部分也不是一个URL必须的部分，如果省略该部分，则使用默认的文件名6.锚部分：从“#”开始到最后，都是锚部分。本例中的锚部分是“name”。锚部分也不是一个URL必须的部分7.参数部分：从“？”开始到“#”为止之间的部分为参数部分，又称搜索部分、查询部分。本例中的参数部分为“boardID=5&amp;ID=24618&amp;page=1”。参数可以允许有多个参数，参数与参数之间用“&amp;”作为分隔符。 HTTP之请求消息Requesthttp请求由三部分组成，分别是：请求行、消息报头、请求正文 请求行请求行以一个方法符号开头，以空格分开，后面跟着请求的URI和协议的版本。GET： 请求获取Request-URI所标识的资源POST： 在Request-URI所标识的资源后附加新的数据HEAD： 请求获取由Request-URI所标识的资源的响应消息报头PUT： 请求服务器存储一个资源，并用Request-URI作为其标识DELETE： 请求服务器删除Request-URI所标识的资源TRACE： 请求服务器回送收到的请求信息，主要用于测试或诊断CONNECT： 保留将来使用OPTIONS： 请求查询服务器的性能，或者查询与资源相关的选项和需求 通过一个简单的Socket来看看这个 import java.io.IOException; import java.io.InputStream; import java.io.InputStreamReader; import java.net.ServerSocket; import java.net.Socket; public class Test { public static void main(String[] args) throws IOException { // 服务器监听端口号9999 ServerSocket serverSocket = new ServerSocket(9999); // 等待接收请求，这是一个阻塞的方法，当请求到来的时候才会继续向下执行 Socket socket = serverSocket.accept(); // 获取请求内容 InputStream is = socket.getInputStream(); InputStreamReader reader = new InputStreamReader(is); // 输出请求内容 while (true) { System.out.print((char)reader.read()); } } } 然后运行main方法。在浏览器中输入http://localhost:9999/test?lijia=1231控制台会输出下面的结果： 请求行（第2行）：（请求方法GET，请求资源/test?lijia=1231，HTTP版本1.1）请求头部（第3-10行）：紧接着请求行（即第2行）之后的部分，用来说明服务器要使用的附加信息空行（第11行）：请求头部后面的空行是必须的请求数据（空行之后的）：为空，也必须有空行。这个例子的请求数据为空。 下图用POST传递：和GET差不多，不过请求数据放到最下面了 HTTP之响应消息ResponseHTTP响应也是由四个部分组成，分别是：状态行、消息报头、空行和响应正文 状态行：，由HTTP协议版本号， 状态码， 状态消息 三部分组成。第一行为状态行，（HTTP/1.1）表明HTTP版本为1.1版本，状态码为200，状态消息为（ok）消息报头：用来说明客户端要使用的一些附加信息第二行和第三行为消息报头，Date:生成响应的日期和时间；Content-Type:指定了MIME类型的HTML(text/html),编码类型是UTF-8空行：消息报头后面的空行是必须的响应正文：服务器返回给客户端的文本信息。空行后面的html部分为响应正文。 其中状态代码有三位数字组成，第一个数字定义了响应的类别，且有五种可能取值：1xx：指示信息–表示请求已接收，继续处理2xx：成功–表示请求已被成功接收、理解、接受3xx：重定向–要完成请求必须进行更进一步的操作4xx：客户端错误–请求有语法错误或请求无法实现5xx：服务器端错误–服务器未能实现合法的请求常见状态码： 200 OK //客户端请求成功 400 Bad Request //客户端请求有语法错误，不能被服务器所理解 401 Unauthorized //请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 403 Forbidden //服务器收到请求，但是拒绝提供服务 404 Not Found //请求资源不存在，eg：输入了错误的URL 500 Internal Server Error //服务器发生不可预期的错误 503 Server Unavailable //服务器当前不能处理客户端的请求，一段时间后可能恢复正常 更多状态码请看看 http://www.runoob.com/http/http-status-codes.html HTTP工作原理一次HTTP操作称为一个事务，其工作整个过程如下： 1）、地址解析 如用客户端浏览器请求这个页面：http://localhost.com:8080/index.htm 从中分解出协议名、主机名、端口、对象路径等部分，对于我们的这个地址，解析得到的结果如下： 协议名：http 主机名：localhost.com 端口：8080 对象路径：/index.html 在这一步，需要域名系统DNS解析域名localhost.com,得主机的IP地址。 2）、封装HTTP请求数据包 把以上部分结合本机自己的信息，封装成一个HTTP请求数据包 3）封装成TCP包，建立TCP连接（TCP的三次握手） 在HTTP工作开始之前，客户机（Web浏览器）首先要通过网络与服务器建立连接，该连接是通过TCP来完成的，该协议与IP协议共同构建Internet，即著名的TCP/IP协议族，因此Internet又被称作是TCP/IP网络。HTTP是比TCP更高层次的应用层协议，根据规则，只有低层协议建立之后才能，才能进行更层协议的连接，因此，首先要建立TCP连接，一般TCP连接的端口号是80。这里是8080端口 4）客户机发送请求命令 建立连接后，客户机发送一个请求给服务器，请求方式的格式为：统一资源标识符（URL）、协议版本号，后边是MIME信息包括请求修饰符、客户机信息和可内容。 5）服务器响应 服务器接到请求后，给予相应的响应信息，其格式为一个状态行，包括信息的协议版本号、一个成功或错误的代码，后边是MIME信息包括服务器信息、实体信息和可能的内容。 实体消息是服务器向浏览器发送头信息后，它会发送一个空白行来表示头信息的发送到此为结束，接着，它就以Content-Type应答头信息所描述的格式发送用户所请求的实际数据 6）服务器关闭TCP连接 一般情况下，一旦Web服务器向浏览器发送了请求数据，它就要关闭TCP连接，然后如果浏览器或者服务器在其头信息加入了这行代码 Connection:keep-alive TCP连接在发送后将仍然保持打开状态，于是，浏览器可以继续通过相同的连接发送请求。保持连接节省了为每个请求建立新连接所需的时间，还节约了网络带宽。 7） 服务器将响应信息传给客户端响应体中的内容可能是一个html页面，也可能是一张图片，通过输入流将其读出，并写回到显示器上。 用netty实现http的文件服务HttpServer启动类import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.http.HttpObjectAggregator; import io.netty.handler.codec.http.HttpRequestDecoder; import io.netty.handler.codec.http.HttpResponseEncoder; import io.netty.handler.stream.ChunkedWriteHandler; public class HttpServer { private static final String DEFAULT_URL = &quot;/src/&quot;; public static void main(String[] args) { int port = 8888; String url = DEFAULT_URL; if(args.length &gt; 1){ url = args[1]; } new HttpServer().connect(port, url); } private void connect(int port, final String url) { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try{ ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup).channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(&quot;http-decoder&quot;, new HttpRequestDecoder()); ch.pipeline().addLast(&quot;http-aggregator&quot;, new HttpObjectAggregator(65536)); ch.pipeline().addLast(&quot;http-encoder&quot;, new HttpResponseEncoder()); ch.pipeline().addLast(&quot;http-chunked&quot;, new ChunkedWriteHandler()); ch.pipeline().addLast(&quot;fileServerHandler&quot;, new HttpFileServerHandler(url)); } }); ChannelFuture f = b.bind(&quot;localhost&quot;,port).sync(); System.out.println(&quot;HTTP 文件服务器启动, 地址是： &quot; + &quot;http://localhost:&quot; + port + url); f.channel().closeFuture().sync(); } catch (InterruptedException e) { e.printStackTrace(); } finally{ bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } HttpFileServerHandler（业务处理）import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.*; import io.netty.handler.codec.http.*; import io.netty.handler.stream.ChunkedFile; import io.netty.util.CharsetUtil; import javax.activation.MimetypesFileTypeMap; import java.io.File; import java.io.FileNotFoundException; import java.io.RandomAccessFile; import java.io.UnsupportedEncodingException; import java.net.URLDecoder; import java.util.regex.Pattern; public class HttpFileServerHandler extends SimpleChannelInboundHandler&lt;FullHttpRequest&gt;{ private final String url; public HttpFileServerHandler(String url) { this.url = url; } @Override protected void messageReceived(ChannelHandlerContext ctx, FullHttpRequest request) throws Exception { //对解码结果进行判断 if(!request.decoderResult().isSuccess()) { sendError(ctx, HttpResponseStatus.BAD_REQUEST); return; } //判断是不是GET方法 if(request.method() != HttpMethod.GET) { sendError(ctx, HttpResponseStatus.METHOD_NOT_ALLOWED); return; } final String uri = request.uri(); //将uri解码 final String path = sanitizeUri(uri); if(path == null) { sendError(ctx, HttpResponseStatus.FORBIDDEN); return; } File file = new File(path); //文件隐藏或者不存在 if(file.isHidden() || !file.exists()) { sendError(ctx, HttpResponseStatus.NOT_FOUND); return; } //是不是一个目录 if(file.isDirectory()) { if(uri.endsWith(&quot;/&quot;)) { sendListing(ctx, file); }else{ sendRedirect(ctx, uri + &quot;/&quot;); } return; } //不是文件 if(!file.isFile()) { sendError(ctx, HttpResponseStatus.FORBIDDEN); return; } RandomAccessFile randomAccessFile = null; try{ randomAccessFile = new RandomAccessFile(file, &quot;r&quot;); }catch(FileNotFoundException fnfd){ sendError(ctx, HttpResponseStatus.NOT_FOUND); return; } //获取文件长度 long fileLength = randomAccessFile.length(); HttpResponse response = new DefaultHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK); HttpHeaderUtil.setContentLength(response, fileLength); setContentTypeHeader(response, file); if(HttpHeaderUtil.isKeepAlive(request)){ response.headers().set(HttpHeaderNames.CONNECTION, HttpHeaderValues.KEEP_ALIVE); } ctx.write(response); ChannelFuture sendFileFuture = null; sendFileFuture = ctx.write(new ChunkedFile(randomAccessFile, 0, fileLength, 8192), ctx.newProgressivePromise()); sendFileFuture.addListener(new ChannelProgressiveFutureListener() { @Override public void operationComplete(ChannelProgressiveFuture future) throws Exception { System.out.println(&quot;Transfer complete.&quot;); } @Override public void operationProgressed(ChannelProgressiveFuture future, long progress, long total) throws Exception { if(total &lt; 0){ System.err.println(&quot;Transfer progress: &quot; + progress); } else{ System.err.println(&quot;Transfer progress: &quot; + progress + &quot;/&quot; + total); } } }); ChannelFuture lastContentFuture = ctx.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT); if(!HttpHeaderUtil.isKeepAlive(request)){ lastContentFuture.addListener(ChannelFutureListener.CLOSE); } } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); if(ctx.channel().isActive()){ sendError(ctx, HttpResponseStatus.INTERNAL_SERVER_ERROR); } } private static final Pattern INSECURE_URI = Pattern.compile(&quot;.*[&lt;&gt;&amp;\&quot;].*&quot;); private String sanitizeUri(String uri){ try{ uri = URLDecoder.decode(uri, &quot;UTF-8&quot;); }catch(UnsupportedEncodingException e){ try{ uri = URLDecoder.decode(uri, &quot;ISO-8859-1&quot;); }catch(UnsupportedEncodingException e1){ throw new Error(); } } if(!uri.startsWith(url)){ return null; } if(!uri.startsWith(&quot;/&quot;)){ return null; } uri = uri.replace(&apos;/&apos;, File.separatorChar); if(uri.contains(File.separator + &apos;.&apos;) || uri.contains(&apos;.&apos; + File.separator) || uri.startsWith(&quot;.&quot;) || uri.endsWith(&quot;.&quot;) || INSECURE_URI.matcher(uri).matches()){ return null; } return System.getProperty(&quot;user.dir&quot;) + File.separator + uri; } private static final Pattern ALLOWED_FILE_NAME = Pattern.compile(&quot;[A-Za-z0-9][-_A-Za-z0-9\\.]*&quot;); //返回并显示 private static void sendListing(ChannelHandlerContext ctx, File dir){ FullHttpResponse response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK); response.headers().set(HttpHeaderNames.CONTENT_TYPE, &quot;text/html;charset=UTF-8&quot;); String dirPath = dir.getPath(); StringBuilder buf = new StringBuilder(); buf.append(&quot;&lt;!DOCTYPE html&gt;\r\n&quot;); buf.append(&quot;&lt;html&gt;&lt;head&gt;&lt;title&gt;&quot;); buf.append(dirPath); buf.append(&quot;目录:&quot;); buf.append(&quot;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;\r\n&quot;); buf.append(&quot;&lt;h3&gt;&quot;); buf.append(dirPath).append(&quot; 目录：&quot;); buf.append(&quot;&lt;/h3&gt;\r\n&quot;); buf.append(&quot;&lt;ul&gt;&quot;); buf.append(&quot;&lt;li&gt;链接：&lt;a href=\&quot; ../\&quot;)..&lt;/a&gt;&lt;/li&gt;\r\n&quot;); for (File f : dir.listFiles()) { if(f.isHidden() || !f.canRead()) { continue; } String name = f.getName(); if (!ALLOWED_FILE_NAME.matcher(name).matches()) { continue; } buf.append(&quot;&lt;li&gt;链接：&lt;a href=\&quot;&quot;); buf.append(name); buf.append(&quot;\&quot;&gt;&quot;); buf.append(name); buf.append(&quot;&lt;/a&gt;&lt;/li&gt;\r\n&quot;); } buf.append(&quot;&lt;/ul&gt;&lt;/body&gt;&lt;/html&gt;\r\n&quot;); ByteBuf buffer = Unpooled.copiedBuffer(buf,CharsetUtil.UTF_8); response.content().writeBytes(buffer); buffer.release(); ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE); } private static void sendRedirect(ChannelHandlerContext ctx, String newUri){ FullHttpResponse response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.FOUND); response.headers().set(HttpHeaderNames.LOCATION, newUri); ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE); } private static void sendError(ChannelHandlerContext ctx, HttpResponseStatus status){ FullHttpResponse response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, status, Unpooled.copiedBuffer(&quot;Failure: &quot; + status.toString() + &quot;\r\n&quot;, CharsetUtil.UTF_8)); response.headers().set(HttpHeaderNames.CONTENT_TYPE, &quot;text/html;charset=UTF-8&quot;); ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE); } private static void setContentTypeHeader(HttpResponse response, File file){ MimetypesFileTypeMap mimetypesFileTypeMap = new MimetypesFileTypeMap(); response.headers().set(HttpHeaderNames.CONTENT_TYPE, mimetypesFileTypeMap.getContentType(file.getPath())); } } 然后启动HttpServer，控制台会出现 然后输入 http://localhost:8888/src/ ，会显示 看看上面的代码在HttpServer中加入了 ch.pipeline().addLast(&quot;http-decoder&quot;, new HttpRequestDecoder()); ch.pipeline().addLast(&quot;http-aggregator&quot;, new HttpObjectAggregator(65536)); ch.pipeline().addLast(&quot;http-encoder&quot;, new HttpResponseEncoder()); ch.pipeline().addLast(&quot;http-chunked&quot;, new ChunkedWriteHandler()); ch.pipeline().addLast(&quot;fileServerHandler&quot;, new HttpFileServerHandler(url)); 加入了请求消息解码器。HttpObjectAggregator这个作用是将多个消息转化成单一的FullHttpRequest或者FullHttpResponse。业务处理放在HttpFileServerHandler中]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty编解码技术]]></title>
    <url>%2F2017%2F10%2F17%2Fnetty%E7%BC%96%E8%A7%A3%E7%A0%81%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[java序列化序列化是干什么的为了保存在内存中的各种对象的状态（也就是实例变量，不是方法），并且可以把保存的对象状态再读出来。虽然你可以用你自己的各种各样的方法来保存object states，但是Java给你提供一种应该比你自己好的保存对象状态的机制，那就是序列化。 java序列化之后码流太大首先通过一个列子来看看 import java.io.ByteArrayOutputStream; import java.io.IOException; import java.io.ObjectOutputStream; import java.io.Serializable; import java.nio.ByteBuffer; public class UserInfo implements Serializable { /** * 默认的序列号 */ private static final long serialVersionUID = 1L; private String userName; private int id; public UserInfo buildUserName(String userName) { this.userName = userName; return this; } public UserInfo buildUserID(int id) { this.id = id; return this; } public final String getUserName() { return userName; } public final void setUserName(String userName) { this.userName = userName; } public final int getUserID() { return id; } public final void setUserID(int userID) { this.id = userID; } public byte[] codeC() { ByteBuffer buffer = ByteBuffer.allocate(1024); byte[] value = this.userName.getBytes(); buffer.putInt(value.length); buffer.put(value); buffer.putInt(this.id); buffer.flip(); value = null; byte[] result = new byte[buffer.remaining()]; buffer.get(result); return result; } public byte[] codeC(ByteBuffer buffer) { buffer.clear(); byte[] value = this.userName.getBytes(); buffer.putInt(value.length); buffer.put(value); buffer.putInt(this.id); buffer.flip(); value = null; byte[] result = new byte[buffer.remaining()]; buffer.get(result); return result; } public static void main(String[] args) throws IOException { System.out.println(&quot;------------大小----------&quot;); UserInfo info = new UserInfo(); info.buildUserID(100).buildUserName(&quot;Welcome to Netty&quot;); ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream os = new ObjectOutputStream(bos); os.writeObject(info); os.flush(); os.close(); byte[] b = bos.toByteArray(); System.out.println(&quot;The jdk serializable length is : &quot; + b.length); bos.close(); System.out.println(&quot;-------------------------------------&quot;); System.out.println(&quot;The byte array serializable length is : &quot; + info.codeC().length); System.out.println(&quot;------------时间----------&quot;); UserInfo info1 = new UserInfo(); info1.buildUserID(100).buildUserName(&quot;Welcome to Netty&quot;); int loop = 1000000; ByteArrayOutputStream bos1 = null; ObjectOutputStream os1 = null; long startTime = System.currentTimeMillis(); for (int i = 0; i &lt; loop; i++) { bos1 = new ByteArrayOutputStream(); os1 = new ObjectOutputStream(bos1); os1.writeObject(info1); os1.flush(); os1.close(); byte[] b1 = bos.toByteArray(); bos.close(); } long endTime = System.currentTimeMillis(); System.out.println(&quot;The jdk serializable cost time is : &quot; + (endTime - startTime) + &quot; ms&quot;); System.out.println(&quot;-------------------------------------&quot;); ByteBuffer buffer1 = ByteBuffer.allocate(1024); startTime = System.currentTimeMillis(); for (int i = 0; i &lt; loop; i++) { byte[] b1 = info.codeC(buffer1); } endTime = System.currentTimeMillis(); System.out.println(&quot;The byte array serializable cost time is : &quot; + (endTime - startTime) + &quot; ms&quot;); } } 运行结果是： 上面是两个测试结果前面都是默认序列化之后的数据大小和序列化的时间，下面都是使用NIO的编解码去对对象进行编码。可以看出默认的Serializable 接口还有一些瑕疵。 编码框架MessagePack编解码MessagePack的特点： 编解码高效，性能高 序列化之后的码流小 支持跨语言简单使用：POJO:需要加上@Message import org.msgpack.annotation.Message; @Message public class Student { private int id; private String name; public int getId() { return id; } public void setId(int id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } @Override public String toString() { return &quot;Student [id=&quot; + id + &quot;, name=&quot; + name + &quot;]&quot;; } } 测试类： Student student = new Student(); student.setId(1); student.setName(&quot;lijia&quot;); MessagePack messagePack = new MessagePack(); try { byte[] write = messagePack.write(student); Value read = messagePack.read(write); System.out.println(read); } catch (IOException e) { e.printStackTrace(); } 运行结果： Protobuf编解码这个我弄了一天，找到一个windows版本的，但是在电脑上运行不了。大致了解一下吧1 .proto文件相当于确定数据协议，数据结构中存在哪些数据，数据类型是怎么样2 modifiers 2-1 required 不可以增加或删除的字段，必须初始化 2-2 optional 可选字段，可删除，可以不初始化 2-3 repeated 可重复字段， 对应到java文件里，生成的是List 3 Message在proto文件里，数据的协议时以Message的形式表现的。4 Build生成具体的java类时，例如Person.java，同时会存在build方法。文档的意思是对于转化后的数据，具有唯一性，build提供了便利的方法来初始化这些数据。这个先放着，以后回头好好研究这个协议。 Marshalling编解码由于Marshalling完全兼容java序列化。调用jboss的API对对象进行编解码。首先要引入jboss-marshalling的jar包。下面的代码是marshalling编解码 public final class MarshallingCodeCFactory { /** * 创建Jboss Marshalling解码器MarshallingDecoder * * @return */ public static MarshallingDecoder buildMarshallingDecoder() { final MarshallerFactory marshallerFactory = Marshalling .getProvidedMarshallerFactory(&quot;serial&quot;); final MarshallingConfiguration configuration = new MarshallingConfiguration(); configuration.setVersion(5); UnmarshallerProvider provider = new DefaultUnmarshallerProvider( marshallerFactory, configuration); MarshallingDecoder decoder = new MarshallingDecoder(provider, 1024); return decoder; } /** * 创建Jboss Marshalling编码器MarshallingEncoder * * @return */ public static MarshallingEncoder buildMarshallingEncoder() { final MarshallerFactory marshallerFactory = Marshalling .getProvidedMarshallerFactory(&quot;serial&quot;); final MarshallingConfiguration configuration = new MarshallingConfiguration(); configuration.setVersion(5); MarshallerProvider provider = new DefaultMarshallerProvider( marshallerFactory, configuration); MarshallingEncoder encoder = new MarshallingEncoder(provider); return encoder; } } 用法：还是以client为例 public class SubReqClient { public void connect(int port, String host) throws Exception { // 配置客户端NIO线程组 EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder()); ch.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder()); ch.pipeline().addLast(new SubReqClientHandler()); } }); // 发起异步连接操作 ChannelFuture f = b.connect(host, port).sync(); // 当代客户端链路关闭 f.channel().closeFuture().sync(); } finally { // 优雅退出，释放NIO线程组 group.shutdownGracefully(); } } /** * @param args * @throws Exception */ public static void main(String[] args) throws Exception { int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { // 采用默认值 } } new SubReqClient().connect(port, &quot;127.0.0.1&quot;); } } 还是在initChannel这个方法中添加 ch.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingDecoder()); ch.pipeline().addLast(MarshallingCodeCFactory.buildMarshallingEncoder()); 服务端和这个一样。注意的是Marshalling支持拆包的处理。 总结性能对比 框架 字节大小（byte） 序列化时间 反序列化时间 messagepack 12793 2313335 529458 protebuf 6590 941790 408571 json 17181 1338371 1776519 讲了3中序列化框架和jdk自带的区别：MessagePack：在反序列化耗内存大小方面，msgpack远远超出json（1.6倍），由于内存是移动客户端场景下的重要指标，因此基本可以排除msgpack。protebuf：缺点是不支持半包处理，其余的都比megpack好marshalling：这个自带半包处理]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty粘包拆包]]></title>
    <url>%2F2017%2F10%2F13%2Fnetty%E7%B2%98%E5%8C%85%E6%8B%86%E5%8C%85%2F</url>
    <content type="text"><![CDATA[什么是TCP粘包/拆包首先了解什么是长连接和短连接长连接： Client方与Server方先建立通讯连接，连接建立后不断开， 然后再进行报文发送和接收。短连接：Client方与Server每进行一次报文收发交易时才进行通讯连接，交易完毕后立即断开连接。 什么时候会出现粘包问题 如果用tcp每次发送数据，就与对方建立连接，然后双方发送完一段数据后，就关闭连接，这样就不会出现粘包问题（因为只有一种包结构,类似于http协议）。关闭连接主要要双方都发送close连接（参考tcp关闭协议）。如：A需要发送一段字符串给B，那么A与B建立连接，然后发送双方都默认好的协议字符如”hello，world”，然后B收到报文后，就将缓冲区数据接收,然后关闭连接，这样粘包问题不用考虑到，因为大家都知道是发送一段字符。 如果发送数据无结构，如文件传输，这样发送方只管发送，接收方只管接收存储就ok，也不用考虑粘包 在流传输中出现，UDP不会出现粘包，因为它有消息边界 如果双方建立连接，需要在连接后一段时间内发送不同结构数据，如连接后，有好几种结构： (1)：”Hello，world” (2)：”Hello，lijia”如果发送方连续将这两个包都发出去了，接收方接受的信息可能是”Hello，worldHello，lijia“。这就需要拆包，所以双方应该规定一个较好的包结构，所以一般可能会在头加一个数据长度之类的包，以确保接收。所以：粘包出现原因1 发送端需要等缓冲区满才发送出去，造成粘包2 接收方不及时接收缓冲区的包，造成多个包接收下面的图显示几种可能性 客服端发送两个包给服务端，服务端读取字节数不确定，可能是上面三种情况： a、分别获取两个独立的包，不存在粘包，拆包的情况 b、一次获取两个完整的数据包，这就是粘包 c、第一次获取D1和部分D2数据，第二次获取D2剩余内容，这就是拆包 还有一种可能，就是多次拆包，即服务端接收划窗小，而D1，D2又比较大 粘包的解决策略1、发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。2、发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。3、可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。4、其他首先模拟去看着这个问题TimeServer import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; public class TimeServer { public void bind(int port) throws Exception { // 配置服务端的NIO线程组 EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 1024) .childHandler(new ChildChannelHandler()); // 绑定端口，同步等待成功 ChannelFuture f = b.bind(port).sync(); // 等待服务端监听端口关闭 f.channel().closeFuture().sync(); } finally { // 优雅退出，释放线程池资源 bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } private class ChildChannelHandler extends ChannelInitializer&lt;SocketChannel&gt; { @Override protected void initChannel(SocketChannel arg0) throws Exception { arg0.pipeline().addLast(new TimeServerHandler()); } } /** * @param args * @throws Exception */ public static void main(String[] args) throws Exception { int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { // 采用默认值 } } new TimeServer().bind(port); } }TimeServerHandler import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; public class TimeServerHandler extends ChannelHandlerAdapter { private int counter; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; byte[] req = new byte[buf.readableBytes()]; buf.readBytes(req); String body = new String(req, &quot;UTF-8&quot;).substring(0, req.length - System.getProperty(&quot;line.separator&quot;).length()); System.out.println(&quot;The time server receive order : &quot; + body + &quot; ; the counter is : &quot; + ++counter); String currentTime = &quot;QUERY TIME ORDER&quot;.equalsIgnoreCase(body) ? new java.util.Date( System.currentTimeMillis()).toString() : &quot;BAD ORDER&quot;; currentTime = currentTime + System.getProperty(&quot;line.separator&quot;); ByteBuf resp = Unpooled.copiedBuffer(currentTime.getBytes()); ctx.writeAndFlush(resp); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) { ctx.close(); } }TimeClient import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; public class TimeClient { public void connect(int port, String host) throws Exception { // 配置客户端NIO线程组 EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new TimeClientHandler()); } }); // 发起异步连接操作 ChannelFuture f = b.connect(host, port).sync(); // 当代客户端链路关闭 f.channel().closeFuture().sync(); } finally { // 优雅退出，释放NIO线程组 group.shutdownGracefully(); } } /** * @param args * @throws Exception */ public static void main(String[] args) throws Exception { int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { // 采用默认值 } } new TimeClient().connect(port, &quot;127.0.0.1&quot;); } }TimeClientHandler import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; import java.util.logging.Logger; public class TimeClientHandler extends ChannelHandlerAdapter { private static final Logger logger = Logger .getLogger(TimeClientHandler.class.getName()); private int counter; private byte[] req; /** * Creates a client-side handler. */ public TimeClientHandler() { req = (&quot;QUERY TIME ORDER&quot; + System.getProperty(&quot;line.separator&quot;)) .getBytes(); } @Override public void channelActive(ChannelHandlerContext ctx) { ByteBuf message = null; for (int i = 0; i &lt; 100; i++) { message = Unpooled.buffer(req.length); message.writeBytes(req); ctx.writeAndFlush(message); } } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; byte[] req = new byte[buf.readableBytes()]; buf.readBytes(req); String body = new String(req, &quot;UTF-8&quot;); System.out.println(&quot;Now is : &quot; + body + &quot; ; the counter is : &quot; + ++counter); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) { // 释放资源 logger.warning(&quot;Unexpected exception from downstream : &quot; + cause.getMessage()); ctx.close(); } }执行结果： 服务端收到2条消息，理论上是100条，发生了粘包。客户端也只收到了2条消息 Netty如何去处理这个问题呢LineBasedFrameDecoder在上面代码的TimeServer和ClientServer的initChannel方法中，分别加上 arg0.pipeline().addLast(new LineBasedFrameDecoder(1024)); arg0.pipeline().addLast(new StringDecoder()); 和 ch.pipeline().addLast(new LineBasedFrameDecoder(1024)); ch.pipeline().addLast(new StringDecoder());如下图： 然后将TimeServerHandler和TimeClientHandler中channelRead方法的获取body字符串改成TimeServerHandler中修改： public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { String body = (String) msg; System.out.println(&quot;The time server receive order : &quot; + body + &quot; ; the counter is : &quot; + ++counter); String currentTime = &quot;QUERY TIME ORDER&quot;.equalsIgnoreCase(body) ? new java.util.Date( System.currentTimeMillis()).toString() : &quot;BAD ORDER&quot;; currentTime = currentTime + System.getProperty(&quot;line.separator&quot;); ByteBuf resp = Unpooled.copiedBuffer(currentTime.getBytes()); ctx.writeAndFlush(resp); } TimeClientHandler中修改： @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { String body = (String) msg; System.out.println(&quot;Now is : &quot; + body + &quot; ; the counter is : &quot; + ++counter); } 那么再执行代码，会出现 这就是正确结果。 LineBasedFrameDecoder的原理LineBasedFrameDecoder的工作原理就是依次遍历ByteBuf中的可读字节，判断是否有”\n“或者”\r\n”，如果有，就以此为结束位置，从可读索引到结束位置区间的字节组成了一个字符串。它是以换行符为结束标志的解码器，支持携带结束符或者不携带两种方式，支持配置单行的最大长度。如果读到最大长度还没有发现换行符，就会抛出异常。同时忽略之前读到的字节。如果不是以换行结束呢，怎么解决？ DelimiterBasedFrameDecoderEchoServer : import io.netty.bootstrap.ServerBootstrap; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.DelimiterBasedFrameDecoder; import io.netty.handler.codec.string.StringDecoder; import io.netty.handler.logging.LogLevel; import io.netty.handler.logging.LoggingHandler; public class EchoServer { public void bind(int port) throws Exception { // 配置服务端的NIO线程组 EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ByteBuf delimiter = Unpooled.copiedBuffer(&quot;$_&quot; .getBytes()); ch.pipeline().addLast( new DelimiterBasedFrameDecoder(1024, delimiter)); ch.pipeline().addLast(new StringDecoder()); ch.pipeline().addLast(new EchoServerHandler()); } }); // 绑定端口，同步等待成功 ChannelFuture f = b.bind(port).sync(); // 等待服务端监听端口关闭 f.channel().closeFuture().sync(); } finally { // 优雅退出，释放线程池资源 bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) throws Exception { int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { // 采用默认值 } } new EchoServer().bind(port); } } EchoServerHandler : import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandler.Sharable; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; @Sharable public class EchoServerHandler extends ChannelHandlerAdapter { int counter = 0; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { String body = (String) msg; System.out.println(&quot;This is &quot; + ++counter + &quot; times receive client : [&quot; + body + &quot;]&quot;); body += &quot;$_&quot;; ByteBuf echo = Unpooled.copiedBuffer(body.getBytes()); ctx.writeAndFlush(echo); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) { cause.printStackTrace(); ctx.close();// 发生异常，关闭链路 } } EchoClient : import io.netty.bootstrap.Bootstrap; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; import io.netty.handler.codec.DelimiterBasedFrameDecoder; import io.netty.handler.codec.string.StringDecoder; public class EchoClient { public void connect(int port, String host) throws Exception { // 配置客户端NIO线程组 EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ByteBuf delimiter = Unpooled.copiedBuffer(&quot;$_&quot; .getBytes()); ch.pipeline().addLast( new DelimiterBasedFrameDecoder(1024, delimiter)); ch.pipeline().addLast(new StringDecoder()); ch.pipeline().addLast(new EchoClientHandler()); } }); // 发起异步连接操作 ChannelFuture f = b.connect(host, port).sync(); // 当代客户端链路关闭 f.channel().closeFuture().sync(); } finally { // 优雅退出，释放NIO线程组 group.shutdownGracefully(); } } /** * @param args * @throws Exception */ public static void main(String[] args) throws Exception { int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { // 采用默认值 } } new EchoClient().connect(port, &quot;127.0.0.1&quot;); } } TimeClientHandler : import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; public class TimeClientHandler extends ChannelHandlerAdapter { private int counter; static final String ECHO_REQ = &quot;Hi, Lilinfeng. Welcome to Netty.$_&quot;; /** * Creates a client-side handler. */ public TimeClientHandler () { } @Override public void channelActive(ChannelHandlerContext ctx) { // ByteBuf buf = UnpooledByteBufAllocator.DEFAULT.buffer(ECHO_REQ // .getBytes().length); // buf.writeBytes(ECHO_REQ.getBytes()); for (int i = 0; i &lt; 10; i++) { ctx.writeAndFlush(Unpooled.copiedBuffer(ECHO_REQ.getBytes())); } } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(&quot;This is &quot; + ++counter + &quot; times receive server : [&quot;+ msg + &quot;]&quot;); } @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) { cause.printStackTrace(); ctx.close(); } } 运行之后出现 如果把EchoServer的ch.pipeline().addLast(new DelimiterBasedFrameDecoder(1024,delimiter));注释掉那么server获取的字符串就是 由于没有分隔符解码器，导致了一次性读取客户端所有数据，就是典型的tcp粘包问题。 FixedLengthFrameDecoderEchoServer ： import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.FixedLengthFrameDecoder; import io.netty.handler.codec.string.StringDecoder; import io.netty.handler.logging.LogLevel; import io.netty.handler.logging.LoggingHandler; public class EchoServer { public void bind(int port) throws Exception { // 配置服务端的NIO线程组 EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast( new FixedLengthFrameDecoder(20)); ch.pipeline().addLast(new StringDecoder()); ch.pipeline().addLast(new EchoServerHandler()); } }); // 绑定端口，同步等待成功 ChannelFuture f = b.bind(port).sync(); // 等待服务端监听端口关闭 f.channel().closeFuture().sync(); } finally { // 优雅退出，释放线程池资源 bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) throws Exception { int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { // 采用默认值 } } new EchoServer().bind(port); } } EchoServerHandler ： import io.netty.channel.ChannelHandler.Sharable; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; @Sharable public class EchoServerHandler extends ChannelHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(&quot;Receive client : [&quot; + msg + &quot;]&quot;); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) { cause.printStackTrace(); ctx.close();// 发生异常，关闭链路 } } 启动EchoServer然后从cmd中启动telnet localhost 8080,我以1234567890一直循环输入，但是由于FixedLengthFrameDecoder设置的大小为20，那么每次不超过20就不会返回，如果超过20，输出20个字符，剩下的以另一个包形式返回。 总结LineBasedFrameDecoder:以换行处理粘包DelimiterBasedFrameDecoder：设置固定的分隔符，然后解码去解决粘包问题FixedLengthFrameDecoder：对固定长度的消息进行自动解码]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty入门]]></title>
    <url>%2F2017%2F10%2F13%2Fnetty%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[什么是nettyNetty 是一个基于 JAVA NIO 类库的异步通信框架，它的架构特点是：异步非阻塞、基于事件驱动、高性能、高可靠性和高可定制性。 Netty 能够做什么 开发异步、非阻塞的 TCP 网络应用程序； 开发异步、非阻塞的 UDP 网络应用程序； 开发异步文件传输应用程序； 开发异步 HTTP 服务端和客户端应用程序； 提供对多种编解码框架的集成，包括谷歌的 Protobuf、Jbossmarshalling、Java 序列化、压缩编解码、XML 解码、字符串编解码等，这些编解码框架可以被用户直接使用； 提供形式多样的编解码基础类库，可以非常方便的实现私有协议栈编解码框架的二次定制和开发； 基于职责链模式的 Pipeline-Handler 机制，用户可以非常方便的对网络事件进行拦截和定制； 所有的 IO 操作都是异步的，用户可以通过 Future-Listener 机制主动 Get 结果或者由 IO 线程操作完成之后主动 Notify 结果，用户的业务线程不需要同步等待； IP 黑白名单控制； 打印消息码流； 流量控制和整形； 性能统计； 基于链路空闲事件检测的心跳检测 …… Netty总体结构 Netty网络模型Netty是典型的Reactor模型结构。Netty中的Reactor模型主要由多路复用器(Acceptor)、事件分发器(Dispatcher)、事件处理器(Handler)组成，可以分为三种。 单线程模型所有I/O操作都由一个线程完成，即多路复用、事件分发和处理都是在一个Reactor线程上完成的。 对于一些小容量应用场景，可以使用单线程模型。但是对于高负载、大并发的应用却不合适，主要原因如下： 一个线程同时处理成百上千的链路，性能上无法支撑，即便CPU负荷达到100%，也无法满足海量消息的编码、解码、读取和发送； 当负载过重后，处理速度将变慢，这会导致大量客户端连接超时，超时之后往往会进行重发，最终会导致大量消息积压和处理超时，成为系统的性能瓶颈； 一旦单线程意外跑飞，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障，可靠性不高。多线程模型为了解决单线程模型存在的一些问题，演化而来的Reactor线程模型。 多线程模型的特点： 有专门一个Acceptor线程用于监听服务端，接收客户端的TCP连接请求； 网络IO的读写操作由一个NIO线程池负责，线程池可以采用标准的JDK线程池实现，包含一个任务队列和N个可用的线程，由这些NIO线程负责消息的读取、解码、编码和发送； 一个NIO线程可以同时处理多条链路，但是一个链路只能对应一个NIO线程，防止发生并发操作问题。 在绝大多数场景下，Reactor多线程模型都可以满足性能需求；但是，在极特殊应用场景中，一个NIO线程负责监听和处理所有的客户端连接可能会存在性能问题。例如百万客户端并发连接，或者服务端需要对客户端的握手消息进行安全认证，认证本身非常损耗性能。在这类场景下，单独一个Acceptor线程可能会存在性能不足问题，为了解决性能问题，产生了第三种Reactor线程模型-主从Reactor多线程模型。 主从多线程模型采用多个reactor，每个reactor都在自己单独的线程里执行。如果是多核，则可以同时响应多个客户端的请求，一旦链路建立成功就将链路注册到负责I/O读写的SubReactor线程池上。 事实上，Netty的线程模型并非固定不变，在启动辅助类中创建不同的EventLoopGroup实例并通过适当的参数配置，就可以支持上述三种Reactor线程模型。正是因为Netty对Reactor线程模型的支持提供了灵活的定制能力，所以可以满足不同业务场景的性能需求。 入门实例在用netty之前，先看看NIO的步骤 创建ServerSocketChannel，配置它为非阻塞模式 绑定监听，配置TCP参数，例如backlog大小 创建一个独立的I/O线程，用于轮询多路复用器Selector 创建Selector，将之前创建的ServerSocketChannel注册到Selector上，监听SelectKey.ACCEPT 启动I/O线程，在循环体中执行Selector.select()方法，轮询就绪的Channel 当轮询到就绪状态的Channel时，需要对其进行判断，如果是OP_APPECT状态，说明是新客户端接入，则调用ServerSocketChannel.accept()方法接受新的客户端 设置新接入的客户端链路SocketChannel为非阻塞模式，配置其他的一些TCP参数 将SocketChannel注册到Selector，监听OP_READ操作位 如果轮询的Channel为OP_READ，则说明SocketChannel中有新的就绪的数据包需要读取，则构造ByteBuffer对象，读取数据包。 如果轮询的Channel为OP_WRITE，说明还有数据没有发送完，需要继续发送用netty来做呢，还是用李林峰老师的代码来理解，netty版本是 &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;5.0.0.Alpha1&lt;/version&gt; &lt;/dependency&gt; 服务端TimeServer： import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; public class TimeServer { public void bind(int port) throws Exception { // 配置服务端的NIO两个线程组，其实就是Reactor线程组。 //创建两个的原因就是一个是服务器接收客户端的连接，一个是进行SocketChannel网络读写 EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { //这个b对象是netty用于启动NIO服务端的辅助启动类，目的是降低服务器端的开发复杂度 ServerBootstrap b = new ServerBootstrap(); //将两个线程组当参数传递到启动类中 b.group(bossGroup, workerGroup) //设置Channel为NioServerSocketChannel，对应的就是JDK中的ServerSocketChannel .channel(NioServerSocketChannel.class) //设置TCP参数，即backlog为1024 .option(ChannelOption.SO_BACKLOG, 1024) //绑定I/O事件的处理类ChildChannelHandler .childHandler(new ChildChannelHandler()); // 绑定端口，同步等待成功 ChannelFuture f = b.bind(port).sync(); // 异步阻塞，等待服务端监听端口关闭 f.channel().closeFuture().sync(); } finally { // 优雅退出，释放线程池资源 bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } private class ChildChannelHandler extends ChannelInitializer&lt;SocketChannel&gt; { @Override protected void initChannel(SocketChannel arg0) throws Exception { arg0.pipeline().addLast(new TimeServerHandler()); } } /** * @param args * @throws Exception */ public static void main(String[] args) throws Exception { int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { // 采用默认值 } } new TimeServer().bind(port); } } TimeServerHandler： import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; //继承了ChannelHandlerAdapter，用于网络事件的读写操作 public class TimeServerHandler extends ChannelHandlerAdapter { public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; //buf.readableBytes()获取缓冲区可读的字节数，并根据可读的字节数创建数组 byte[] req = new byte[buf.readableBytes()]; //复制到新的数组 buf.readBytes(req); //获取请求信息 String body = new String(req, &quot;UTF-8&quot;); System.out.println(&quot;The time server receive order : &quot; + body); //如果是QUERY TIME ORDER创建应答信息并返回给客户端 String currentTime = &quot;QUERY TIME ORDER&quot;.equalsIgnoreCase(body) ? new java.util.Date( System.currentTimeMillis()).toString() : &quot;BAD ORDER&quot;; ByteBuf resp = Unpooled.copiedBuffer(currentTime.getBytes()); ctx.write(resp); } public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { //将消息发送队列中的消息写到SocketChannel中发送给对方 ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) { //发送异常时关闭 ctx.close(); } } 客户端TimeClient： import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; public class TimeClient { public void connect(int port, String host) throws Exception { // 配置客户端NIO线程组，这个和server一样 EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); b.group(group).channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() { @Override public void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new TimeClientHandler()); } }); // 发起异步连接操作，调用sync等待连接成功 ChannelFuture f = b.connect(host, port).sync(); // 当代客户端链路关闭 f.channel().closeFuture().sync(); } finally { // 优雅退出，释放NIO线程组 group.shutdownGracefully(); } } /** * @param args * @throws Exception */ public static void main(String[] args) throws Exception { int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { // 采用默认值 } } new TimeClient().connect(port, &quot;127.0.0.1&quot;); } } TimeClientHandler ： import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; import java.util.logging.Logger; public class TimeClientHandler extends ChannelHandlerAdapter { private static final Logger logger = Logger .getLogger(TimeClientHandler.class.getName()); private final ByteBuf firstMessage; /** * Creates a client-side handler. */ public TimeClientHandler() { byte[] req = &quot;QUERY TIME ORDER&quot;.getBytes(); firstMessage = Unpooled.buffer(req.length); firstMessage.writeBytes(req); } //当客户端和服务端的TCP链路建立成功之后，会调用该方法，发送查询时间的指令给服务器 public void channelActive(ChannelHandlerContext ctx) { ctx.writeAndFlush(firstMessage); } //当服务器返回应答信息时，该方法被调用，从netty的ByteBuf中读取并打印应答信息 public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; byte[] req = new byte[buf.readableBytes()]; buf.readBytes(req); String body = new String(req, &quot;UTF-8&quot;); System.out.println(&quot;Now is : &quot; + body); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) { // 发生异常，打印异常日志，释放客户端资源 logger.warning(&quot;Unexpected exception from downstream : &quot; + cause.getMessage()); ctx.close(); } } 运行结果是：]]></content>
      <categories>
        <category>netty</category>
      </categories>
      <tags>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Selector]]></title>
    <url>%2F2017%2F10%2F12%2FSelector%2F</url>
    <content type="text"><![CDATA[选择器的概念Selector是Java NIO中的一个组件，用于检查一个或多个NIO Channel的状态是否处于可读、可写。如此可以实现单线程管理多个channels,也就是可以管理多个网络链接。 为什么要用选择器用单线程处理多个channels的好处是我需要更少的线程来处理channel。实际上，你甚至可以用一个线程来处理所有的channels。从操作系统的角度来看，切换线程开销是比较昂贵的，并且每个线程都需要占用系统资源，因此用的线程越少越好。但是现在的操作系统和CPU内核已经越来越好了（不在此说了）。通过一个图来表示一个线程管理selector Selector操作创建SelectorSelector selector = Selector.open(); 注册Channel到Selector上为了将Channel和Selector配合使用，必须将Channel注册到Selector上。通过SelectableChannel.register()来实现，如下 channel.configureBlocking(false); SelectionKey key = channel.register(selector, Selectionkey.OP_READ); Channel必须是非阻塞的。所以FileChannel不适用Selector，因为FileChannel不能切换为非阻塞模式。Socket channel可以正常使用。注意register()的第二个参数，这是一个interest集合，意思啥通过Selector监听Channel对什么事件感兴趣，可以监听四种不通类型的事件： Connect(SelectionKey.OP_CONNECT) Accept(SelectionKey.OP_ACCEPT) Read(SelectionKey.OP_READ) Writer(SelectionKey.OP_WRITE) 如果对多个事件感兴趣可利用位的或运算结合多个常量 int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; SelectionKey代表了Secletor和SelectableChannel的注册关系 key.attachment(); //返回SelectionKey的attachment，attachment可以在注册channel的时候指定。 key.channel(); // 返回该SelectionKey对应的channel。 key.selector(); // 返回该SelectionKey对应的Selector。 key.interestOps(); //返回代表需要Selector监控的IO操作的bit mask key.readyOps(); //返回一个bit mask，代表在相应channel上可以进行的IO操作。 key.attachment()可以将一个对象或者更多信息附着到SelectionKey上，这样就能方便的识别某个给定的通道。例如，可以附加 与通道一起使用的Buffer，或是包含聚集数据的某个对象。使用方法如下： selectionKey.attach(theObject); Object attachedObj = selectionKey.attachment(); 还可以在用register()方法向Selector注册Channel的时候附加对象 SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject); key.channel() &amp;&amp; key.selector()从SelectionKey访问Channel和Selector很简单 Channel channel = selectionKey.channel(); Selector selector = selectionKey.selector(); key.interestOps()就像向Selector注册通道一节中所描述的，interest集合是你所选择的感兴趣的事件集合。可以通过SelectionKey读写interest集合 int interestSet = selectionKey.interestOps(); boolean isInterestedInAccept = (interestSet &amp; SelectionKey.OP_ACCEPT) == SelectionKey.OP_ACCEPT； boolean isInterestedInConnect = interestSet &amp; SelectionKey.OP_CONNECT; boolean isInterestedInRead = interestSet &amp; SelectionKey.OP_READ; boolean isInterestedInWrite = interestSet &amp; SelectionKey.OP_WRITE; key.readyOps()ready 集合是通道已经准备就绪的操作的集合。在一次选择(Selection)之后，你会首先访问这个ready set。Selection将在下一小节进行解释。可以这样访问ready集合 int readySet = selectionKey.readyOps(); 可以用像检测interest集合那样的方法，来检测channel中什么事件或操作已经就绪。但是，也可以使用以下四个方法，它们都会返回一个布尔类型： selectionKey.isAcceptable(); selectionKey.isConnectable(); selectionKey.isReadable(); selectionKey.isWritable(); 通过Selector选择通道一旦向Selector注册了一或多个通道，就可以调用几个重载的select()方法。这些方法返回你所感兴趣的事件（如连接、接受、读或写）已经准备就绪的那些通道。换句话说，如果你对“读就绪”的通道感兴趣，select()方法会返回读事件已经就绪的那些通道。 int select() int select(long timeout) int selectNow() select()阻塞到至少有一个通道在你注册的事件上就绪了。 select(long timeout)和select()一样，除了最长会阻塞timeout毫秒(参数)。 selectNow()不会阻塞，不管什么通道就绪都立刻返回（译者注：此方法执行非阻塞的选择操作。如果自从前一次选择操作后，没有通道变成可选择的，则此方法直接返回零。）。 select()方法返回的int值表示有多少通道已经就绪。亦即，自上次调用select()方法后有多少通道变成就绪状态。如果调用select()方法，因为有一个通道变成就绪状态，返回了1，若再次调用select()方法，如果另一个通道就绪了，它会再次返回1。如果对第一个就绪的channel没有做任何操作，现在就有两个就绪的通道，但在每次select()方法调用之间，只有一个通道就绪了。 selectedKeys()一旦调用了select()方法，并且返回值表明有一个或更多个通道就绪了，然后可以通过调用selector的selectedKeys()方法，访问“已选择键集（selected key set）”中的就绪通道。如下所示： Set selectedKeys = selector.selectedKeys(); 可以遍历这个已选择的键集合来访问就绪的通道 Set selectedKeys = selector.selectedKeys(); Iterator keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) { SelectionKey key = keyIterator.next(); if(key.isAcceptable()) { // a connection was accepted by a ServerSocketChannel. } else if (key.isConnectable()) { // a connection was established with a remote server. } else if (key.isReadable()) { // a channel is ready for reading } else if (key.isWritable()) { // a channel is ready for writing } keyIterator.remove(); } 这个循环遍历已选择键集中的每个键，并检测各个键所对应的通道的就绪事件。 注意每次迭代末尾的keyIterator.remove()调用。Selector不会自己从已选择键集中移除SelectionKey实例。必须在处理完通道时自己移除。下次该通道变成就绪时，Selector会再次将其放入已选择键集中。 SelectionKey.channel()方法返回的通道需要转型成你要处理的类型，如ServerSocketChannel或SocketChannel等。wakeUp() 某个线程调用select()方法后阻塞了，即使没有通道已经就绪，也有办法让其从select()方法返回。只要让其它线程在第一个线程调用select()方法的那个对象上调用Selector.wakeup()方法即可。阻塞在select()方法上的线程会立马返回。 如果有其它线程调用了wakeup()方法，但当前没有线程阻塞在select()方法上，下个调用select()方法的线程会立即“醒来（wake up）”。close() 用完Selector后调用其close()方法会关闭该Selector，且使注册到该Selector上的所有SelectionKey实例无效。通道本身并不会关闭。 完整的示例这里有一个完整的示例，打开一个Selector，注册一个通道注册到这个Selector上(通道的初始化过程略去),然后持续监控这个Selector的四种事件（接受，连接，读，写）是否就绪。 Selector selector = Selector.open(); channel.configureBlocking(false); SelectionKey key = channel.register(selector, SelectionKey.OP_READ); while(true) { int readyChannels = selector.select(); if(readyChannels == 0) continue; Set selectedKeys = selector.selectedKeys(); Iterator keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) { SelectionKey key = keyIterator.next(); if(key.isAcceptable()) { // a connection was accepted by a ServerSocketChannel. } else if (key.isConnectable()) { // a connection was established with a remote server. } else if (key.isReadable()) { // a channel is ready for reading } else if (key.isWritable()) { // a channel is ready for writing } keyIterator.remove(); } } 引用李林峰老师《netty权威指南》的代码 server public class TimeServer { public static void main(String[] args) throws IOException { int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { // 采用默认值 } } MultiplexerTimeServer timeServer = new MultiplexerTimeServer(port); new Thread(timeServer, &quot;NIO-MultiplexerTimeServer-001&quot;).start(); } } class MultiplexerTimeServer implements Runnable { private Selector selector; private ServerSocketChannel servChannel; private volatile boolean stop; /** * 初始化多路复用器、绑定监听端口 * * @param port */ public MultiplexerTimeServer(int port) { try { selector = Selector.open(); servChannel = ServerSocketChannel.open(); servChannel.configureBlocking(false); servChannel.socket().bind(new InetSocketAddress(port), 1024); servChannel.register(selector, SelectionKey.OP_ACCEPT); System.out.println(&quot;The time server is start in port : &quot; + port); } catch (IOException e) { e.printStackTrace(); System.exit(1); } } public void stop() { this.stop = true; } /* * (non-Javadoc) * * @see java.lang.Runnable#run() */ public void run() { while (!stop) { try { selector.select(1000); Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; it = selectedKeys.iterator(); SelectionKey key = null; while (it.hasNext()) { key = it.next(); it.remove(); try { handleInput(key); } catch (Exception e) { if (key != null) { key.cancel(); if (key.channel() != null) key.channel().close(); } } } } catch (Throwable t) { t.printStackTrace(); } } // 多路复用器关闭后，所有注册在上面的Channel和Pipe等资源都会被自动去注册并关闭，所以不需要重复释放资源 if (selector != null) try { selector.close(); } catch (IOException e) { e.printStackTrace(); } } private void handleInput(SelectionKey key) throws IOException { if (key.isValid()) { // 处理新接入的请求消息 if (key.isAcceptable()) { // Accept the new connection ServerSocketChannel ssc = (ServerSocketChannel) key.channel(); SocketChannel sc = ssc.accept(); sc.configureBlocking(false); // Add the new connection to the selector sc.register(selector, SelectionKey.OP_READ); } if (key.isReadable()) { // Read the data SocketChannel sc = (SocketChannel) key.channel(); ByteBuffer readBuffer = ByteBuffer.allocate(1024); int readBytes = sc.read(readBuffer); if (readBytes &gt; 0) { readBuffer.flip(); byte[] bytes = new byte[readBuffer.remaining()]; readBuffer.get(bytes); String body = new String(bytes, &quot;UTF-8&quot;); System.out.println(&quot;The time server receive order : &quot; + body); String currentTime = &quot;QUERY TIME ORDER&quot; .equalsIgnoreCase(body) ? new java.util.Date( System.currentTimeMillis()).toString() : &quot;BAD ORDER&quot;; doWrite(sc, currentTime); } else if (readBytes &lt; 0) { // 对端链路关闭 key.cancel(); sc.close(); } else ; // 读到0字节，忽略 } } } private void doWrite(SocketChannel channel, String response) throws IOException { if (response != null &amp;&amp; response.trim().length() &gt; 0) { byte[] bytes = response.getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(bytes.length); writeBuffer.put(bytes); writeBuffer.flip(); channel.write(writeBuffer); } } } client public class TimeClient { public static void main(String[] args) { int port = 8080; if (args != null &amp;&amp; args.length &gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { // 采用默认值 } } new Thread(new TimeClientHandle(&quot;127.0.0.1&quot;, port), &quot;TimeClient-001&quot;) .start(); } } class TimeClientHandle implements Runnable { private String host; private int port; private Selector selector; private SocketChannel socketChannel; private volatile boolean stop; public TimeClientHandle(String host, int port) { this.host = host == null ? &quot;127.0.0.1&quot; : host; this.port = port; try { selector = Selector.open(); socketChannel = SocketChannel.open(); socketChannel.configureBlocking(false); } catch (IOException e) { e.printStackTrace(); System.exit(1); } } /* * (non-Javadoc) * * @see java.lang.Runnable#run() */ public void run() { try { doConnect(); } catch (IOException e) { e.printStackTrace(); System.exit(1); } while (!stop) { try { selector.select(1000); Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; it = selectedKeys.iterator(); SelectionKey key = null; while (it.hasNext()) { key = it.next(); it.remove(); try { handleInput(key); } catch (Exception e) { if (key != null) { key.cancel(); if (key.channel() != null) key.channel().close(); } } } } catch (Exception e) { e.printStackTrace(); System.exit(1); } } // 多路复用器关闭后，所有注册在上面的Channel和Pipe等资源都会被自动去注册并关闭，所以不需要重复释放资源 if (selector != null) try { selector.close(); } catch (IOException e) { e.printStackTrace(); } } private void handleInput(SelectionKey key) throws IOException { if (key.isValid()) { // 判断是否连接成功 SocketChannel sc = (SocketChannel) key.channel(); if (key.isConnectable()) { if (sc.finishConnect()) { sc.register(selector, SelectionKey.OP_READ); doWrite(sc); } else System.exit(1);// 连接失败，进程退出 } if (key.isReadable()) { ByteBuffer readBuffer = ByteBuffer.allocate(1024); int readBytes = sc.read(readBuffer); if (readBytes &gt; 0) { readBuffer.flip(); byte[] bytes = new byte[readBuffer.remaining()]; readBuffer.get(bytes); String body = new String(bytes, &quot;UTF-8&quot;); System.out.println(&quot;Now is : &quot; + body); this.stop = true; } else if (readBytes &lt; 0) { // 对端链路关闭 key.cancel(); sc.close(); } else ; // 读到0字节，忽略 } } } private void doConnect() throws IOException { // 如果直接连接成功，则注册到多路复用器上，发送请求消息，读应答 if (socketChannel.connect(new InetSocketAddress(host, port))) { socketChannel.register(selector, SelectionKey.OP_READ); doWrite(socketChannel); } else socketChannel.register(selector, SelectionKey.OP_CONNECT); } private void doWrite(SocketChannel sc) throws IOException { byte[] req = &quot;QUERY TIME ORDER&quot;.getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(req.length); writeBuffer.put(req); writeBuffer.flip(); sc.write(writeBuffer); if (!writeBuffer.hasRemaining()) System.out.println(&quot;Send order 2 server succeed.&quot;); } }]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>Selector</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java面试之dubbo]]></title>
    <url>%2F2017%2F10%2F12%2Fjava%E9%9D%A2%E8%AF%95%E4%B9%8Bdubbo%2F</url>
    <content type="text"><![CDATA[什么是dubbodubbo是一个分布式框架，远程服务调用的分布式框架，其核心部分包含： **集群容错**：提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。 **远程通讯**： 提供对多种基于长连接的NIO框架抽象封装，包括多种线程模型，序列化，以及“请求-响应”模式的信息交换方式。 **自动发现**：基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。 dubbo可以做什么 透明化的远程方法调用，就像调用本地方法一样调用远程方法，只需简单配置，没有任何API侵入。 软负载均衡及容错机制，可在内网替代F5等硬件负载均衡器，降低成本，减少单点。 服务自动注册与发现，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并且能够平滑添加或删除服务提供者。 dubbo的架构 图中节点角色说明：Provider: 暴露服务的服务提供方。Consumer: 调用远程服务的服务消费方。Registry: 服务注册与发现的注册中心。Monitor: 统计服务的调用次调和调用时间的监控中心。Container: 服务运行容器。对于这些角色来说，其他都还好，Monitor可能猿友们前期使用会把它忽略，但是后期会发现它的作用十分明显哦，如服务的调用量越来越大，服务的容量问题就暴露出来，这个服务需要多少机器支撑？什么时候该加机器？为了解决这个问题，第一步，要将服务现在每天的调用量，响应时间，都统计出来，作为容量规划的参考指标。其次，要可以动态调整权重，在线上，将某台机器的权重一直加大，并在加大的过程中记录响应时间的变化，直到响应时间到达阀值，记录此时的访问量，再以此访问量乘以机器数反推总容量。 调用关系说明：0 服务容器负责启动，加载，运行服务提供者。1 服务提供者在启动时，向注册中心注册自己提供的服务。2 服务消费者在启动时，向注册中心订阅自己所需的服务。3 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。4 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。5 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 dubbo的使用框架的搭建自己去google，有的博客讲的特别细。有的会在部署中出问题，有的会在打包出问题，这个需要多google去解决 dubbo的一些面试题dubbo默认使用什么通信协议dubbo共支持如下几种通信协议： dubbo:// Dubbo缺省协议采用单一长连接和NIO异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况。 rmi:// RMI协议采用JDK标准的java.rmi.*实现，采用阻塞式短连接和JDK标准序列化方式 hessian:// http:// webservice:// thrift:// memcached:// redis:// 服务调用超时问题怎么解决dubbo在调用服务不成功时，默认是会重试两次的。这样在服务端的处理时间超过了设定的超时时间时，就会有重复请求，比如在发邮件时，可能就会发出多份重复邮件，执行注册请求时，就会插入多条重复的注册数据，那么怎么解决超时问题呢？1.对于核心的服务中心，去除dubbo超时重试机制，并重新评估设置超时时间。2.业务处理代码必须放在服务端，客户端只做参数验证和服务调用，不涉及业务流程处理代码配置：&lt;dubbo:provider delay=&quot;-1&quot; timeout=&quot;6000&quot; retries=&quot;0&quot;/&gt;当然Dubbo的重试机制其实是非常好的QOS保证，它的路由机制，是会帮你把超时的请求路由到其他机器上，而不是本机尝试，所以 dubbo的重试机器也能一定程度的保证服务的质量。但是请一定要综合线上的访问情况，给出综合的评估。 一般使用什么注册中心，还有其他的选择吗？Multicast注册中心 Zookeeper注册中心 Redis注册中心 Simple注册中心 正常情况下我们使用zookeeper注册中心 ZooKeeper的节点是通过像树一样的结构来进行维护的，并且每一个节点通过路径来标示以及访问。除此之外，每一个节点还拥有自身的一些信息，包括：数据、数据长度、创建时间、修改时间等等。 从这样一类既含有数据，又作为路径表标示的节点的特点中，可以看出，ZooKeeper的节点既可以被看做是一个文件，又可以被看做是一个目录，它同时具有二者的特点。为了简单我们可以Znode来表示所讨论的ZooKeeper节点。 具体地说，Znode维护着数据、ACL（access controllist，访问控制列表）、时间戳等交换版本号等数据结构，它通过对这些数据的管理来让缓存生效并且令协调更新。每当Znode中的数据更新后它所维护的版本号将增加，这非常类似于数据库中计数器时间戳的操作方式。 另外Znode还具有原子性操作的特点：命名空间中，每一个Znode的数据将被原子地读写。读操作将读取与Znode相关的所有数据，写操作将替换掉所有的数据。除此之外，每一个节点都有一个访问控制列表，这个访问控制列表规定了用户操作的权限。 ZooKeeper中同样存在临时节点。这些节点与session同时存在，当session生命周期结束，这些临时节点也将被删除。临时节点在某些场合也发挥着非常重要的作用。 了解了Zookeeper的命名空间和节点之后我们需要跟上一篇文章中提到的内部逻辑联系起来.在上篇介绍到的内部流程中,拿到这里看看Zookeeper是如何处理的,流程如下图: 1 当服务提供者启动时,Zookeeper向/dubbo/com.foo.BarService/providers目录下写入自己的URL地址。2 当服务消费者启动时,这时候有两个动作: 订阅/dubbo/com.foo.BarService/providers目录下的提供者URL地址。 并向/dubbo/com.foo.BarService/consumers目录下写入自己的URL地址。 3当监控中心启动时,订阅/dubbo/com.foo.BarService目录下的所有提供者和消费者URL地址。 默认使用什么序列化框架Dubbo默认使用的是Hessian序列化。hessian是一个采用二进制格式传输的服务框架，相对传统soap web service，更轻量，更快速。 Hessian原理与协议简析：http的协议约定了数据传输的方式，hessian也无法改变太多： 1) hessian中client与server的交互，基于http-post方式。 2) hessian将辅助信息，封装在http header中，比如“授权token”等，我们可以基于http-header来封装关于“安全校验”“meta数据”等。hessian提供了简单的&quot;校验&quot;机制。 3) 对于hessian的交互核心数据，比如“调用的方法”和参数列表信息，将通过post请求的body体直接发送，格式为字节流。 4) 对于hessian的server端响应数据，将在response中通过字节流的方式直接输出。 hessian的协议本身并不复杂，在此不再赘言；所谓协议(protocol)就是约束数据的格式，client按照协议将请求信息序列化成字节序列发送给server端，server端根据协议，将数据反序列化成“对象”，然后执行指定的方法，并将方法的返回值再次按照协议序列化成字节流，响应给client，client按照协议将字节流反序列话成”对象”。 服务提供者能实现失效踢出的原理 ConfigServer（配置中心）每个Server/Client之间会作一个实时的心跳检测（因为它们都是建立的Socket长连接），比如几秒钟检测一次。收集每个Server提供的服务的信息，每个Client的信息，整理出一个服务列表，如： serviceName serverAddressList clientAddressList UserService 192.168.0.1，192.168.0.2，192.168.0.3，192.168.0.4 172.16.0.1，172.16.0.2 ProductService 192.168.0.3，192.168.0.4，192.168.0.5，192.168.0.6 172.16.0.2，172.16.0.3 OrderService 192.168.0.10，192.168.0.12，192.168.0.5，192.168.0.6 172.16.0.3，172.16.0.4 当某个Server不可用，那么就更新受影响的服务对应的serverAddressList，即把这个Server从serverAddressList中踢出去（从地址列表中删除），同时将推送serverAddressList给这些受影响的服务的clientAddressList里面的所有Client。如：192.168.0.3挂了，那么UserService和ProductService的serverAddressList都要把192.168.0.3删除掉，同时把新的列表告诉对应的Client 172.16.0.1，172.16.0.2，172.16.0.3；当某个Client挂了，那么更新受影响的服务对应的clientAddressListConfigServer根据服务列表，就能提供一个web管理界面，来查看管理服务的提供者和使用者。新加一个Server时，由于它会主动与ConfigServer取得联系，而ConfigServer又会将这个信息主动发送给Client，所以新加一个Server时，只需要启动Server，然后几秒钟内，Client就会使用上它提供的服务 Client（调用服务的机器） 每个Client启动时，主动与ConfigServer建立Socket长连接，并将自己的IP等相应信息发送给ConfigServer。Client在使用服务的时候根据服务名称去ConfigServer中获取服务提供者信息（这样ConfigServer就知道某个服务是当前哪几个Client在使用），Client拿到这些服务提供者信息后，与它们都建立连接，后面就可以直接调用服务了，当有多个服务提供者的时候，Client根据一定的规则来进行负载均衡，如轮询，随机，按权重等。一旦Client使用的服务它对应的服务提供者有变化（服务提供者有新增，删除的情况），ConfigServer就会把最新的服务提供者列表推送给Client，Client就会依据最新的服务提供者列表重新建立连接，新增的提供者建立连接，删除的提供者丢弃连接 Server（真正提供服务的机器） 每个Server启动时，主动与ConfigServer建立Scoket长连接，并将自己的IP，提供的服务名称，端口等信息直接发送给ConfigServer，ConfigServer就会收集到每个Server提供的服务的信息。 优点： 只要在Client和Server启动的时候，ConfigServer是好的，服务就可调用了，如果后面ConfigServer挂了，那只影响ConfigServer挂了以后服务提供者有变化，而Client还无法感知这一变化。 Client每次调用服务是不经过ConfigServer的，Client只是与它建立联系，从它那里获取提供服务者列表而已 调用服务-负载均衡：Client调用服务时，可以根据规则在多个服务提供者之间轮流调用服务。 服务提供者-容灾：某一个Server挂了，Client依然是可以正确的调用服务的，当前提是这个服务有至少2个服务提供者，Client能很快的感知到服务提供者的变化，并作出相应反应。 服务提供者-扩展：添加一个服务提供者很容易，而且Client会很快的感知到它的存在并使用它。 服务上线怎么不影响旧版本dubbo的文档中说到： 当一个接口实现，出现不兼容升级时，可以用版本号过渡，版本号不同的服务相互间不引用。 在低压力时间段，先升级一半提供者为新版本，再将所有消费者升级为新版本，然后将剩下的一半提供者升级为新版本 &lt;dubbo:service interface=&quot;com.foo.BarService&quot; version=&quot;1.0.0&quot; /&gt; &lt;dubbo:service interface=&quot;com.foo.BarService&quot; version=&quot;2.0.0&quot; /&gt; &lt;dubbo:reference id=&quot;barService&quot; interface=&quot;com.foo.BarService&quot; version=&quot;1.0.0&quot; /&gt; &lt;dubbo:reference id=&quot;barService&quot; interface=&quot;com.foo.BarService&quot; version=&quot;2.0.0&quot; /&gt; 不区分版本：(2.2.0以上版本支持) &lt;dubbo:reference id=&quot;barService&quot; interface=&quot;com.foo.BarService&quot; version=&quot;*&quot; /&gt; dubbo协议下的单一长连接与多线程并发如何协同工作底层采用netty。 集群容错怎么做dubbo的容错方案当我们的系统中用到Dubbo的集群环境,因为各种原因在集群调用失败时，Dubbo提供了多种容错方案，缺省为failover重试。Dubbo的集群容错在这里想说说他是因为我们实际的项目中出现了此类的问题,因为依赖的第三方项目出现异常,导致dubbo调用超时,此时使用的是默认的集群容错方式,而配置的reties=’3’,这样前段系统连续掉用了三次服务。 通过上面dubbo架构图这里的Invoker是Provider的一个可调用Service的抽象，Invoker封装了Provider地址及Service接口信息。Directory代表多个Invoker，可以把它看成List，但与List不同的是，它的值可能是动态变化的，比如注册中心推送变更。Cluster将Directory中的多个Invoker伪装成一个Invoker，对上层透明，伪装过程包含了容错逻辑，调用失败后，重试另一个。Router负责从多个Invoker中按路由规则选出子集，比如读写分离，应用隔离等。LoadBalance负责从多个Invoker中选出具体的一个用于本次调用，选的过程包含了负载均衡算法，调用失败后，需要重选。集群容错模式：Failover Cluster失败自动切换，当出现失败，重试其它服务器。(缺省)通常用于读操作，但重试会带来更长延迟。可通过retries=”2”来设置重试次数(不含第一次)。正是文章刚开始说的那种情况.Failfast Cluster快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。Failsafe Cluster失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。Failback Cluster失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。Forking Cluster并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过forks=”2”来设置最大并行数。Broadcast Cluster广播调用所有提供者，逐个调用，任意一台报错则报错。(2.1.0开始支持)通常用于通知所有提供者更新缓存或日志等本地资源信息。重试次数配置如：(failover集群模式生效)&lt;dubbo:serviceretries=&quot;2&quot;/&gt;或：&lt;dubbo:referenceretries=&quot;2&quot;/&gt;或：&lt;dubbo:reference&gt; &lt;dubbo:methodname=&quot;findFoo&quot;retries=&quot;2&quot;/&gt; &lt;/dubbo:reference&gt; 集群模式配置如：&lt;dubbo:servicecluster=&quot;failsafe&quot;/&gt;或：&lt;dubbo:referencecluster=&quot;failsafe&quot;/&gt; dubbo是如何实现负载均衡dubbo负载均衡策略：在集群负载均衡时，Dubbo提供了多种均衡策略，缺省为random随机调用。RandomLoadBalance随机，按权重设置随机概率。在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。RoundRobin LoadBalance轮循，按公约后的权重设置轮循比率。存在慢的提供者累积请求问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。LeastActive LoadBalance最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。ConsistentHashLoadBalance一致性Hash，相同参数的请求总是发到同一提供者。当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。Dubbo的集群容错和负载均衡同样也是Dubbo本身的高级特性.正如我们在说自定义扩展的时候一样,这两个特征同样也可以进行自定义扩展,用户可以根据自己实际的需求来扩展他们从而满足项目的实际需求. 遇到的问题场景描述：客户端远程异步调用ServiceA，ServiceA在处理客户端请求的过程中需要远程同步调用ServiceB，ServiceA从ServiceB的响应中取数据时，得到的是null。对于上面的问题，解决办法有三个：1.方法调用两次 ServiceA调用ServiceB的地方写两次一样的调用，这个方法原理就像ServiceB调用ServiceC一样，即清除attachements。 这个方法最简单，但是可能对不了解的人来说，这块业务代码写重复了，会不小心删除掉，而且从写代码的角度来说，这个很鸡肋，所以不推荐。 2.修改Dubbo源码 修改AbstractInvoker第137行，改成每次都对async进行实际赋值， boolean isAsync = getUrl().getMethodParameter(invocation.getMethodName(), Constants.ASYNC_KEY, false); invocation.setAttachment(Constants.ASYNC_KEY, String.valueOf(isAsync)); 3.自定义Filter实现com.alibaba.dubbo.rpc.Filter，在RpcContext中清除这个async， @Activate(group = {Constants.PROVIDER}) public class AsyncFilter implements Filter { @Override public Result invoke(Invoker&lt;?&gt; invoker, Invocation invocation) throws RpcException { RpcContext.getContext().getAttachments().remove(Constants.ASYNC_KEY); return invoker.invoke(invocation); } } 同时在src/main/resources/META-INF/dubbo/下添加com.alibaba.dubbo.rpc.Filter文件，内容文件如下： asyncFilter=com.abc.filter.AsyncFilter根据n多的博客整理出来的一些，以后有其他东西再加进去]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Channel]]></title>
    <url>%2F2017%2F10%2F11%2FChannel%2F</url>
    <content type="text"><![CDATA[Channel基础Channel 用于在字节缓冲区和位于通道另一侧的实体（通常是一个文件或套接字）之间有效地传输数据。Java NIO的通道类似流，但又有些不同 既可以从通道中读取数据，也可以写数据到通道。但是流的读写通常是单向的 通道可以异步读写 通道中的数据通常总是要先读到一个Buffer，或者总是从Buffer中写入 Channel的源码 import java.io.Closeable; import java.io.IOException; public interface Channel extends Closeable { boolean isOpen();//打开通道 void close() throws IOException;//关闭通道 } Channel的实现类 FileChannel：从文件中读取数据DatagramChannel：能通过UDP读写网络中的数据SockeChannel：能通过TCP读写网络中的数据ServerSocketChannel：可以监听新进来的TCP连接，像WEB服务器那样。对每一个新进来的连接都会创建一个SocketChannel。 Channel的实例FileChannel读文件import java.io.RandomAccessFile; import java.nio.ByteBuffer; import java.nio.channels.FileChannel; public class FileChannelDemo{ public static void main(String[] args) throws Exception { RandomAccessFile rFile = new RandomAccessFile(&quot;D:\\test_gc.log&quot;,&quot;rw&quot;); //从文件中读取数据，打开通道 FileChannel inChannel = rFile.getChannel(); //创建48字节的缓冲区 ByteBuffer buf = ByteBuffer.allocate(48); //从通道读取数据到缓冲区 int bytesRead = inChannel.read(buf); while(bytesRead != -1){ //写模式改成读模式 buf.flip(); System.out.println(&quot;Read &quot;+bytesRead); while(buf.hasRemaining()){ System.out.println((char)buf.get()); System.out.println(buf.position()+&quot;=========&quot;); } buf.clear(); bytesRead = inChannel.read(buf); } rFile.close(); } } FileChannel写文件import java.io.RandomAccessFile; import java.nio.ByteBuffer; import java.nio.channels.FileChannel; public class FileChannelDemo{ public static void main(String[] args) throws Exception { String date = &quot;test insert...&quot;; RandomAccessFile rFile = new RandomAccessFile(&quot;D:\\test_gc.log&quot;,&quot;rw&quot;); //从文件中读取数据，打开通道 FileChannel inChannel = rFile.getChannel(); //创建48字节的缓冲区,如果分配4个字节，而date比较长，那么在buf.put的时候就会报错。 ByteBuffer buf = ByteBuffer.allocate(48); //指定position为文件大小的值，即在channel的末尾追加内容,如果没有，则直接覆盖原来的数据 inChannel.position(inChannel.size()); buf.clear(); buf.put(date.getBytes()); buf.flip(); while(buf.hasRemaining()) { inChannel.write(buf); } inChannel.close(); rFile.close(); } } DatagramChannel由于DatagramChannel通过UDP读取数据，需要一个接受方，和一个发送方。接收方代码： import java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.DatagramChannel; import java.nio.charset.Charset; public class Reveiver { public static void main(String[] args) { try { receive(); } catch (IOException e) { e.printStackTrace(); } } private static void receive() throws IOException{ //指定端口 DatagramChannel channel =DatagramChannel.open(); channel.socket().bind(new InetSocketAddress(10022)); ByteBuffer buffer =ByteBuffer.allocate(60); //接受数据 while(channel.receive(buffer)==null){ try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } buffer.flip(); String recStr =Charset.forName(&quot;utf-8&quot;).newDecoder().decode(buffer).toString(); System.out.println(recStr); channel.close(); } } 发送方代码： import java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.DatagramChannel; public class Sender { public static void main(String[] args) { try { send(); } catch (IOException e) { e.printStackTrace(); } } private static void send() throws IOException{ DatagramChannel channel =DatagramChannel.open(); ByteBuffer buffer =ByteBuffer.wrap(&quot;测试DatagramChannel&quot;.getBytes(&quot;utf-8&quot;)); //通过send发送数据 channel.send(buffer, new InetSocketAddress(&quot;localhost&quot;,10022)); channel.close(); } } SocketChannel 和ServerSocketChannel可以用非阻塞的SocketChannel和ServerSocketChannel代替阻塞的Socket和ServerSocket。这个后期学到选择器的时候再具体研究。]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>Channel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Buffer]]></title>
    <url>%2F2017%2F10%2F10%2FBuffer%2F</url>
    <content type="text"><![CDATA[缓冲区缓冲区基础缓冲区概念缓冲区是包在一个对象内的基本数据元素数组。Buffer 类相比一个简单数组的优点是它将关于数据的数据内容和信息包含在一个单一的对象中。Buffer 类以及它专有的子类定义了一个用于处理数据缓冲区的 API。如下图，还有一些其他的子类这就不列举了 通过上图可以看出，都是基本类型对应的Buffer。上图的几个Buffer都提供了读和写的方法get()和put()。 属性所有的缓冲区都具有四个属性来提供关于其所包含的数据元素的信息。 容量（Capacity）：缓冲区能够容纳的数据元素的最大数量。这一容量在缓冲区创建时被设定，并且永远不能被改变。 上界（Limit）：缓冲区的第一个不能被读或写的元素。或者说，缓冲区中现存元素的计数。 位置（Position）：下一个要被读或写的元素的索引。位置会自动由相应的 get( )和 put( )函数更新。 标记（Mark）：一个备忘位置。调用 mark( )来设定 mark = postion。调用 reset( )设定 position = mark。标记在设定前是未定义的( undefined) 。 缓冲区的创建想要获得一个Buffer对象首先要进行分配。每一个Buffer类都有一个allocate()方法这是一个可储存100字符的CharBuffer CharBuffer buf = CharBuffer.allocate(100);或者用以下wrap方法 char [] myArray = new char [100]; CharBuffer charbuffer = CharBuffer.wrap (myArray);通过创建缓冲区我们再来看看capacity，limit，positioncapacity作为一个内存块，Buffer有一个固定的大小值,一般创建Buffer时初始化写入–&gt;ByteBuffer.allocate(capacity)，你只能往capacity里写byte、long、char等类型。一旦Buffer满了，需要将其清空（通过读数据或者清除数据）才能继续往里面写数据pisition当你写数据到Buffer中，position表示当前的位置。初始位置的position值为0，当一个byte、long等数据写到Buffer后，position会向前移动到下一个可插入数据的Buffer单元。position最大可为capacity-1(因为position的初始值为0)当读取数据时，也是从某个特定位置读，当Buffer从写模式切换到读模式，position会被重置为0，当从Buffer的position处读取数据时，position向前移动到下一个可读位置。limit在写模式中，Buffer的limit表示你最多往Buffer中写多少数据。写模式下，limit=capacity在读模式中，limit表示你最多能读多少数据。因此，当切换读模式，limit会被设置成写模式下的position值（你能读到之前写入的所有数据）如下图，我插入了1,2,3,4四个数据进这个Buffer 下面通过一个例子来看看 import java.nio.Buffer; import java.nio.ByteBuffer; import java.nio.CharBuffer; import java.nio.ByteOrder; public class BufferCharView { public static void main (String [] argv) throws Exception { ByteBuffer byteBuffer = ByteBuffer.allocate (7).order (ByteOrder.BIG_ENDIAN); CharBuffer charBuffer = byteBuffer.asCharBuffer( ); // Load the ByteBuffer with some bytes byteBuffer.put (0, (byte)0); byteBuffer.put (1, (byte)&apos;H&apos;); byteBuffer.put (2, (byte)0); byteBuffer.put (3, (byte)&apos;i&apos;); byteBuffer.put (4, (byte)0); byteBuffer.put (5, (byte)&apos;!&apos;); byteBuffer.put (6, (byte)0); println (byteBuffer); println (charBuffer); } // Print info about a buffer private static void println (Buffer buffer) { System.out.println (&quot;pos=&quot; + buffer.position( ) + &quot;, limit=&quot; + buffer.limit( ) + &quot;, capacity=&quot; + buffer.capacity( ) + &quot;: &apos;&quot; + buffer.toString( ) + &quot;&apos;&quot;); } } 运行结果： 函数Buffer的实现类自带了几个函数，也是我们经常用的flip()该方法是将Buffer从写模式切换到读模式。调用flip()方法会将position设回0，并将limit设置成之前position的值（position表示标记读的位置，limit表示之前写进多少个字节等—》现在能读多少个字节） public final Buffer flip() { limit = position; position = 0; mark = -1; return this; } rewind()Buffer.rewind()将position设回0，所以你可以重读Buffer中的所有数据。limit保持不变，仍然表示能从Buffer中读取多少个元素（byte、char等）。 public final Buffer rewind() { position = 0; mark = -1; return this; } clear()和compact()一旦读完Buffer中的数据，需要让Buffer准备好再次被写入，可以通过clear()或者compact()来完成。 如果调用的是clear()，position将被设为0，limit将被设为capacity的值，换句话说，Buffer被清空来，Buffer中的数据并未清除，只说这些标记告诉我们可以从哪里开始往Buffer中写数据了。如果里面还有数据，调用clear()，这些数据将被遗忘，意味着不再有任何标记会告诉你哪些数据被读过，哪些没有。 public final Buffer clear() { position = 0; limit = capacity; mark = -1; return this; } 如果Buffer中未读的数据，并且以后还需要，那么使用compact()方法。 compact方法将所有未读的数据copy到Buffer起始处，然后将position设到最后一个未读数据的后面。limit属性仍然和clear()方法一样，设置成capacity。现在Buffer准备好写数据了，但是不会覆盖未读的数据。mark()与reset()通过Buffer.mark()方法，可以标记Buffer中的一个特定的position，之后可以通过调用Buffer.reset()恢复到这个position。 public final Buffer mark() { mark = position; return this; } public final Buffer reset() { int m = mark; if (m &lt; 0) throw new InvalidMarkException(); position = m; return this; } 下面通过一个例子来看看mark和rest的方法 import java.io.BufferedInputStream; import java.io.ByteArrayInputStream; import java.io.IOException; public class MarkDemo { public static void main(String[] args) { try { // 初始化一个字节数组，内有5个字节的数据 byte[] bytes = { 1, 2, 3, 4, 5 }; // 用一个ByteArrayInputStream来读取这个字节数组 ByteArrayInputStream in = new ByteArrayInputStream(bytes); // 将ByteArrayInputStream包含在一个BufferedInputStream，并初始化缓冲区大小为2。 BufferedInputStream bis = new BufferedInputStream(in, 2); // 读取字节1 System.out.print(bis.read() + &quot;,&quot;); // 在字节2处做标记，同时设置readlimit参数为1 // 根据JAVA文档mark以后最多只能读取1个字节，否则mark标记失效，但实际运行结果不是这样 System.out.println(&quot;mark&quot;); bis.mark(1); /* * 连续读取两个字节，超过了readlimit的大小，mark标记仍有效 */ // 连续读取两个字节 System.out.print(bis.read() + &quot;,&quot;); System.out.print(bis.read() + &quot;,&quot;); // 调用reset方法，未发生异常，说明mark标记仍有效。 // 因为，虽然readlimit参数为1，但是这个BufferedInputStream类的缓冲区大小为2， // 所以允许读取2字节 System.out.println(&quot;reset&quot;); bis.reset(); /* * 连续读取3个字节，超过了缓冲区大小，mark标记失效。 * 在这个例子中BufferedInputStream类的缓冲区大小大于readlimit, mark标记由缓冲区大小决定 */ // reset重置后连续读取3个字节，超过了BufferedInputStream类的缓冲区大小 System.out.print(bis.read() + &quot;,&quot;); System.out.print(bis.read() + &quot;,&quot;); System.out.print(bis.read() + &quot;,&quot;); // 再次调用reset重置，抛出异常，说明mark后读取3个字节，mark标记失效 System.out.println(&quot;reset again&quot;); bis.reset(); } catch (IOException e) { // TODO Auto-generated catch block e.printStackTrace(); } } }]]></content>
      <categories>
        <category>NIO</category>
      </categories>
      <tags>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring源码之Autowired]]></title>
    <url>%2F2017%2F10%2F09%2FSpring%E6%BA%90%E7%A0%81%E4%B9%8BAutowired%2F</url>
    <content type="text"><![CDATA[#测试]]></content>
      <categories>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring Autowired</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开篇]]></title>
    <url>%2F2017%2F09%2F27%2Ftest%2F</url>
    <content type="text"><![CDATA[开篇寄语一直想自己搭建一个博客，但是身为资深懒人，什么都不愿意去做，正好趁着闲时抓紧时间去做一下，不然肯定又拖了。主要分享一些工作中遇到的问题和一些面试问题。因为我本人是学java的，所以一般是java的代码。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
</search>
